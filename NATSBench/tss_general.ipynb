{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cc63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 17:47:05.533023: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-10 17:47:05.579626: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 17:47:06.300118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import tqdm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# XAutoDL \n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_search_spaces\n",
    "\n",
    "# API\n",
    "from nats_bench import create\n",
    "\n",
    "# custom modules\n",
    "from custom.tss_model import TinyNetwork\n",
    "from xautodl.models.cell_searchs.genotypes import Structure\n",
    "from ZeroShotProxy import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6018e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Namespace(data_path='./cifar.python', dataset='cifar10', search_space='tss', config_path='./configs/nas-benchmark/algos/weight-sharing.config', max_nodes=4, channel=16, num_cells=5, affine=1, track_running_stats=0, print_freq=200, gpu=0, workers=2, api_data_path='./api_data/NATS-tss-v1_0-3ffb9-simple/', save_dir='./results/tmp', zero_shot_score='az_nas', rand_seed=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Training-free NAS on NATSBench (TSS)\")\n",
    "parser.add_argument(\"--data_path\", type=str, default='./cifar.python', help=\"The path to dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='cifar10',choices=[\"cifar10\", \"cifar100\", \"ImageNet16-120\"], help=\"Choose between Cifar10/100 and ImageNet-16.\")\n",
    "\n",
    "# channels and number-of-cells\n",
    "parser.add_argument(\"--search_space\", type=str, default='tss', help=\"The search space name.\")\n",
    "parser.add_argument(\"--config_path\", type=str, default='./configs/nas-benchmark/algos/weight-sharing.config', help=\"The path to the configuration.\")\n",
    "parser.add_argument(\"--max_nodes\", type=int, default=4, help=\"The maximum number of nodes.\")\n",
    "parser.add_argument(\"--channel\", type=int, default=16, help=\"The number of channels.\")\n",
    "parser.add_argument(\"--num_cells\", type=int, default=5, help=\"The number of cells in one stage.\")\n",
    "parser.add_argument(\"--affine\", type=int, default=1, choices=[0, 1], help=\"Whether use affine=True or False in the BN layer.\")\n",
    "parser.add_argument(\"--track_running_stats\", type=int, default=0, choices=[0, 1], help=\"Whether use track_running_stats or not in the BN layer.\")\n",
    "\n",
    "# log\n",
    "parser.add_argument(\"--print_freq\", type=int, default=200, help=\"print frequency (default: 200)\")\n",
    "\n",
    "# custom\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"\")\n",
    "parser.add_argument(\"--workers\", type=int, default=2, help=\"number of data loading workers\")\n",
    "parser.add_argument(\"--api_data_path\", type=str, default=\"./api_data/NATS-tss-v1_0-3ffb9-simple/\", help=\"\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./results/tmp', help=\"Folder to save checkpoints and log.\")\n",
    "parser.add_argument('--zero_shot_score', type=str, default='az_nas', choices=['az_nas','zico','zen','gradnorm','naswot','synflow','snip','grasp','te_nas','gradsign'])\n",
    "parser.add_argument(\"--rand_seed\", type=int, default=1, help=\"manual seed (we use 1-to-5)\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.rand_seed is None or args.rand_seed < 0:\n",
    "    args.rand_seed = random.randint(1, 100000)\n",
    "\n",
    "print(args.rand_seed)\n",
    "print(args)\n",
    "xargs=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a05319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=results/tmp, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "data_path        : ./cifar.python\n",
      "dataset          : cifar10\n",
      "search_space     : tss\n",
      "config_path      : ./configs/nas-benchmark/algos/weight-sharing.config\n",
      "max_nodes        : 4\n",
      "channel          : 16\n",
      "num_cells        : 5\n",
      "affine           : 1\n",
      "track_running_stats : 0\n",
      "print_freq       : 200\n",
      "gpu              : 0\n",
      "workers          : 2\n",
      "api_data_path    : ./api_data/NATS-tss-v1_0-3ffb9-simple/\n",
      "save_dir         : ./results/tmp\n",
      "zero_shot_score  : az_nas\n",
      "rand_seed        : 1\n",
      "Python  Version  : 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]\n",
      "Pillow  Version  : 9.4.0\n",
      "PyTorch Version  : 2.0.1\n",
      "cuDNN   Version  : 8500\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 1\n",
      "CUDA_VISIBLE_DEVICES : 1\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CUDA is not available.\"\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_num_threads(xargs.workers)\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78557cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create API = NATStopology(0/15625 architectures, fast_mode=True, file=) done\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./configs/nas-benchmark/algos/weight-sharing.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=100, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, Valid-Loader-Num=49, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=100, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "search space : ['none', 'skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\n"
     ]
    }
   ],
   "source": [
    "## API\n",
    "api = create(xargs.api_data_path, xargs.search_space, fast_mode=True, verbose=False)\n",
    "logger.log(\"Create API = {:} done\".format(api))\n",
    "\n",
    "## data\n",
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(xargs.config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "search_loader, train_loader, valid_loader = get_nas_search_loaders(train_data,\n",
    "                                                                   valid_data,\n",
    "                                                                   xargs.dataset,\n",
    "                                                                   \"./configs/nas-benchmark/\",\n",
    "                                                                   (config.batch_size, config.test_batch_size),\n",
    "                                                                   xargs.workers,)\n",
    "logger.log(\"||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\".format(xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "## model\n",
    "search_space = get_search_spaces(xargs.search_space, \"nats-bench\")\n",
    "logger.log(\"search space : {:}\".format(search_space))\n",
    "\n",
    "device = torch.device('cuda:{}'.format(xargs.gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c557c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_genotype(max_nodes, op_names):\n",
    "        genotypes = []\n",
    "        for i in range(1, max_nodes):\n",
    "            xlist = []\n",
    "            for j in range(i):\n",
    "                node_str = \"{:}<-{:}\".format(i, j)\n",
    "                op_name = random.choice(op_names)\n",
    "                xlist.append((op_name, j))\n",
    "            genotypes.append(tuple(xlist))\n",
    "        arch = Structure(genotypes)\n",
    "        return arch\n",
    "\n",
    "real_input_metrics = ['zico', 'snip', 'grasp', 'te_nas', 'gradsign']\n",
    "    \n",
    "def search_find_best(xargs, xloader, n_samples = None, archs = None):\n",
    "    logger.log(\"Searching with {}\".format(xargs.zero_shot_score.lower()))\n",
    "    score_fn_name = \"compute_{}_score\".format(xargs.zero_shot_score.lower())\n",
    "    score_fn = globals().get(score_fn_name)\n",
    "    input_, target_ = next(iter(xloader))\n",
    "    resolution = input_.size(2)\n",
    "    batch_size = input_.size(0)\n",
    "    zero_shot_score_dict = None\n",
    "    arch_list = []\n",
    "    trainloader = train_loader if xargs.zero_shot_score.lower() in real_input_metrics else None\n",
    "        \n",
    "    if archs is None and n_samples is not None:\n",
    "        all_time = []\n",
    "        all_mem = []\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        for i in tqdm.tqdm(range(n_samples)):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            # random sampling\n",
    "            arch = random_genotype(xargs.max_nodes, search_space)\n",
    "            network = TinyNetwork(xargs.channel, xargs.num_cells, arch, class_num)\n",
    "            network = network.to(device)\n",
    "            network.train()\n",
    "\n",
    "            start.record()\n",
    "            \n",
    "\n",
    "            info_dict = score_fn.compute_nas_score(network, gpu=xargs.gpu, trainloader=trainloader, resolution=resolution, batch_size=batch_size)\n",
    "\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            all_time.append(start.elapsed_time(end))\n",
    "#             all_mem.append(torch.cuda.max_memory_reserved())\n",
    "            all_mem.append(torch.cuda.max_memory_allocated())\n",
    "\n",
    "            arch_list.append(arch)\n",
    "            if zero_shot_score_dict is None: # initialize dict\n",
    "                zero_shot_score_dict = dict()\n",
    "                for k in info_dict.keys():\n",
    "                    zero_shot_score_dict[k] = []\n",
    "            for k, v in info_dict.items():\n",
    "                zero_shot_score_dict[k].append(v)\n",
    "\n",
    "        logger.log(\"------Runtime------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(all_time)))\n",
    "        logger.log(\"------Avg Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.mean(all_mem)/1e9))\n",
    "        logger.log(\"------Max Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.max(all_mem)/1e9))\n",
    "        \n",
    "    elif archs is not None and n_samples is None:\n",
    "        all_time = []\n",
    "        all_mem = []\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        for arch in tqdm.tqdm(archs):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            network = TinyNetwork(xargs.channel, xargs.num_cells, arch, class_num)\n",
    "            network = network.to(device)\n",
    "            network.train()\n",
    "\n",
    "            start.record()\n",
    "            \n",
    "\n",
    "            info_dict = score_fn.compute_nas_score(network, gpu=xargs.gpu, trainloader=trainloader, resolution=resolution, batch_size=batch_size)\n",
    "\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            all_time.append(start.elapsed_time(end))\n",
    "#             all_mem.append(torch.cuda.max_memory_reserved())\n",
    "            all_mem.append(torch.cuda.max_memory_allocated())\n",
    "\n",
    "            arch_list.append(arch)\n",
    "            if zero_shot_score_dict is None: # initialize dict\n",
    "                zero_shot_score_dict = dict()\n",
    "                for k in info_dict.keys():\n",
    "                    zero_shot_score_dict[k] = []\n",
    "            for k, v in info_dict.items():\n",
    "                zero_shot_score_dict[k].append(v)\n",
    "\n",
    "        logger.log(\"------Runtime------\")\n",
    "        logger.log(\"All: {:.5f} ms\".format(np.mean(all_time)))\n",
    "        logger.log(\"------Avg Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.mean(all_mem)/1e9))\n",
    "        logger.log(\"------Max Mem------\")\n",
    "        logger.log(\"All: {:.5f} GB\".format(np.max(all_mem)/1e9))\n",
    "        \n",
    "    return arch_list, zero_shot_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967c488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c71e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching with az_nas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 327/1042 [00:26<01:03, 11.25it/s]"
     ]
    }
   ],
   "source": [
    "# ######### search across random N archs #########\n",
    "# archs, results = search_find_best(xargs, train_loader, n_samples=3000)\n",
    "\n",
    "######### search across N archs uniformly sampled according to test acc. #########\n",
    "def uniform_sample_archs(search_space, xargs, api, n_samples=1000, dataset='ImageNet16-120'):\n",
    "    arch = random_genotype(xargs.max_nodes, search_space)\n",
    "    search_space = get_search_spaces(xargs.search_space, \"nats-bench\")\n",
    "    archs = arch.gen_all(search_space, xargs.max_nodes, False)\n",
    "    \n",
    "    def get_results_from_api(api, arch, dataset='cifar10'):\n",
    "        dataset_candidates = ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120']\n",
    "        assert dataset in dataset_candidates\n",
    "        index = api.query_index_by_arch(arch)\n",
    "        api._prepare_info(index)\n",
    "        archresult = api.arch2infos_dict[index]['200']\n",
    "        if dataset == 'cifar10-valid':\n",
    "            acc = archresult.get_metrics(dataset, 'x-valid', iepoch=None, is_random=False)['accuracy']\n",
    "        elif dataset == 'cifar10':\n",
    "            acc = archresult.get_metrics(dataset, 'ori-test', iepoch=None, is_random=False)['accuracy']\n",
    "        else:\n",
    "            acc = archresult.get_metrics(dataset, 'x-test', iepoch=None, is_random=False)['accuracy']\n",
    "        return acc\n",
    "\n",
    "    accs = []\n",
    "    for a in archs:\n",
    "        accs.append(get_results_from_api(api, a, dataset))\n",
    "    interval = len(archs) // n_samples\n",
    "    sorted_indices = np.argsort(accs)\n",
    "    new_archs = []\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        if i % interval == 0:\n",
    "            new_archs.append(archs[idx])\n",
    "    archs = new_archs\n",
    "    \n",
    "    return archs\n",
    "\n",
    "if os.path.exists(\"./tss_uniform_arch.pickle\"):\n",
    "    with open(\"./tss_uniform_arch.pickle\", \"rb\") as fp:\n",
    "        uniform_archs = pickle.load(fp)\n",
    "else:\n",
    "    uniform_archs = uniform_sample_archs(search_space, xargs, api, 1000, 'ImageNet16-120')\n",
    "    with open(\"./tss_uniform_arch.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(uniform_archs, fp)\n",
    "        \n",
    "result_path = \"./{}_uniform_arch.pickle\".format(args.zero_shot_score)\n",
    "if os.path.exists(result_path):\n",
    "    print(\"results already exists\")\n",
    "    with open(result_path, \"rb\") as fp:\n",
    "        results = pickle.load(fp)\n",
    "    archs = uniform_archs\n",
    "else:\n",
    "    archs, results = search_find_best(xargs, train_loader, archs=uniform_archs)\n",
    "    with open(result_path, \"wb\") as fp:\n",
    "        pickle.dump(results, fp)\n",
    "\n",
    "\n",
    "# ######### search across all archs #########\n",
    "# def generate_all_archs(search_space, xargs):\n",
    "#     arch = random_genotype(xargs.max_nodes, search_space)\n",
    "#     archs = arch.gen_all(search_space, xargs.max_nodes, False)\n",
    "#     return archs\n",
    "\n",
    "# if os.path.exists(\"./tss_all_arch.pickle\"):\n",
    "#     with open(\"./tss_all_arch.pickle\", \"rb\") as fp:\n",
    "#         all_archs = pickle.load(fp)\n",
    "# else:\n",
    "#     all_archs = generate_all_archs(search_space, xargs)\n",
    "#     with open(\"./tss_all_arch.pickle\", \"wb\") as fp:\n",
    "#         pickle.dump(all_archs, fp)\n",
    "\n",
    "# # archs, results = search_find_best(xargs, train_loader, archs=all_archs)\n",
    "\n",
    "# ####\n",
    "# result_path = \"./{}_all_arch.pickle\".format(args.zero_shot_score)\n",
    "# if os.path.exists(result_path):\n",
    "#     print(\"results already exists\")\n",
    "#     with open(result_path, \"rb\") as fp:\n",
    "#         results = pickle.load(fp)\n",
    "#     archs = all_archs\n",
    "# else:\n",
    "#     archs, results = search_find_best(xargs, train_loader, archs=all_archs)\n",
    "#     with open(result_path, \"wb\") as fp:\n",
    "#         pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4147a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_api(api, arch, dataset='cifar10'):\n",
    "    dataset_candidates = ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120']\n",
    "    assert dataset in dataset_candidates\n",
    "    index = api.query_index_by_arch(arch)\n",
    "    api._prepare_info(index)\n",
    "    archresult = api.arch2infos_dict[index]['200']\n",
    "    \n",
    "    if dataset == 'cifar10-valid':\n",
    "        acc = archresult.get_metrics(dataset, 'x-valid', iepoch=None, is_random=False)['accuracy']\n",
    "    elif dataset == 'cifar10':\n",
    "        acc = archresult.get_metrics(dataset, 'ori-test', iepoch=None, is_random=False)['accuracy']\n",
    "    else:\n",
    "        acc = archresult.get_metrics(dataset, 'x-test', iepoch=None, is_random=False)['accuracy']\n",
    "    flops = archresult.get_compute_costs(dataset)['flops']\n",
    "    params = archresult.get_compute_costs(dataset)['params']\n",
    "    \n",
    "    return acc, flops, params\n",
    "\n",
    "api_valid_accs, api_flops, api_params = [], [], []\n",
    "for a in archs:\n",
    "#     valid_acc, flops, params = get_results_from_api(api, a, 'cifar10')\n",
    "#     valid_acc, flops, params = get_results_from_api(api, a, 'cifar100')\n",
    "    valid_acc, flops, params = get_results_from_api(api, a, 'ImageNet16-120')\n",
    "    api_valid_accs.append(valid_acc)\n",
    "    api_flops.append(flops)\n",
    "    api_params.append(params)\n",
    "    \n",
    "print(\"Maximum acc: {}% \\n Info\".format(np.max(api_valid_accs)))\n",
    "best_idx = np.argmax(api_valid_accs)\n",
    "best_arch = archs[best_idx]\n",
    "if api is not None:\n",
    "    print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd185d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_scale = 1.1\n",
    "\n",
    "if xargs.zero_shot_score.lower() == 'az_nas':\n",
    "    rank_agg = None\n",
    "    l = len(api_flops)\n",
    "    rank_agg = np.log(stats.rankdata(api_flops) / l)\n",
    "    for k in results.keys():\n",
    "        print(k)\n",
    "        if rank_agg is None:\n",
    "            rank_agg = np.log( stats.rankdata(results[k]) / l)\n",
    "        else:\n",
    "            rank_agg = rank_agg + np.log( stats.rankdata(results[k]) / l)\n",
    "\n",
    "\n",
    "    best_idx = np.argmax(rank_agg)\n",
    "\n",
    "    best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "    if api is not None:\n",
    "        print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "\n",
    "    x = stats.rankdata(rank_agg)\n",
    "    y = stats.rankdata(api_valid_accs)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    print(\"aggregated: {}\\t{}\\t{}\\t\".format(kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "    plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "    plt.scatter(x, y, linewidths=0.1)\n",
    "    best_idx = np.argmax(rank_agg)\n",
    "    plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "    plt.title(\"AZ-NAS\")\n",
    "    plt.show()\n",
    "    \n",
    "elif xargs.zero_shot_score.lower() == 'te_nas':\n",
    "    rank_agg = None\n",
    "    for k in results.keys():\n",
    "        print(k)\n",
    "        if rank_agg is None:\n",
    "            rank_agg = stats.rankdata(results[k])\n",
    "        else:\n",
    "            rank_agg = rank_agg + stats.rankdata(results[k])\n",
    "\n",
    "\n",
    "    best_idx = np.argmax(rank_agg)\n",
    "\n",
    "    best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "    if api is not None:\n",
    "        print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "\n",
    "    x = stats.rankdata(rank_agg)\n",
    "    y = stats.rankdata(api_valid_accs)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    print(\"aggregated: {}\\t{}\\t{}\\t\".format(kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "    plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "    plt.scatter(x, y, linewidths=0.1)\n",
    "    best_idx = np.argmax(rank_agg)\n",
    "    plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "    plt.title(\"Rank_agg_te_nas\")\n",
    "    plt.show()\n",
    "\n",
    "# for each\n",
    "# metrics = {'FLOPs':api_flops, 'Params':api_params}\n",
    "metrics = {}\n",
    "for k, v in results.items():\n",
    "    metrics[k] = v\n",
    "\n",
    "    print(k)\n",
    "    best_idx = np.argmax(v)\n",
    "\n",
    "    best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "    if api is not None:\n",
    "        print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "\n",
    "for k in metrics.keys():\n",
    "    x = stats.rankdata(metrics[k])\n",
    "    y = stats.rankdata(api_valid_accs)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    print(\"{}: {}\\t{}\\t{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "    plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "    plt.scatter(x, y, linewidths=0.1)\n",
    "    best_idx = np.argmax(metrics[k])\n",
    "    plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "    plt.title(\"Rank_{}\".format(k))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "# import seaborn as sn\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import copy\n",
    "\n",
    "# metrics = copy.deepcopy(results)\n",
    "\n",
    "# metrics['accuracy'] = api_valid_accs\n",
    "# metrics['complexity'] = api_flops\n",
    "\n",
    "# # keys = ['accuracy', 'expressivity', 'progressivity', 'trainability', 'complexity']\n",
    "# # key_names = ['Acc.', r\"$s^{\\mathcal{E}}$\", r\"$s^{\\mathcal{P}}$\", r\"$s^{\\mathcal{T}}$\", r\"$s^{\\mathcal{C}}$\"]\n",
    "# keys = ['expressivity', 'progressivity', 'trainability', 'complexity']\n",
    "# key_names = [r\"$s^{\\mathcal{E}}$\", r\"$s^{\\mathcal{P}}$\", r\"$s^{\\mathcal{T}}$\", r\"$s^{\\mathcal{C}}$\"]\n",
    "# print(keys)\n",
    "\n",
    "# matrix = np.zeros((len(keys),len(keys)))\n",
    "\n",
    "# for i in range(len(keys)):\n",
    "#     for j in range(len(keys)):\n",
    "#         x = stats.rankdata(metrics[keys[i]])\n",
    "#         y = stats.rankdata(metrics[keys[j]])\n",
    "#         kendalltau = stats.kendalltau(x, y)[0]\n",
    "#         matrix[i,j] = kendalltau\n",
    "\n",
    "# print(matrix)\n",
    "        \n",
    "# df_cm = pd.DataFrame(matrix, index = [i for i in key_names], columns = [i for i in key_names])\n",
    "# plt.figure(figsize=(6,3))\n",
    "# sn.set(font_scale=1.9) # for label size\n",
    "# ax = sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 17}, cmap='GnBu') # font size\n",
    "# cbar = ax.collections[0].colorbar\n",
    "# cbar.ax.tick_params(labelsize=16)\n",
    "# plt.yticks(rotation=0) \n",
    "# plt.savefig('confusion_matrix.pdf', bbox_inches = 'tight', pad_inches = 0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c638e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Visualize\n",
    "def visualize_proxy_cmap(x, y, title, save_name, ref_rank=None):\n",
    "    if ref_rank is None:\n",
    "        ref_rank = x\n",
    "    plt.figure(figsize=(4.5*1.5,3*1.5))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.scatter(x,y, linewidths=0.1, c=ref_rank, cmap='viridis_r')\n",
    "    plt.xlabel(\"Predicted network ranking\", fontsize=16)\n",
    "    plt.ylabel(\"Ground-truth network ranking\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.colorbar()\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.savefig('{}.pdf'.format(save_name), bbox_inches = 'tight', pad_inches = 0)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_proxy(x, y, title, save_name):\n",
    "    plt.figure(figsize=(3.8*1.5,3*1.5))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.scatter(x,y, linewidths=0.1, c=\"#140c86\")\n",
    "    plt.xlabel(\"Predicted network ranking\", fontsize=16)\n",
    "    plt.ylabel(\"Ground-truth network ranking\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.savefig('{}.pdf'.format(save_name), bbox_inches = 'tight', pad_inches = 0)\n",
    "    plt.show()\n",
    "\n",
    "if xargs.zero_shot_score.lower() == 'az_nas':\n",
    "    rank_agg = None\n",
    "    l = len(api_flops)\n",
    "    rank_agg = np.log(stats.rankdata(api_flops) / l)\n",
    "    for k in results.keys():\n",
    "        print(k)\n",
    "        if rank_agg is None:\n",
    "            rank_agg = np.log( stats.rankdata(results[k]) / l)\n",
    "        else:\n",
    "            rank_agg = rank_agg + np.log( stats.rankdata(results[k]) / l)\n",
    "\n",
    "\n",
    "    best_idx = np.argmax(rank_agg)\n",
    "\n",
    "    best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "    if api is not None:\n",
    "        print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "\n",
    "    x = stats.rankdata(rank_agg)\n",
    "    x_agg = x\n",
    "    y = stats.rankdata(api_valid_accs)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    visualize_proxy(x,y,r\"AZ-NAS ($\\tau$={0:.3f}, $\\rho$={1:.3f})\".format(kendalltau[0], spearmanr[0]), 'AZ-NAS_comp')\n",
    "    visualize_proxy_cmap(x,y,r\"AZ-NAS ($\\tau$={0:.3f}, $\\rho$={1:.3f})\".format(kendalltau[0], spearmanr[0]), 'AZ-NAS')\n",
    "    \n",
    "    metrics = {'FLOPs':api_flops}\n",
    "    for k, v in results.items():\n",
    "        metrics[k] = v\n",
    "\n",
    "        print(k)\n",
    "        best_idx = np.argmax(v)\n",
    "\n",
    "        best_arch, acc = archs[best_idx], api_valid_accs[best_idx]\n",
    "        if api is not None:\n",
    "            print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "    title_names = {\"expressivity\":\"Expressivity\",\"progressivity\":\"Progressivity\",\"trainability\":\"Trainability\",\"FLOPs\":\"Complexity\"}\n",
    "    for k in metrics.keys():\n",
    "        x = stats.rankdata(metrics[k])\n",
    "        y = stats.rankdata(api_valid_accs)\n",
    "        kendalltau = stats.kendalltau(x, y)\n",
    "        spearmanr = stats.spearmanr(x, y)\n",
    "        pearsonr = stats.pearsonr(x, y)\n",
    "        visualize_proxy_cmap(x,y,r\"{0} ($\\tau$={1:.3f}, $\\rho$={2:.3f})\".format(title_names[k],kendalltau[0], spearmanr[0]),title_names[k],x_agg)\n",
    "        \n",
    "elif xargs.zero_shot_score.lower() == 'te_nas':\n",
    "    title_names = {\"te_nas\":\"TE-NAS\"}\n",
    "    rank_agg = None\n",
    "    for k in results.keys():\n",
    "        print(k)\n",
    "        if rank_agg is None:\n",
    "            rank_agg = stats.rankdata(results[k])\n",
    "        else:\n",
    "            rank_agg = rank_agg + stats.rankdata(results[k])\n",
    "    x = stats.rankdata(rank_agg)\n",
    "    y = stats.rankdata(api_valid_accs)\n",
    "    kendalltau = stats.kendalltau(x, y)\n",
    "    spearmanr = stats.spearmanr(x, y)\n",
    "    pearsonr = stats.pearsonr(x, y)\n",
    "    visualize_proxy(x,y,r\"{0} ($\\tau$={1:.3f}, $\\rho$={2:.3f})\".format(title_names['te_nas'],kendalltau[0], spearmanr[0]),title_names['te_nas'])\n",
    "        \n",
    "else:\n",
    "    title_names = {\"zico\":\"ZiCo\",\"zen\":\"ZenNAS\",'params':\"#Params\",'naswot':\"NASWOT\",\"synflow\":\"Synflow\",\"gradsign\":\"GradSign\"}\n",
    "    for k in results.keys():\n",
    "        print(k)\n",
    "        x = stats.rankdata(results[k])\n",
    "        y = stats.rankdata(api_valid_accs)\n",
    "        kendalltau = stats.kendalltau(x, y)\n",
    "        spearmanr = stats.spearmanr(x, y)\n",
    "        pearsonr = stats.pearsonr(x, y)\n",
    "        visualize_proxy(x,y,r\"{0} ($\\tau$={1:.3f}, $\\rho$={2:.3f})\".format(title_names[k],kendalltau[0], spearmanr[0]),title_names[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e525a88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Ablation study\n",
    "\n",
    "# ##############################################################################\n",
    "# # for each vs acc\n",
    "# for k in results.keys():\n",
    "#     x = stats.rankdata(results[k])\n",
    "#     y = stats.rankdata(api_valid_accs)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{} vs. Acc: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{} vs. Acc\".format(k))\n",
    "#     plt.show()\n",
    "    \n",
    "# # for each+params vs acc\n",
    "# for k in results.keys():\n",
    "#     l = len(results[k])\n",
    "#     x = np.log(stats.rankdata(results[k])/l) + np.log(stats.rankdata(api_params)/l)\n",
    "#     x = stats.rankdata(x)\n",
    "#     y = stats.rankdata(api_valid_accs)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{}+Params vs. Acc: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{}+Params vs. Acc\".format(k))\n",
    "#     plt.show()\n",
    "    \n",
    "# # for each+params vs acc\n",
    "# for k in results.keys():\n",
    "#     l = len(results[k])\n",
    "#     x = np.log(stats.rankdata(results[k])/l) + np.log(stats.rankdata(api_flops)/l)\n",
    "#     x = stats.rankdata(x)\n",
    "#     y = stats.rankdata(api_valid_accs)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{}+FLOPs vs. Acc: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{}+FLOPs vs. Acc\".format(k))\n",
    "#     plt.show()\n",
    "\n",
    "# ##############################################################################\n",
    "# # for each vs flops\n",
    "# for k in results.keys():\n",
    "#     x = stats.rankdata(results[k])\n",
    "#     y = stats.rankdata(api_flops)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{} vs. FLOPs: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{} vs. FLOPs\".format(k))\n",
    "#     plt.show()\n",
    "    \n",
    "# # for each+params vs flops\n",
    "# for k in results.keys():\n",
    "#     l = len(results[k])\n",
    "#     x = np.log(stats.rankdata(results[k])/l) + np.log(stats.rankdata(api_params)/l)\n",
    "#     x = stats.rankdata(x)\n",
    "#     y = stats.rankdata(api_flops)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{}+Params vs. FLOPs: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{}+Params vs. FLOPs\".format(k))\n",
    "#     plt.show()\n",
    "    \n",
    "# # for each+flops vs flops\n",
    "# for k in results.keys():\n",
    "#     l = len(results[k])\n",
    "#     x = np.log(stats.rankdata(results[k])/l) + np.log(stats.rankdata(api_flops)/l)\n",
    "#     x = stats.rankdata(x)\n",
    "#     y = stats.rankdata(api_flops)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{}+FLOPs vs. FLOPs: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{}+FLOPs vs. FLOPs\".format(k))\n",
    "#     plt.show()\n",
    "\n",
    "# ##############################################################################\n",
    "# # for each vs params\n",
    "# for k in results.keys():\n",
    "#     x = stats.rankdata(results[k])\n",
    "#     y = stats.rankdata(api_params)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{} vs. Params: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{} vs. Params\".format(k))\n",
    "#     plt.show()\n",
    "    \n",
    "# # for each+params vs params\n",
    "# for k in results.keys():\n",
    "#     l = len(results[k])\n",
    "#     x = np.log(stats.rankdata(results[k])/l) + np.log(stats.rankdata(api_params)/l)\n",
    "#     x = stats.rankdata(x)\n",
    "#     y = stats.rankdata(api_params)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{}+Params vs. Params: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{}+Params vs. Params\".format(k))\n",
    "#     plt.show()\n",
    "    \n",
    "# # for each+flops vs params\n",
    "# for k in results.keys():\n",
    "#     l = len(results[k])\n",
    "#     x = np.log(stats.rankdata(results[k])/l) + np.log(stats.rankdata(api_flops)/l)\n",
    "#     x = stats.rankdata(x)\n",
    "#     y = stats.rankdata(api_params)\n",
    "#     kendalltau = stats.kendalltau(x, y)\n",
    "#     spearmanr = stats.spearmanr(x, y)\n",
    "#     pearsonr = stats.pearsonr(x, y)\n",
    "#     print(\"{}+FLOPs vs. Params: KT-{}\\tPCC-{}\\tSPR-{}\\t\".format(k, kendalltau[0], pearsonr[0], spearmanr[0]))\n",
    "#     plt.figure(figsize=(4*fig_scale,3*fig_scale))\n",
    "#     plt.scatter(x, y, linewidths=0.1)\n",
    "#     best_idx = np.argmax(results[k])\n",
    "#     plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=0.1)\n",
    "#     plt.title(\"{}+FLOPs vs. Params\".format(k))\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
