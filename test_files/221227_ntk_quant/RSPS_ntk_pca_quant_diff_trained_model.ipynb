{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15198afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# XAutoDL \n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_search_spaces\n",
    "\n",
    "# NB201\n",
    "from nas_201_api import NASBench201API as API\n",
    "\n",
    "from ntk import get_ntk_n\n",
    "from linear_region_counter import Linear_Region_Collector\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# custom\n",
    "from custom_models import get_cell_based_tiny_net\n",
    "from custom_modules import QConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "392dc080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76322\n",
      "Namespace(arch_nas_dataset='../../NAS-Bench-201-v1_1-096897.pth', channel=3, config_path='../../configs/nas-benchmark/algos/RANDOM.config', data_path='../../cifar.python', dataset='cifar10', max_nodes=4, num_cells=5, print_freq=50, rand_seed=76322, save_dir='./results/tmp', search_space_name='nas-bench-201', select_num=100, track_running_stats=0, train_config_path='../../configs/nas-benchmark/CIFAR.config', workers=0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Random search for NAS.\")\n",
    "parser.add_argument(\"--data_path\", type=str, default='../../cifar.python', help=\"The path to dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='cifar10',choices=[\"cifar10\", \"cifar100\", \"ImageNet16-120\"], help=\"Choose between Cifar10/100 and ImageNet-16.\")\n",
    "\n",
    "# channels and number-of-cells\n",
    "parser.add_argument(\"--search_space_name\", type=str, default='nas-bench-201', help=\"The search space name.\")\n",
    "parser.add_argument(\"--config_path\", type=str, default='../../configs/nas-benchmark/algos/RANDOM.config', help=\"The path to the configuration.\")\n",
    "parser.add_argument(\"--max_nodes\", type=int, default=4, help=\"The maximum number of nodes.\")\n",
    "# parser.add_argument(\"--channel\", type=int, default=16, help=\"The number of channels.\")\n",
    "parser.add_argument(\"--num_cells\", type=int, default=5, help=\"The number of cells in one stage.\")\n",
    "parser.add_argument(\"--channel\", type=int, default=3, help=\"The number of channels.\")\n",
    "# parser.add_argument(\"--num_cells\", type=int, default=1, help=\"The number of cells in one stage.\")\n",
    "parser.add_argument(\"--select_num\", type=int, default=100, help=\"The number of selected architectures to evaluate.\")\n",
    "parser.add_argument(\"--track_running_stats\", type=int, default=0, choices=[0, 1], help=\"Whether use track_running_stats or not in the BN layer.\")\n",
    "# log\n",
    "parser.add_argument(\"--workers\", type=int, default=0, help=\"number of data loading workers\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./results/tmp', help=\"Folder to save checkpoints and log.\")\n",
    "parser.add_argument(\"--arch_nas_dataset\", type=str, default='../../NAS-Bench-201-v1_1-096897.pth', help=\"The path to load the architecture dataset (tiny-nas-benchmark).\")\n",
    "parser.add_argument(\"--print_freq\", type=int, default=50, help=\"print frequency (default: 200)\")\n",
    "parser.add_argument(\"--rand_seed\", type=int, default=None, help=\"manual seed\")\n",
    "\n",
    "parser.add_argument(\"--train_config_path\", type=str, default='../../configs/nas-benchmark/CIFAR.config', help=\"The path to the configuration.\")\n",
    "args = parser.parse_args(args=[])\n",
    "if args.rand_seed is None or args.rand_seed < 0:\n",
    "    args.rand_seed = random.randint(1, 100000)\n",
    "\n",
    "    \n",
    "print(args.rand_seed)\n",
    "print(args)\n",
    "xargs=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f83abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=results/tmp, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "arch_nas_dataset : ../../NAS-Bench-201-v1_1-096897.pth\n",
      "channel          : 16\n",
      "config_path      : ../../configs/nas-benchmark/algos/RANDOM.config\n",
      "data_path        : ../../cifar.python\n",
      "dataset          : cifar10\n",
      "max_nodes        : 4\n",
      "num_cells        : 5\n",
      "print_freq       : 50\n",
      "rand_seed        : 85864\n",
      "save_dir         : ./results/tmp\n",
      "search_space_name : nas-bench-201\n",
      "select_num       : 100\n",
      "track_running_stats : 0\n",
      "train_config_path : ../../configs/nas-benchmark/CIFAR.config\n",
      "workers          : 0\n",
      "Python  Version  : 3.8.8 (default, Feb 24 2021, 21:46:12)  [GCC 7.3.0]\n",
      "Pillow  Version  : 8.1.2\n",
      "PyTorch Version  : 1.8.1\n",
      "cuDNN   Version  : 8005\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CUDA is not available.\"\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# torch.set_num_threads(xargs.workers)\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631f8ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM-NAS finds the best one : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|avg_pool_3x3~0|nor_conv_3x3~1|nor_conv_3x3~2|) with ntk_score=-163.105349222819, lr_score=300.0\n",
      "184.73025 1.288506\n",
      "\n",
      "\n",
      "\n",
      "Call query_info_str_by_arch with arch=Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|avg_pool_3x3~0|nor_conv_3x3~1|nor_conv_3x3~2|) and hp=200\n",
      "Call query_index_by_arch with arch=Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|avg_pool_3x3~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|avg_pool_3x3~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=13403\n",
      "cifar10-valid  FLOP=184.73 M, Params=1.289 MB, latency=20.98 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.495, top1 = 90.41%]\n",
      "cifar10        FLOP=184.73 M, Params=1.289 MB, latency=20.98 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.345, top1 = 93.34%]\n",
      "cifar100       FLOP=184.74 M, Params=1.294 MB, latency=22.87 ms.\n",
      "cifar100       train : [loss = 0.017, top1 = 99.89%], valid : [loss = 1.357, top1 = 71.49%], test : [loss = 1.340, top1 = 71.85%]\n",
      "ImageNet16-120 FLOP= 46.19 M, Params=1.296 MB, latency=20.74 ms.\n",
      "ImageNet16-120 train : [loss = 1.362, top1 = 62.88%], valid : [loss = 2.412, top1 = 42.48%], test : [loss = 2.443, top1 = 42.38%]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6811262981586923 3.562602824939169e-228\n"
     ]
    }
   ],
   "source": [
    "if 'api' not in vars():\n",
    "    if args.arch_nas_dataset is None:\n",
    "        api = None\n",
    "    else:\n",
    "        api = API(xargs.arch_nas_dataset)\n",
    "\n",
    "fp_results = torch.load(\"./c3n5_1000samples.pth\")\n",
    "archs = fp_results['archs']\n",
    "fp_ntk_scores = fp_results['ntk_scores']\n",
    "fp_lr_scores = fp_results['lr_scores']\n",
    "api_valid_accs = fp_results['api_valid_accs']\n",
    "api_flops = fp_results['api_flops']\n",
    "api_params = fp_results['api_params']\n",
    "\n",
    "rank_ntk, rank_lr, rank_flops, rank_params = stats.rankdata(fp_ntk_scores), stats.rankdata(fp_lr_scores), stats.rankdata(api_flops), stats.rankdata(api_params)\n",
    "\n",
    "l = len(fp_ntk_scores)\n",
    "\n",
    "rank_agg = np.log(rank_ntk/l) + np.log(rank_lr/l) + np.log(rank_flops/l)\n",
    "\n",
    "\n",
    "best_idx = np.argmax(rank_agg)\n",
    "best_arch, best_ntk_score, best_lr_score, flops, params = archs[best_idx], fp_ntk_scores[best_idx], fp_lr_scores[best_idx], api_flops[best_idx], api_params[best_idx]\n",
    "\n",
    "print(\"RANDOM-NAS finds the best one : {:} with ntk_score={:}, lr_score={:}\".format(best_arch, best_ntk_score, best_lr_score))\n",
    "print(flops, params)\n",
    "print(\"\\n\\n\")\n",
    "if api is not None:\n",
    "    print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "x = stats.rankdata(rank_agg)\n",
    "y = stats.rankdata(api_valid_accs)\n",
    "# y = api_valid_accs\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=4)\n",
    "plt.title(\"rank_agg\")\n",
    "plt.show()\n",
    "tau, p_value = stats.kendalltau(x, y)\n",
    "print(tau, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae311519",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937a003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_one_arch(xloader, network, criterion, scheduler, w_optimizer, epoch_str, print_freq, logger):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.train()\n",
    "    end = time.time()\n",
    "    for step, (base_inputs, base_targets) in enumerate(\n",
    "        xloader\n",
    "    ):\n",
    "        scheduler.update(None, 1.0 * step / len(xloader))\n",
    "        base_inputs = base_inputs.cuda(non_blocking=True)\n",
    "        base_targets = base_targets.cuda(non_blocking=True)\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        _, logits = network(base_inputs)\n",
    "        base_loss = criterion(logits, base_targets)\n",
    "        base_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "        w_optimizer.step()\n",
    "        # record\n",
    "        base_prec1, base_prec5 = obtain_accuracy(\n",
    "            logits.data, base_targets.data, topk=(1, 5)\n",
    "        )\n",
    "        base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "        base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "        base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % print_freq == 0 or step + 1 == len(xloader):\n",
    "            Sstr = (\n",
    "                \"*SEARCH* \"\n",
    "                + time_string()\n",
    "                + \" [{:}][{:03d}/{:03d}]\".format(epoch_str, step, len(xloader))\n",
    "            )\n",
    "            Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(\n",
    "                batch_time=batch_time, data_time=data_time\n",
    "            )\n",
    "            Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(\n",
    "                loss=base_losses, top1=base_top1, top5=base_top5\n",
    "            )\n",
    "            logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "    return base_losses.avg, base_top1.avg, base_top5.avg\n",
    "\n",
    "def valid_func_one_arch(xloader, network, criterion):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.eval()\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for step, (arch_inputs, arch_targets) in enumerate(xloader):\n",
    "            arch_inputs = arch_inputs.cuda(non_blocking=True)\n",
    "            arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            # prediction\n",
    "\n",
    "            _, logits = network(arch_inputs)\n",
    "            arch_loss = criterion(logits, arch_targets)\n",
    "            # record\n",
    "            arch_prec1, arch_prec5 = obtain_accuracy(\n",
    "                logits.data, arch_targets.data, topk=(1, 5)\n",
    "            )\n",
    "            arch_losses.update(arch_loss.item(), arch_inputs.size(0))\n",
    "            arch_top1.update(arch_prec1.item(), arch_inputs.size(0))\n",
    "            arch_top5.update(arch_prec5.item(), arch_inputs.size(0))\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "    return arch_losses.avg, arch_top1.avg, arch_top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab972e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=results/tmp/train_w32_a32, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "arch_nas_dataset : ../../NAS-Bench-201-v1_1-096897.pth\n",
      "channel          : 3\n",
      "config_path      : ../../configs/nas-benchmark/algos/RANDOM.config\n",
      "data_path        : ../../cifar.python\n",
      "dataset          : cifar10\n",
      "max_nodes        : 4\n",
      "num_cells        : 5\n",
      "print_freq       : 50\n",
      "rand_seed        : 68245\n",
      "save_dir         : ./results/tmp/train_w32_a32\n",
      "search_space_name : nas-bench-201\n",
      "select_num       : 100\n",
      "track_running_stats : 0\n",
      "train_config_path : ../../configs/nas-benchmark/CIFAR.config\n",
      "workers          : 16\n",
      "Python  Version  : 3.8.8 (default, Feb 24 2021, 21:46:12)  [GCC 7.3.0]\n",
      "Pillow  Version  : 8.1.2\n",
      "PyTorch Version  : 1.8.1\n",
      "cuDNN   Version  : 8005\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "../../configs/nas-benchmark/CIFAR.config\n",
      "Configure(scheduler='cos', eta_min=0.0, epochs=200, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Train-Loader-Num=196, Test-Loader-Num=40, batch size=256\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', eta_min=0.0, epochs=200, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=10, xshape=(1, 3, 32, 32))\n",
      "\n",
      "[Search the 000-200-th epoch] Time Left: [00:00:00], LR=0.1\n",
      "*SEARCH* [2023-01-09 07:14:22] [000-200][000/196] Time 6.13 (6.13) Data 5.40 (5.40) Base [Loss 2.336 (2.336)  Prec@1 9.38 (9.38) Prec@5 54.30 (54.30)]\n",
      "*SEARCH* [2023-01-09 07:14:38] [000-200][050/196] Time 0.31 (0.42) Data 0.00 (0.11) Base [Loss 1.991 (2.087)  Prec@1 25.00 (21.38) Prec@5 81.64 (72.05)]\n",
      "*SEARCH* [2023-01-09 07:14:53] [000-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 1.810 (1.982)  Prec@1 32.42 (25.31) Prec@5 82.81 (77.27)]\n",
      "*SEARCH* [2023-01-09 07:15:10] [000-200][150/196] Time 0.36 (0.36) Data 0.00 (0.04) Base [Loss 1.651 (1.912)  Prec@1 41.41 (28.13) Prec@5 89.84 (79.87)]\n",
      "*SEARCH* [2023-01-09 07:15:26] [000-200][195/196] Time 0.17 (0.36) Data 0.00 (0.03) Base [Loss 1.703 (1.861)  Prec@1 37.50 (30.02) Prec@5 91.25 (81.67)]\n",
      "[000-200] searching : loss=1.86, accuracy@1=30.02%, accuracy@5=81.67%, time-cost=70.4 s\n",
      "[000-200] evaluate  : loss=1.66, accuracy@1=38.52%, accuracy@5=88.09%\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 000-200-th epoch : find the highest test accuracy : 38.52%.\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 001-200-th epoch] Time Left: [04:40:04], LR=0.09999383162408304\n",
      "*SEARCH* [2023-01-09 07:15:46] [001-200][000/196] Time 5.48 (5.48) Data 5.11 (5.11) Base [Loss 1.699 (1.699)  Prec@1 37.50 (37.50) Prec@5 85.16 (85.16)]\n",
      "*SEARCH* [2023-01-09 07:16:02] [001-200][050/196] Time 0.32 (0.43) Data 0.00 (0.10) Base [Loss 1.520 (1.634)  Prec@1 42.19 (39.34) Prec@5 91.02 (88.47)]\n",
      "*SEARCH* [2023-01-09 07:16:18] [001-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 1.532 (1.617)  Prec@1 42.97 (39.92) Prec@5 92.19 (89.04)]\n",
      "*SEARCH* [2023-01-09 07:16:34] [001-200][150/196] Time 0.31 (0.35) Data 0.00 (0.03) Base [Loss 1.398 (1.589)  Prec@1 48.05 (41.05) Prec@5 94.14 (89.55)]\n",
      "*SEARCH* [2023-01-09 07:16:48] [001-200][195/196] Time 0.12 (0.34) Data 0.00 (0.03) Base [Loss 1.543 (1.567)  Prec@1 47.50 (42.00) Prec@5 87.50 (90.02)]\n",
      "[001-200] searching : loss=1.57, accuracy@1=42.00%, accuracy@5=90.02%, time-cost=138.5 s\n",
      "[001-200] evaluate  : loss=1.59, accuracy@1=41.76%, accuracy@5=90.01%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 001-200-th epoch : find the highest test accuracy : 41.76%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 002-200-th epoch] Time Left: [04:29:28], LR=0.09997532801828658\n",
      "*SEARCH* [2023-01-09 07:17:08] [002-200][000/196] Time 6.28 (6.28) Data 5.91 (5.91) Base [Loss 1.588 (1.588)  Prec@1 41.41 (41.41) Prec@5 89.45 (89.45)]\n",
      "*SEARCH* [2023-01-09 07:17:24] [002-200][050/196] Time 0.31 (0.43) Data 0.00 (0.12) Base [Loss 1.424 (1.480)  Prec@1 47.27 (45.49) Prec@5 93.75 (91.57)]\n",
      "*SEARCH* [2023-01-09 07:17:40] [002-200][100/196] Time 0.32 (0.37) Data 0.00 (0.06) Base [Loss 1.386 (1.447)  Prec@1 49.61 (46.58) Prec@5 93.36 (92.06)]\n",
      "*SEARCH* [2023-01-09 07:17:55] [002-200][150/196] Time 0.32 (0.35) Data 0.00 (0.04) Base [Loss 1.408 (1.430)  Prec@1 47.66 (47.37) Prec@5 94.14 (92.36)]\n",
      "*SEARCH* [2023-01-09 07:18:09] [002-200][195/196] Time 0.12 (0.34) Data 0.00 (0.03) Base [Loss 1.706 (1.412)  Prec@1 40.00 (48.12) Prec@5 83.75 (92.56)]\n",
      "[002-200] searching : loss=1.41, accuracy@1=48.12%, accuracy@5=92.56%, time-cost=206.4 s\n",
      "[002-200] evaluate  : loss=1.45, accuracy@1=47.68%, accuracy@5=92.67%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 002-200-th epoch : find the highest test accuracy : 47.68%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 003-200-th epoch] Time Left: [04:27:30], LR=0.09994449374809851\n",
      "*SEARCH* [2023-01-09 07:18:30] [003-200][000/196] Time 6.03 (6.03) Data 5.66 (5.66) Base [Loss 1.500 (1.500)  Prec@1 42.19 (42.19) Prec@5 90.23 (90.23)]\n",
      "*SEARCH* [2023-01-09 07:18:45] [003-200][050/196] Time 0.32 (0.43) Data 0.00 (0.11) Base [Loss 1.320 (1.342)  Prec@1 50.78 (51.30) Prec@5 94.53 (93.15)]\n",
      "*SEARCH* [2023-01-09 07:19:01] [003-200][100/196] Time 0.31 (0.37) Data 0.00 (0.06) Base [Loss 1.261 (1.320)  Prec@1 51.95 (52.20) Prec@5 93.75 (93.46)]\n",
      "*SEARCH* [2023-01-09 07:19:17] [003-200][150/196] Time 0.32 (0.35) Data 0.00 (0.04) Base [Loss 1.203 (1.308)  Prec@1 53.12 (52.37) Prec@5 92.58 (93.65)]\n",
      "*SEARCH* [2023-01-09 07:19:31] [003-200][195/196] Time 0.12 (0.34) Data 0.00 (0.03) Base [Loss 1.250 (1.295)  Prec@1 50.00 (52.91) Prec@5 98.75 (93.80)]\n",
      "[003-200] searching : loss=1.29, accuracy@1=52.91%, accuracy@5=93.80%, time-cost=274.4 s\n",
      "[003-200] evaluate  : loss=1.29, accuracy@1=53.43%, accuracy@5=94.20%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 003-200-th epoch : find the highest test accuracy : 53.43%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 004-200-th epoch] Time Left: [04:32:43], LR=0.09990133642141358\n",
      "*SEARCH* [2023-01-09 07:19:53] [004-200][000/196] Time 5.81 (5.81) Data 5.43 (5.43) Base [Loss 1.284 (1.284)  Prec@1 55.08 (55.08) Prec@5 92.19 (92.19)]\n",
      "*SEARCH* [2023-01-09 07:20:09] [004-200][050/196] Time 0.32 (0.42) Data 0.00 (0.11) Base [Loss 1.198 (1.213)  Prec@1 57.81 (56.01) Prec@5 94.14 (94.91)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 07:20:24] [004-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 1.126 (1.214)  Prec@1 59.77 (56.16) Prec@5 94.92 (94.80)]\n",
      "*SEARCH* [2023-01-09 07:20:40] [004-200][150/196] Time 0.32 (0.35) Data 0.00 (0.04) Base [Loss 1.195 (1.205)  Prec@1 58.20 (56.45) Prec@5 93.36 (94.81)]\n",
      "*SEARCH* [2023-01-09 07:20:54] [004-200][195/196] Time 0.12 (0.34) Data 0.00 (0.03) Base [Loss 0.944 (1.200)  Prec@1 62.50 (56.67) Prec@5 100.00 (94.89)]\n",
      "[004-200] searching : loss=1.20, accuracy@1=56.67%, accuracy@5=94.89%, time-cost=342.8 s\n",
      "[004-200] evaluate  : loss=1.24, accuracy@1=55.00%, accuracy@5=94.74%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 004-200-th epoch : find the highest test accuracy : 55.00%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 005-200-th epoch] Time Left: [04:32:45], LR=0.0998458666866564\n",
      "*SEARCH* [2023-01-09 07:21:17] [005-200][000/196] Time 5.64 (5.64) Data 5.23 (5.23) Base [Loss 1.104 (1.104)  Prec@1 62.89 (62.89) Prec@5 94.92 (94.92)]\n",
      "*SEARCH* [2023-01-09 07:21:32] [005-200][050/196] Time 0.32 (0.42) Data 0.00 (0.10) Base [Loss 1.224 (1.156)  Prec@1 58.20 (58.69) Prec@5 96.48 (95.44)]\n",
      "*SEARCH* [2023-01-09 07:21:48] [005-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 1.191 (1.156)  Prec@1 57.42 (58.49) Prec@5 94.14 (95.35)]\n",
      "*SEARCH* [2023-01-09 07:22:04] [005-200][150/196] Time 0.35 (0.35) Data 0.00 (0.03) Base [Loss 1.091 (1.141)  Prec@1 58.20 (58.94) Prec@5 95.70 (95.48)]\n",
      "*SEARCH* [2023-01-09 07:22:19] [005-200][195/196] Time 0.14 (0.35) Data 0.00 (0.03) Base [Loss 0.989 (1.135)  Prec@1 57.50 (59.05) Prec@5 100.00 (95.55)]\n",
      "[005-200] searching : loss=1.14, accuracy@1=59.05%, accuracy@5=95.55%, time-cost=411.5 s\n",
      "[005-200] evaluate  : loss=1.16, accuracy@1=57.99%, accuracy@5=95.42%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 005-200-th epoch : find the highest test accuracy : 57.99%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 006-200-th epoch] Time Left: [04:25:00], LR=0.099778098230154\n",
      "*SEARCH* [2023-01-09 07:22:38] [006-200][000/196] Time 4.87 (4.87) Data 4.47 (4.47) Base [Loss 1.106 (1.106)  Prec@1 58.59 (58.59) Prec@5 96.09 (96.09)]\n",
      "*SEARCH* [2023-01-09 07:22:54] [006-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 1.107 (1.094)  Prec@1 59.77 (60.05) Prec@5 96.88 (96.19)]\n",
      "*SEARCH* [2023-01-09 07:23:11] [006-200][100/196] Time 0.33 (0.38) Data 0.00 (0.04) Base [Loss 1.082 (1.097)  Prec@1 63.67 (60.18) Prec@5 94.14 (95.92)]\n",
      "*SEARCH* [2023-01-09 07:23:28] [006-200][150/196] Time 0.36 (0.37) Data 0.00 (0.03) Base [Loss 1.113 (1.085)  Prec@1 61.33 (60.85) Prec@5 95.70 (95.93)]\n",
      "*SEARCH* [2023-01-09 07:23:44] [006-200][195/196] Time 0.15 (0.36) Data 0.00 (0.02) Base [Loss 0.981 (1.085)  Prec@1 62.50 (60.84) Prec@5 97.50 (95.96)]\n",
      "[006-200] searching : loss=1.08, accuracy@1=60.84%, accuracy@5=95.96%, time-cost=483.4 s\n",
      "[006-200] evaluate  : loss=1.19, accuracy@1=57.60%, accuracy@5=95.21%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 007-200-th epoch] Time Left: [04:32:35], LR=0.099698047772759\n",
      "*SEARCH* [2023-01-09 07:24:02] [007-200][000/196] Time 4.71 (4.71) Data 4.32 (4.32) Base [Loss 1.019 (1.019)  Prec@1 64.84 (64.84) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:24:18] [007-200][050/196] Time 0.32 (0.40) Data 0.00 (0.08) Base [Loss 1.026 (1.063)  Prec@1 59.38 (61.60) Prec@5 96.88 (96.38)]\n",
      "*SEARCH* [2023-01-09 07:24:35] [007-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 1.029 (1.054)  Prec@1 63.28 (62.10) Prec@5 96.09 (96.50)]\n",
      "*SEARCH* [2023-01-09 07:24:51] [007-200][150/196] Time 0.33 (0.35) Data 0.00 (0.03) Base [Loss 0.959 (1.047)  Prec@1 66.41 (62.38) Prec@5 96.88 (96.50)]\n",
      "*SEARCH* [2023-01-09 07:25:06] [007-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.988 (1.048)  Prec@1 63.75 (62.40) Prec@5 98.75 (96.44)]\n",
      "[007-200] searching : loss=1.05, accuracy@1=62.40%, accuracy@5=96.44%, time-cost=552.5 s\n",
      "[007-200] evaluate  : loss=1.13, accuracy@1=59.45%, accuracy@5=96.00%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 007-200-th epoch : find the highest test accuracy : 59.45%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 008-200-th epoch] Time Left: [04:23:44], LR=0.0996057350657239\n",
      "*SEARCH* [2023-01-09 07:25:25] [008-200][000/196] Time 4.95 (4.95) Data 4.53 (4.53) Base [Loss 1.104 (1.104)  Prec@1 59.77 (59.77) Prec@5 95.70 (95.70)]\n",
      "*SEARCH* [2023-01-09 07:25:42] [008-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 0.863 (1.029)  Prec@1 69.92 (63.30) Prec@5 97.66 (96.35)]\n",
      "*SEARCH* [2023-01-09 07:25:58] [008-200][100/196] Time 0.33 (0.38) Data 0.00 (0.05) Base [Loss 1.018 (1.022)  Prec@1 64.45 (63.35) Prec@5 97.27 (96.43)]\n",
      "*SEARCH* [2023-01-09 07:26:15] [008-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 1.054 (1.016)  Prec@1 64.06 (63.53) Prec@5 94.53 (96.46)]\n",
      "*SEARCH* [2023-01-09 07:26:29] [008-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 1.051 (1.013)  Prec@1 62.50 (63.61) Prec@5 96.25 (96.50)]\n",
      "[008-200] searching : loss=1.01, accuracy@1=63.61%, accuracy@5=96.50%, time-cost=622.4 s\n",
      "[008-200] evaluate  : loss=1.06, accuracy@1=62.31%, accuracy@5=96.07%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 008-200-th epoch : find the highest test accuracy : 62.31%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 009-200-th epoch] Time Left: [04:29:10], LR=0.09950118288582788\n",
      "*SEARCH* [2023-01-09 07:26:49] [009-200][000/196] Time 4.80 (4.80) Data 4.39 (4.39) Base [Loss 0.965 (0.965)  Prec@1 66.80 (66.80) Prec@5 96.88 (96.88)]\n",
      "*SEARCH* [2023-01-09 07:27:06] [009-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 1.041 (0.987)  Prec@1 60.94 (64.58) Prec@5 98.05 (97.00)]\n",
      "*SEARCH* [2023-01-09 07:27:22] [009-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.996 (0.990)  Prec@1 66.41 (64.53) Prec@5 97.66 (96.93)]\n",
      "*SEARCH* [2023-01-09 07:27:38] [009-200][150/196] Time 0.33 (0.35) Data 0.00 (0.03) Base [Loss 1.008 (0.994)  Prec@1 64.84 (64.25) Prec@5 96.48 (96.86)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 07:27:53] [009-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.809 (0.988)  Prec@1 72.50 (64.48) Prec@5 97.50 (96.87)]\n",
      "[009-200] searching : loss=0.99, accuracy@1=64.48%, accuracy@5=96.87%, time-cost=691.2 s\n",
      "[009-200] evaluate  : loss=1.08, accuracy@1=61.70%, accuracy@5=96.00%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 010-200-th epoch] Time Left: [04:19:29], LR=0.0993844170297569\n",
      "*SEARCH* [2023-01-09 07:28:11] [010-200][000/196] Time 4.62 (4.62) Data 4.23 (4.23) Base [Loss 0.998 (0.998)  Prec@1 64.06 (64.06) Prec@5 93.75 (93.75)]\n",
      "*SEARCH* [2023-01-09 07:28:28] [010-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 1.021 (0.973)  Prec@1 64.45 (65.08) Prec@5 97.66 (96.80)]\n",
      "*SEARCH* [2023-01-09 07:28:43] [010-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 1.026 (0.970)  Prec@1 61.72 (65.01) Prec@5 96.88 (96.83)]\n",
      "*SEARCH* [2023-01-09 07:29:00] [010-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.963 (0.972)  Prec@1 64.84 (65.08) Prec@5 97.27 (96.86)]\n",
      "*SEARCH* [2023-01-09 07:29:14] [010-200][195/196] Time 0.12 (0.34) Data 0.00 (0.02) Base [Loss 0.765 (0.969)  Prec@1 70.00 (65.23) Prec@5 100.00 (96.86)]\n",
      "[010-200] searching : loss=0.97, accuracy@1=65.23%, accuracy@5=96.86%, time-cost=759.2 s\n",
      "[010-200] evaluate  : loss=1.04, accuracy@1=63.58%, accuracy@5=96.46%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 010-200-th epoch : find the highest test accuracy : 63.58%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 011-200-th epoch] Time Left: [04:16:09], LR=0.0992554663077387\n",
      "*SEARCH* [2023-01-09 07:29:33] [011-200][000/196] Time 4.93 (4.93) Data 4.55 (4.55) Base [Loss 0.982 (0.982)  Prec@1 61.33 (61.33) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 07:29:49] [011-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 0.966 (0.952)  Prec@1 62.89 (66.17) Prec@5 98.83 (97.25)]\n",
      "*SEARCH* [2023-01-09 07:30:06] [011-200][100/196] Time 0.32 (0.38) Data 0.00 (0.05) Base [Loss 0.927 (0.952)  Prec@1 68.36 (66.06) Prec@5 97.27 (97.14)]\n",
      "*SEARCH* [2023-01-09 07:30:22] [011-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.971 (0.947)  Prec@1 62.11 (66.10) Prec@5 98.05 (97.06)]\n",
      "*SEARCH* [2023-01-09 07:30:36] [011-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 1.082 (0.950)  Prec@1 58.75 (66.01) Prec@5 96.25 (97.08)]\n",
      "[011-200] searching : loss=0.95, accuracy@1=66.01%, accuracy@5=97.08%, time-cost=828.3 s\n",
      "[011-200] evaluate  : loss=1.05, accuracy@1=62.68%, accuracy@5=96.47%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 012-200-th epoch] Time Left: [04:19:51], LR=0.09911436253643445\n",
      "*SEARCH* [2023-01-09 07:30:55] [012-200][000/196] Time 4.62 (4.62) Data 4.22 (4.22) Base [Loss 0.944 (0.944)  Prec@1 64.84 (64.84) Prec@5 96.88 (96.88)]\n",
      "*SEARCH* [2023-01-09 07:31:12] [012-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 0.960 (0.925)  Prec@1 69.14 (66.94) Prec@5 97.27 (97.38)]\n",
      "*SEARCH* [2023-01-09 07:31:28] [012-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.921 (0.932)  Prec@1 66.02 (66.75) Prec@5 96.48 (97.31)]\n",
      "*SEARCH* [2023-01-09 07:31:45] [012-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.896 (0.937)  Prec@1 66.80 (66.53) Prec@5 98.05 (97.28)]\n",
      "*SEARCH* [2023-01-09 07:31:59] [012-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.830 (0.935)  Prec@1 67.50 (66.59) Prec@5 100.00 (97.27)]\n",
      "[012-200] searching : loss=0.94, accuracy@1=66.59%, accuracy@5=97.27%, time-cost=897.4 s\n",
      "[012-200] evaluate  : loss=1.03, accuracy@1=63.27%, accuracy@5=96.68%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 013-200-th epoch] Time Left: [04:17:37], LR=0.09896114053108829\n",
      "*SEARCH* [2023-01-09 07:32:18] [013-200][000/196] Time 4.51 (4.51) Data 4.14 (4.14) Base [Loss 1.022 (1.022)  Prec@1 64.06 (64.06) Prec@5 97.66 (97.66)]\n",
      "*SEARCH* [2023-01-09 07:32:34] [013-200][050/196] Time 0.33 (0.41) Data 0.00 (0.08) Base [Loss 0.860 (0.930)  Prec@1 68.75 (66.56) Prec@5 97.66 (97.30)]\n",
      "*SEARCH* [2023-01-09 07:32:51] [013-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.865 (0.921)  Prec@1 72.27 (66.96) Prec@5 96.48 (97.41)]\n",
      "*SEARCH* [2023-01-09 07:33:07] [013-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.965 (0.924)  Prec@1 66.02 (66.93) Prec@5 96.48 (97.42)]\n",
      "*SEARCH* [2023-01-09 07:33:21] [013-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 1.007 (0.919)  Prec@1 60.00 (67.16) Prec@5 97.50 (97.36)]\n",
      "[013-200] searching : loss=0.92, accuracy@1=67.16%, accuracy@5=97.36%, time-cost=966.1 s\n",
      "[013-200] evaluate  : loss=1.01, accuracy@1=64.40%, accuracy@5=96.87%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 013-200-th epoch : find the highest test accuracy : 64.40%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 014-200-th epoch] Time Left: [04:13:03], LR=0.09879583809693737\n",
      "*SEARCH* [2023-01-09 07:33:40] [014-200][000/196] Time 4.83 (4.83) Data 4.43 (4.43) Base [Loss 0.885 (0.885)  Prec@1 68.36 (68.36) Prec@5 96.09 (96.09)]\n",
      "*SEARCH* [2023-01-09 07:33:56] [014-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 0.825 (0.909)  Prec@1 72.27 (67.62) Prec@5 97.66 (97.33)]\n",
      "*SEARCH* [2023-01-09 07:34:13] [014-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.896 (0.913)  Prec@1 72.66 (67.50) Prec@5 95.70 (97.34)]\n",
      "*SEARCH* [2023-01-09 07:34:30] [014-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.947 (0.911)  Prec@1 66.41 (67.48) Prec@5 97.66 (97.39)]\n",
      "*SEARCH* [2023-01-09 07:34:45] [014-200][195/196] Time 0.14 (0.36) Data 0.00 (0.02) Base [Loss 0.758 (0.908)  Prec@1 76.25 (67.69) Prec@5 98.75 (97.40)]\n",
      "[014-200] searching : loss=0.91, accuracy@1=67.69%, accuracy@5=97.40%, time-cost=1036.5 s\n",
      "[014-200] evaluate  : loss=1.00, accuracy@1=65.22%, accuracy@5=96.82%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 014-200-th epoch : find the highest test accuracy : 65.22%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 015-200-th epoch] Time Left: [04:19:40], LR=0.09861849601988383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 07:35:04] [015-200][000/196] Time 4.97 (4.97) Data 4.57 (4.57) Base [Loss 0.783 (0.783)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 07:35:21] [015-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 0.874 (0.887)  Prec@1 69.14 (68.73) Prec@5 96.88 (97.49)]\n",
      "*SEARCH* [2023-01-09 07:35:38] [015-200][100/196] Time 0.33 (0.38) Data 0.00 (0.05) Base [Loss 0.990 (0.890)  Prec@1 64.84 (68.61) Prec@5 97.66 (97.45)]\n",
      "*SEARCH* [2023-01-09 07:35:54] [015-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.843 (0.894)  Prec@1 71.48 (68.37) Prec@5 97.27 (97.45)]\n",
      "*SEARCH* [2023-01-09 07:36:09] [015-200][195/196] Time 0.15 (0.36) Data 0.00 (0.02) Base [Loss 0.925 (0.893)  Prec@1 67.50 (68.43) Prec@5 100.00 (97.54)]\n",
      "[015-200] searching : loss=0.89, accuracy@1=68.43%, accuracy@5=97.54%, time-cost=1107.1 s\n",
      "[015-200] evaluate  : loss=1.02, accuracy@1=63.33%, accuracy@5=96.77%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 016-200-th epoch] Time Left: [04:19:18], LR=0.09842915805643156\n",
      "*SEARCH* [2023-01-09 07:36:29] [016-200][000/196] Time 4.63 (4.63) Data 4.23 (4.23) Base [Loss 0.858 (0.858)  Prec@1 70.70 (70.70) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 07:36:45] [016-200][050/196] Time 0.34 (0.41) Data 0.00 (0.08) Base [Loss 0.860 (0.887)  Prec@1 71.09 (68.58) Prec@5 97.66 (97.73)]\n",
      "*SEARCH* [2023-01-09 07:37:02] [016-200][100/196] Time 0.34 (0.37) Data 0.00 (0.04) Base [Loss 0.822 (0.878)  Prec@1 68.75 (68.73) Prec@5 98.44 (97.69)]\n",
      "*SEARCH* [2023-01-09 07:37:18] [016-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.975 (0.872)  Prec@1 65.62 (69.01) Prec@5 96.88 (97.66)]\n",
      "*SEARCH* [2023-01-09 07:37:33] [016-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.917 (0.872)  Prec@1 68.75 (69.00) Prec@5 98.75 (97.66)]\n",
      "[016-200] searching : loss=0.87, accuracy@1=69.00%, accuracy@5=97.66%, time-cost=1176.4 s\n",
      "[016-200] evaluate  : loss=0.95, accuracy@1=66.68%, accuracy@5=97.09%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 016-200-th epoch : find the highest test accuracy : 66.68%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 017-200-th epoch] Time Left: [04:11:50], LR=0.09822787092288991\n",
      "*SEARCH* [2023-01-09 07:37:51] [017-200][000/196] Time 4.76 (4.76) Data 4.35 (4.35) Base [Loss 0.962 (0.962)  Prec@1 67.58 (67.58) Prec@5 97.27 (97.27)]\n",
      "*SEARCH* [2023-01-09 07:38:09] [017-200][050/196] Time 0.35 (0.44) Data 0.00 (0.09) Base [Loss 0.941 (0.868)  Prec@1 67.97 (69.39) Prec@5 98.05 (97.71)]\n",
      "*SEARCH* [2023-01-09 07:38:26] [017-200][100/196] Time 0.35 (0.39) Data 0.00 (0.04) Base [Loss 0.997 (0.870)  Prec@1 62.50 (69.24) Prec@5 97.27 (97.64)]\n",
      "*SEARCH* [2023-01-09 07:38:44] [017-200][150/196] Time 0.35 (0.38) Data 0.00 (0.03) Base [Loss 0.831 (0.869)  Prec@1 69.53 (69.21) Prec@5 98.83 (97.63)]\n",
      "*SEARCH* [2023-01-09 07:38:59] [017-200][195/196] Time 0.15 (0.37) Data 0.00 (0.02) Base [Loss 0.921 (0.868)  Prec@1 70.00 (69.40) Prec@5 96.25 (97.60)]\n",
      "[017-200] searching : loss=0.87, accuracy@1=69.40%, accuracy@5=97.60%, time-cost=1250.0 s\n",
      "[017-200] evaluate  : loss=1.04, accuracy@1=63.70%, accuracy@5=96.18%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 018-200-th epoch] Time Left: [04:22:48], LR=0.09801468428384716\n",
      "*SEARCH* [2023-01-09 07:39:18] [018-200][000/196] Time 5.22 (5.22) Data 4.79 (4.79) Base [Loss 0.909 (0.909)  Prec@1 69.92 (69.92) Prec@5 97.27 (97.27)]\n",
      "*SEARCH* [2023-01-09 07:39:36] [018-200][050/196] Time 0.34 (0.45) Data 0.00 (0.09) Base [Loss 0.833 (0.860)  Prec@1 70.70 (69.79) Prec@5 97.27 (97.57)]\n",
      "*SEARCH* [2023-01-09 07:39:53] [018-200][100/196] Time 0.35 (0.40) Data 0.00 (0.05) Base [Loss 0.863 (0.856)  Prec@1 69.14 (69.87) Prec@5 98.05 (97.66)]\n",
      "*SEARCH* [2023-01-09 07:40:11] [018-200][150/196] Time 0.34 (0.38) Data 0.00 (0.03) Base [Loss 0.912 (0.853)  Prec@1 68.36 (69.85) Prec@5 96.09 (97.70)]\n",
      "*SEARCH* [2023-01-09 07:40:26] [018-200][195/196] Time 0.15 (0.37) Data 0.00 (0.02) Base [Loss 0.790 (0.856)  Prec@1 71.25 (69.72) Prec@5 100.00 (97.67)]\n",
      "[018-200] searching : loss=0.86, accuracy@1=69.72%, accuracy@5=97.67%, time-cost=1323.7 s\n",
      "[018-200] evaluate  : loss=0.92, accuracy@1=67.25%, accuracy@5=97.24%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 018-200-th epoch : find the highest test accuracy : 67.25%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 019-200-th epoch] Time Left: [04:22:54], LR=0.09778965073991651\n",
      "*SEARCH* [2023-01-09 07:40:46] [019-200][000/196] Time 5.29 (5.29) Data 4.90 (4.90) Base [Loss 0.959 (0.959)  Prec@1 64.06 (64.06) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:41:02] [019-200][050/196] Time 0.33 (0.42) Data 0.00 (0.10) Base [Loss 0.756 (0.854)  Prec@1 75.39 (69.85) Prec@5 98.44 (97.50)]\n",
      "*SEARCH* [2023-01-09 07:41:18] [019-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 0.801 (0.849)  Prec@1 73.05 (70.17) Prec@5 96.88 (97.61)]\n",
      "*SEARCH* [2023-01-09 07:41:34] [019-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.891 (0.848)  Prec@1 67.97 (70.24) Prec@5 98.05 (97.64)]\n",
      "*SEARCH* [2023-01-09 07:41:48] [019-200][195/196] Time 0.12 (0.35) Data 0.00 (0.03) Base [Loss 0.913 (0.847)  Prec@1 66.25 (70.29) Prec@5 96.25 (97.63)]\n",
      "[019-200] searching : loss=0.85, accuracy@1=70.29%, accuracy@5=97.63%, time-cost=1392.2 s\n",
      "[019-200] evaluate  : loss=0.95, accuracy@1=66.90%, accuracy@5=97.09%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 020-200-th epoch] Time Left: [04:05:33], LR=0.09755282581475769\n",
      "*SEARCH* [2023-01-09 07:42:07] [020-200][000/196] Time 5.01 (5.01) Data 4.61 (4.61) Base [Loss 0.758 (0.758)  Prec@1 75.39 (75.39) Prec@5 97.66 (97.66)]\n",
      "*SEARCH* [2023-01-09 07:42:24] [020-200][050/196] Time 0.34 (0.42) Data 0.00 (0.09) Base [Loss 0.875 (0.834)  Prec@1 67.97 (71.28) Prec@5 97.66 (97.65)]\n",
      "*SEARCH* [2023-01-09 07:42:40] [020-200][100/196] Time 0.33 (0.38) Data 0.00 (0.05) Base [Loss 0.867 (0.838)  Prec@1 66.80 (70.74) Prec@5 98.05 (97.82)]\n",
      "*SEARCH* [2023-01-09 07:42:57] [020-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.917 (0.837)  Prec@1 67.97 (70.82) Prec@5 96.48 (97.80)]\n",
      "*SEARCH* [2023-01-09 07:43:12] [020-200][195/196] Time 0.13 (0.36) Data 0.00 (0.02) Base [Loss 0.809 (0.835)  Prec@1 67.50 (70.90) Prec@5 100.00 (97.77)]\n",
      "[020-200] searching : loss=0.83, accuracy@1=70.90%, accuracy@5=97.77%, time-cost=1462.8 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020-200] evaluate  : loss=0.95, accuracy@1=66.78%, accuracy@5=97.20%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 021-200-th epoch] Time Left: [04:09:24], LR=0.09730426794137727\n",
      "*SEARCH* [2023-01-09 07:43:30] [021-200][000/196] Time 4.56 (4.56) Data 4.17 (4.17) Base [Loss 0.743 (0.743)  Prec@1 73.83 (73.83) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:43:47] [021-200][050/196] Time 0.34 (0.42) Data 0.00 (0.08) Base [Loss 0.772 (0.824)  Prec@1 71.48 (70.99) Prec@5 98.83 (97.82)]\n",
      "*SEARCH* [2023-01-09 07:44:04] [021-200][100/196] Time 0.33 (0.38) Data 0.00 (0.04) Base [Loss 0.792 (0.828)  Prec@1 70.70 (70.85) Prec@5 98.05 (97.81)]\n",
      "*SEARCH* [2023-01-09 07:44:20] [021-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.853 (0.823)  Prec@1 71.48 (70.99) Prec@5 96.09 (97.86)]\n",
      "*SEARCH* [2023-01-09 07:44:35] [021-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.623 (0.826)  Prec@1 77.50 (70.96) Prec@5 98.75 (97.86)]\n",
      "[021-200] searching : loss=0.83, accuracy@1=70.96%, accuracy@5=97.86%, time-cost=1532.4 s\n",
      "[021-200] evaluate  : loss=0.89, accuracy@1=68.65%, accuracy@5=97.40%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 021-200-th epoch : find the highest test accuracy : 68.65%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 022-200-th epoch] Time Left: [04:04:54], LR=0.09704403844771128\n",
      "*SEARCH* [2023-01-09 07:44:53] [022-200][000/196] Time 4.65 (4.65) Data 4.25 (4.25) Base [Loss 0.798 (0.798)  Prec@1 71.88 (71.88) Prec@5 96.48 (96.48)]\n",
      "*SEARCH* [2023-01-09 07:45:10] [022-200][050/196] Time 0.33 (0.42) Data 0.00 (0.08) Base [Loss 0.752 (0.820)  Prec@1 74.61 (71.29) Prec@5 98.05 (97.89)]\n",
      "*SEARCH* [2023-01-09 07:45:26] [022-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.782 (0.814)  Prec@1 73.05 (71.48) Prec@5 96.88 (97.97)]\n",
      "*SEARCH* [2023-01-09 07:45:42] [022-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.774 (0.817)  Prec@1 74.22 (71.35) Prec@5 98.83 (97.91)]\n",
      "*SEARCH* [2023-01-09 07:45:57] [022-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.846 (0.815)  Prec@1 66.25 (71.53) Prec@5 100.00 (97.89)]\n",
      "[022-200] searching : loss=0.82, accuracy@1=71.53%, accuracy@5=97.89%, time-cost=1601.3 s\n",
      "[022-200] evaluate  : loss=0.90, accuracy@1=68.66%, accuracy@5=97.59%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 022-200-th epoch : find the highest test accuracy : 68.66%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 023-200-th epoch] Time Left: [04:01:49], LR=0.09677220154149338\n",
      "*SEARCH* [2023-01-09 07:46:15] [023-200][000/196] Time 4.56 (4.56) Data 4.13 (4.13) Base [Loss 0.833 (0.833)  Prec@1 72.27 (72.27) Prec@5 97.66 (97.66)]\n",
      "*SEARCH* [2023-01-09 07:46:32] [023-200][050/196] Time 0.35 (0.43) Data 0.00 (0.08) Base [Loss 0.651 (0.811)  Prec@1 80.47 (71.92) Prec@5 98.44 (97.92)]\n",
      "*SEARCH* [2023-01-09 07:46:50] [023-200][100/196] Time 0.35 (0.39) Data 0.00 (0.04) Base [Loss 0.800 (0.811)  Prec@1 74.61 (71.96) Prec@5 98.05 (97.91)]\n",
      "*SEARCH* [2023-01-09 07:47:07] [023-200][150/196] Time 0.35 (0.38) Data 0.00 (0.03) Base [Loss 0.769 (0.808)  Prec@1 74.22 (72.06) Prec@5 98.05 (97.92)]\n",
      "*SEARCH* [2023-01-09 07:47:23] [023-200][195/196] Time 0.15 (0.37) Data 0.00 (0.02) Base [Loss 0.828 (0.809)  Prec@1 70.00 (71.89) Prec@5 97.50 (97.89)]\n",
      "[023-200] searching : loss=0.81, accuracy@1=71.89%, accuracy@5=97.89%, time-cost=1674.8 s\n",
      "[023-200] evaluate  : loss=0.90, accuracy@1=68.34%, accuracy@5=97.66%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 024-200-th epoch] Time Left: [04:13:57], LR=0.09648882429441258\n",
      "*SEARCH* [2023-01-09 07:47:41] [024-200][000/196] Time 4.50 (4.50) Data 4.12 (4.12) Base [Loss 0.872 (0.872)  Prec@1 68.75 (68.75) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:47:58] [024-200][050/196] Time 0.34 (0.41) Data 0.00 (0.08) Base [Loss 0.795 (0.813)  Prec@1 71.09 (71.86) Prec@5 99.61 (97.76)]\n",
      "*SEARCH* [2023-01-09 07:48:14] [024-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.748 (0.803)  Prec@1 78.52 (72.18) Prec@5 98.05 (97.83)]\n",
      "*SEARCH* [2023-01-09 07:48:31] [024-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.745 (0.806)  Prec@1 72.66 (71.99) Prec@5 98.05 (97.89)]\n",
      "*SEARCH* [2023-01-09 07:48:46] [024-200][195/196] Time 0.14 (0.35) Data 0.00 (0.02) Base [Loss 0.542 (0.808)  Prec@1 88.75 (71.80) Prec@5 100.00 (97.88)]\n",
      "[024-200] searching : loss=0.81, accuracy@1=71.80%, accuracy@5=97.88%, time-cost=1744.4 s\n",
      "[024-200] evaluate  : loss=0.87, accuracy@1=69.25%, accuracy@5=97.73%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 024-200-th epoch : find the highest test accuracy : 69.25%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 025-200-th epoch] Time Left: [04:04:24], LR=0.09619397662556434\n",
      "*SEARCH* [2023-01-09 07:49:05] [025-200][000/196] Time 4.58 (4.58) Data 4.20 (4.20) Base [Loss 0.759 (0.759)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 07:49:22] [025-200][050/196] Time 0.33 (0.42) Data 0.00 (0.08) Base [Loss 0.801 (0.790)  Prec@1 69.53 (72.28) Prec@5 99.61 (98.01)]\n",
      "*SEARCH* [2023-01-09 07:49:39] [025-200][100/196] Time 0.33 (0.38) Data 0.00 (0.04) Base [Loss 0.771 (0.802)  Prec@1 72.66 (71.79) Prec@5 98.44 (97.96)]\n",
      "*SEARCH* [2023-01-09 07:49:55] [025-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.962 (0.800)  Prec@1 66.80 (71.93) Prec@5 96.88 (97.93)]\n",
      "*SEARCH* [2023-01-09 07:50:10] [025-200][195/196] Time 0.13 (0.36) Data 0.00 (0.02) Base [Loss 0.948 (0.800)  Prec@1 67.50 (71.93) Prec@5 92.50 (97.90)]\n",
      "[025-200] searching : loss=0.80, accuracy@1=71.93%, accuracy@5=97.90%, time-cost=1814.8 s\n",
      "[025-200] evaluate  : loss=0.90, accuracy@1=68.51%, accuracy@5=97.40%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 026-200-th epoch] Time Left: [04:02:39], LR=0.09588773128419906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 07:50:29] [026-200][000/196] Time 4.70 (4.70) Data 4.31 (4.31) Base [Loss 0.884 (0.884)  Prec@1 69.92 (69.92) Prec@5 97.27 (97.27)]\n",
      "*SEARCH* [2023-01-09 07:50:45] [026-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 0.871 (0.800)  Prec@1 70.70 (71.87) Prec@5 96.09 (97.68)]\n",
      "*SEARCH* [2023-01-09 07:51:01] [026-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.784 (0.803)  Prec@1 71.48 (71.75) Prec@5 98.83 (97.83)]\n",
      "*SEARCH* [2023-01-09 07:51:17] [026-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.870 (0.804)  Prec@1 67.19 (72.00) Prec@5 97.66 (97.77)]\n",
      "*SEARCH* [2023-01-09 07:51:32] [026-200][195/196] Time 0.15 (0.35) Data 0.00 (0.02) Base [Loss 0.735 (0.799)  Prec@1 75.00 (72.18) Prec@5 98.75 (97.82)]\n",
      "[026-200] searching : loss=0.80, accuracy@1=72.18%, accuracy@5=97.82%, time-cost=1883.4 s\n",
      "[026-200] evaluate  : loss=0.88, accuracy@1=69.06%, accuracy@5=97.53%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 027-200-th epoch] Time Left: [03:56:07], LR=0.09557016383177226\n",
      "*SEARCH* [2023-01-09 07:51:51] [027-200][000/196] Time 4.50 (4.50) Data 4.13 (4.13) Base [Loss 0.797 (0.797)  Prec@1 71.09 (71.09) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 07:52:07] [027-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 0.824 (0.797)  Prec@1 71.88 (71.98) Prec@5 95.70 (97.86)]\n",
      "*SEARCH* [2023-01-09 07:52:24] [027-200][100/196] Time 0.34 (0.37) Data 0.00 (0.04) Base [Loss 0.686 (0.792)  Prec@1 73.83 (72.34) Prec@5 99.61 (97.92)]\n",
      "*SEARCH* [2023-01-09 07:52:41] [027-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.830 (0.795)  Prec@1 69.14 (72.19) Prec@5 98.83 (97.94)]\n",
      "*SEARCH* [2023-01-09 07:52:56] [027-200][195/196] Time 0.14 (0.35) Data 0.00 (0.02) Base [Loss 0.943 (0.795)  Prec@1 67.50 (72.25) Prec@5 97.50 (97.97)]\n",
      "[027-200] searching : loss=0.79, accuracy@1=72.25%, accuracy@5=97.97%, time-cost=1953.6 s\n",
      "[027-200] evaluate  : loss=0.89, accuracy@1=68.98%, accuracy@5=97.78%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 028-200-th epoch] Time Left: [04:00:19], LR=0.09524135262330098\n",
      "*SEARCH* [2023-01-09 07:53:15] [028-200][000/196] Time 4.79 (4.79) Data 4.36 (4.36) Base [Loss 0.797 (0.797)  Prec@1 71.48 (71.48) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 07:53:33] [028-200][050/196] Time 0.36 (0.45) Data 0.00 (0.09) Base [Loss 0.754 (0.787)  Prec@1 73.44 (71.82) Prec@5 97.66 (98.15)]\n",
      "*SEARCH* [2023-01-09 07:53:51] [028-200][100/196] Time 0.36 (0.41) Data 0.00 (0.04) Base [Loss 0.814 (0.784)  Prec@1 67.97 (72.34) Prec@5 97.66 (98.10)]\n",
      "*SEARCH* [2023-01-09 07:54:09] [028-200][150/196] Time 0.36 (0.39) Data 0.00 (0.03) Base [Loss 0.719 (0.782)  Prec@1 75.78 (72.34) Prec@5 98.44 (98.10)]\n",
      "*SEARCH* [2023-01-09 07:54:26] [028-200][195/196] Time 0.16 (0.39) Data 0.00 (0.02) Base [Loss 1.026 (0.782)  Prec@1 66.25 (72.45) Prec@5 96.25 (98.07)]\n",
      "[028-200] searching : loss=0.78, accuracy@1=72.45%, accuracy@5=98.07%, time-cost=2029.8 s\n",
      "[028-200] evaluate  : loss=0.86, accuracy@1=69.73%, accuracy@5=97.67%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 028-200-th epoch : find the highest test accuracy : 69.73%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 029-200-th epoch] Time Left: [04:17:27], LR=0.09490137878803079\n",
      "*SEARCH* [2023-01-09 07:54:45] [029-200][000/196] Time 4.92 (4.92) Data 4.52 (4.52) Base [Loss 0.950 (0.950)  Prec@1 68.75 (68.75) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:55:02] [029-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 0.656 (0.782)  Prec@1 75.78 (72.75) Prec@5 98.44 (97.99)]\n",
      "*SEARCH* [2023-01-09 07:55:18] [029-200][100/196] Time 0.33 (0.37) Data 0.00 (0.05) Base [Loss 0.885 (0.781)  Prec@1 66.41 (72.59) Prec@5 99.22 (98.03)]\n",
      "*SEARCH* [2023-01-09 07:55:36] [029-200][150/196] Time 0.36 (0.37) Data 0.00 (0.03) Base [Loss 0.732 (0.778)  Prec@1 76.56 (72.79) Prec@5 97.66 (98.06)]\n",
      "*SEARCH* [2023-01-09 07:55:52] [029-200][195/196] Time 0.17 (0.36) Data 0.00 (0.02) Base [Loss 0.985 (0.778)  Prec@1 70.00 (72.74) Prec@5 97.50 (98.04)]\n",
      "[029-200] searching : loss=0.78, accuracy@1=72.74%, accuracy@5=98.04%, time-cost=2102.0 s\n",
      "[029-200] evaluate  : loss=0.89, accuracy@1=68.82%, accuracy@5=97.48%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 030-200-th epoch] Time Left: [04:01:44], LR=0.09455032620941839\n",
      "*SEARCH* [2023-01-09 07:56:10] [030-200][000/196] Time 4.61 (4.61) Data 4.19 (4.19) Base [Loss 0.825 (0.825)  Prec@1 72.66 (72.66) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:56:27] [030-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 0.711 (0.766)  Prec@1 73.83 (73.41) Prec@5 98.83 (97.94)]\n",
      "*SEARCH* [2023-01-09 07:56:43] [030-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.822 (0.775)  Prec@1 70.70 (73.09) Prec@5 97.27 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:57:00] [030-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.755 (0.776)  Prec@1 73.44 (73.11) Prec@5 97.66 (98.06)]\n",
      "*SEARCH* [2023-01-09 07:57:15] [030-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.722 (0.775)  Prec@1 77.50 (73.12) Prec@5 98.75 (98.06)]\n",
      "[030-200] searching : loss=0.78, accuracy@1=73.12%, accuracy@5=98.06%, time-cost=2171.9 s\n",
      "[030-200] evaluate  : loss=0.88, accuracy@1=69.35%, accuracy@5=97.67%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 031-200-th epoch] Time Left: [03:54:20], LR=0.09418828150443469\n",
      "*SEARCH* [2023-01-09 07:57:33] [031-200][000/196] Time 4.52 (4.52) Data 4.14 (4.14) Base [Loss 0.807 (0.807)  Prec@1 71.48 (71.48) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 07:57:50] [031-200][050/196] Time 0.34 (0.42) Data 0.00 (0.08) Base [Loss 0.764 (0.757)  Prec@1 71.48 (73.54) Prec@5 98.44 (98.15)]\n",
      "*SEARCH* [2023-01-09 07:58:08] [031-200][100/196] Time 0.36 (0.38) Data 0.00 (0.04) Base [Loss 0.779 (0.768)  Prec@1 69.92 (73.23) Prec@5 97.66 (98.04)]\n",
      "*SEARCH* [2023-01-09 07:58:25] [031-200][150/196] Time 0.35 (0.37) Data 0.00 (0.03) Base [Loss 0.743 (0.767)  Prec@1 71.09 (73.16) Prec@5 99.22 (98.06)]\n",
      "*SEARCH* [2023-01-09 07:58:41] [031-200][195/196] Time 0.15 (0.37) Data 0.00 (0.02) Base [Loss 0.700 (0.768)  Prec@1 72.50 (73.14) Prec@5 98.75 (98.04)]\n",
      "[031-200] searching : loss=0.77, accuracy@1=73.14%, accuracy@5=98.04%, time-cost=2244.6 s\n",
      "[031-200] evaluate  : loss=0.84, accuracy@1=71.10%, accuracy@5=97.73%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 031-200-th epoch : find the highest test accuracy : 71.10%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 032-200-th epoch] Time Left: [04:00:26], LR=0.09381533400219318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 07:59:00] [032-200][000/196] Time 5.10 (5.10) Data 4.73 (4.73) Base [Loss 0.771 (0.771)  Prec@1 73.05 (73.05) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:59:16] [032-200][050/196] Time 0.32 (0.42) Data 0.00 (0.09) Base [Loss 0.765 (0.772)  Prec@1 70.70 (72.96) Prec@5 97.27 (98.05)]\n",
      "*SEARCH* [2023-01-09 07:59:32] [032-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 0.699 (0.767)  Prec@1 78.12 (73.24) Prec@5 98.44 (98.01)]\n",
      "*SEARCH* [2023-01-09 07:59:49] [032-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.750 (0.761)  Prec@1 74.22 (73.57) Prec@5 98.83 (98.10)]\n",
      "*SEARCH* [2023-01-09 08:00:04] [032-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.681 (0.764)  Prec@1 78.75 (73.40) Prec@5 97.50 (98.11)]\n",
      "[032-200] searching : loss=0.76, accuracy@1=73.40%, accuracy@5=98.11%, time-cost=2314.5 s\n",
      "[032-200] evaluate  : loss=0.83, accuracy@1=71.11%, accuracy@5=97.75%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 032-200-th epoch : find the highest test accuracy : 71.11%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 033-200-th epoch] Time Left: [03:52:10], LR=0.09343157572190958\n",
      "*SEARCH* [2023-01-09 08:00:23] [033-200][000/196] Time 4.74 (4.74) Data 4.35 (4.35) Base [Loss 0.770 (0.770)  Prec@1 73.83 (73.83) Prec@5 96.48 (96.48)]\n",
      "*SEARCH* [2023-01-09 08:00:39] [033-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.803 (0.772)  Prec@1 70.31 (73.02) Prec@5 98.83 (97.82)]\n",
      "*SEARCH* [2023-01-09 08:00:55] [033-200][100/196] Time 0.38 (0.37) Data 0.00 (0.04) Base [Loss 0.729 (0.770)  Prec@1 76.17 (73.20) Prec@5 98.05 (97.94)]\n",
      "*SEARCH* [2023-01-09 08:01:13] [033-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.751 (0.770)  Prec@1 74.22 (73.10) Prec@5 97.27 (97.97)]\n",
      "*SEARCH* [2023-01-09 08:01:27] [033-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.849 (0.769)  Prec@1 72.50 (73.17) Prec@5 96.25 (98.03)]\n",
      "[033-200] searching : loss=0.77, accuracy@1=73.17%, accuracy@5=98.03%, time-cost=2383.9 s\n",
      "[033-200] evaluate  : loss=0.87, accuracy@1=69.71%, accuracy@5=97.70%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 034-200-th epoch] Time Left: [03:49:46], LR=0.09303710135019719\n",
      "*SEARCH* [2023-01-09 08:01:46] [034-200][000/196] Time 4.88 (4.88) Data 4.49 (4.49) Base [Loss 0.913 (0.913)  Prec@1 70.31 (70.31) Prec@5 96.48 (96.48)]\n",
      "*SEARCH* [2023-01-09 08:02:02] [034-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.745 (0.759)  Prec@1 71.88 (73.38) Prec@5 97.66 (98.28)]\n",
      "*SEARCH* [2023-01-09 08:02:18] [034-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.673 (0.759)  Prec@1 74.61 (73.38) Prec@5 99.61 (98.15)]\n",
      "*SEARCH* [2023-01-09 08:02:34] [034-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.773 (0.757)  Prec@1 74.61 (73.53) Prec@5 98.05 (98.16)]\n",
      "*SEARCH* [2023-01-09 08:02:49] [034-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.892 (0.761)  Prec@1 67.50 (73.39) Prec@5 97.50 (98.15)]\n",
      "[034-200] searching : loss=0.76, accuracy@1=73.39%, accuracy@5=98.15%, time-cost=2452.2 s\n",
      "[034-200] evaluate  : loss=0.80, accuracy@1=72.58%, accuracy@5=98.00%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 034-200-th epoch : find the highest test accuracy : 72.58%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 035-200-th epoch] Time Left: [03:45:44], LR=0.09263200821770462\n",
      "*SEARCH* [2023-01-09 08:03:08] [035-200][000/196] Time 4.86 (4.86) Data 4.47 (4.47) Base [Loss 0.673 (0.673)  Prec@1 76.56 (76.56) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:03:24] [035-200][050/196] Time 0.33 (0.41) Data 0.00 (0.09) Base [Loss 0.935 (0.757)  Prec@1 69.14 (73.43) Prec@5 98.05 (98.06)]\n",
      "*SEARCH* [2023-01-09 08:03:41] [035-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.731 (0.751)  Prec@1 73.44 (73.73) Prec@5 99.22 (98.22)]\n",
      "*SEARCH* [2023-01-09 08:03:58] [035-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.729 (0.754)  Prec@1 75.39 (73.54) Prec@5 97.66 (98.20)]\n",
      "*SEARCH* [2023-01-09 08:04:13] [035-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.606 (0.757)  Prec@1 80.00 (73.47) Prec@5 97.50 (98.16)]\n",
      "[035-200] searching : loss=0.76, accuracy@1=73.47%, accuracy@5=98.16%, time-cost=2522.2 s\n",
      "[035-200] evaluate  : loss=0.82, accuracy@1=71.48%, accuracy@5=97.96%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 036-200-th epoch] Time Left: [03:47:29], LR=0.09221639627510075\n",
      "*SEARCH* [2023-01-09 08:04:32] [036-200][000/196] Time 5.02 (5.02) Data 4.62 (4.62) Base [Loss 0.857 (0.857)  Prec@1 71.09 (71.09) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:04:48] [036-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.778 (0.757)  Prec@1 71.48 (73.57) Prec@5 97.66 (98.24)]\n",
      "*SEARCH* [2023-01-09 08:05:04] [036-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 0.776 (0.750)  Prec@1 74.61 (73.70) Prec@5 96.09 (98.31)]\n",
      "*SEARCH* [2023-01-09 08:05:20] [036-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.764 (0.754)  Prec@1 73.83 (73.73) Prec@5 97.27 (98.19)]\n",
      "*SEARCH* [2023-01-09 08:05:34] [036-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 1.006 (0.752)  Prec@1 61.25 (73.89) Prec@5 96.25 (98.18)]\n",
      "[036-200] searching : loss=0.75, accuracy@1=73.89%, accuracy@5=98.18%, time-cost=2590.4 s\n",
      "[036-200] evaluate  : loss=0.83, accuracy@1=70.88%, accuracy@5=97.89%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 037-200-th epoch] Time Left: [03:41:48], LR=0.09179036806841352\n",
      "*SEARCH* [2023-01-09 08:05:53] [037-200][000/196] Time 5.27 (5.27) Data 4.86 (4.86) Base [Loss 0.799 (0.799)  Prec@1 73.83 (73.83) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:06:10] [037-200][050/196] Time 0.34 (0.42) Data 0.00 (0.10) Base [Loss 0.813 (0.743)  Prec@1 72.66 (73.81) Prec@5 97.66 (98.18)]\n",
      "*SEARCH* [2023-01-09 08:06:26] [037-200][100/196] Time 0.33 (0.38) Data 0.00 (0.05) Base [Loss 0.730 (0.743)  Prec@1 76.56 (73.94) Prec@5 98.44 (98.19)]\n",
      "*SEARCH* [2023-01-09 08:06:43] [037-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.840 (0.744)  Prec@1 70.70 (74.02) Prec@5 96.88 (98.16)]\n",
      "*SEARCH* [2023-01-09 08:06:58] [037-200][195/196] Time 0.13 (0.36) Data 0.00 (0.03) Base [Loss 0.875 (0.749)  Prec@1 67.50 (73.85) Prec@5 96.25 (98.13)]\n",
      "[037-200] searching : loss=0.75, accuracy@1=73.85%, accuracy@5=98.13%, time-cost=2660.9 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[037-200] evaluate  : loss=0.83, accuracy@1=70.94%, accuracy@5=97.79%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 038-200-th epoch] Time Left: [03:47:59], LR=0.0913540287137281\n",
      "*SEARCH* [2023-01-09 08:07:18] [038-200][000/196] Time 5.07 (5.07) Data 4.62 (4.62) Base [Loss 0.753 (0.753)  Prec@1 74.22 (74.22) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 08:07:34] [038-200][050/196] Time 0.32 (0.42) Data 0.00 (0.09) Base [Loss 0.754 (0.741)  Prec@1 73.44 (74.45) Prec@5 98.44 (98.22)]\n",
      "*SEARCH* [2023-01-09 08:07:50] [038-200][100/196] Time 0.32 (0.37) Data 0.00 (0.05) Base [Loss 0.681 (0.744)  Prec@1 77.73 (74.22) Prec@5 98.05 (98.15)]\n",
      "*SEARCH* [2023-01-09 08:08:06] [038-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.682 (0.745)  Prec@1 73.44 (74.11) Prec@5 99.61 (98.15)]\n",
      "*SEARCH* [2023-01-09 08:08:21] [038-200][195/196] Time 0.14 (0.35) Data 0.00 (0.02) Base [Loss 0.683 (0.741)  Prec@1 76.25 (74.14) Prec@5 98.75 (98.23)]\n",
      "[038-200] searching : loss=0.74, accuracy@1=74.14%, accuracy@5=98.23%, time-cost=2729.8 s\n",
      "[038-200] evaluate  : loss=0.85, accuracy@1=70.24%, accuracy@5=97.71%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 039-200-th epoch] Time Left: [03:40:03], LR=0.09090748587125118\n",
      "*SEARCH* [2023-01-09 08:08:39] [039-200][000/196] Time 4.72 (4.72) Data 4.33 (4.33) Base [Loss 0.737 (0.737)  Prec@1 75.78 (75.78) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:08:57] [039-200][050/196] Time 0.36 (0.43) Data 0.00 (0.09) Base [Loss 0.682 (0.738)  Prec@1 75.00 (74.26) Prec@5 98.44 (98.20)]\n",
      "*SEARCH* [2023-01-09 08:09:15] [039-200][100/196] Time 0.35 (0.40) Data 0.00 (0.04) Base [Loss 0.721 (0.744)  Prec@1 75.39 (73.96) Prec@5 100.00 (98.30)]\n",
      "*SEARCH* [2023-01-09 08:09:32] [039-200][150/196] Time 0.34 (0.38) Data 0.00 (0.03) Base [Loss 0.709 (0.739)  Prec@1 74.61 (74.28) Prec@5 98.05 (98.28)]\n",
      "*SEARCH* [2023-01-09 08:09:48] [039-200][195/196] Time 0.15 (0.37) Data 0.00 (0.02) Base [Loss 0.649 (0.742)  Prec@1 77.50 (74.09) Prec@5 98.75 (98.28)]\n",
      "[039-200] searching : loss=0.74, accuracy@1=74.09%, accuracy@5=98.28%, time-cost=2803.8 s\n",
      "[039-200] evaluate  : loss=0.82, accuracy@1=71.55%, accuracy@5=98.00%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 040-200-th epoch] Time Left: [03:55:01], LR=0.09045084971874738\n",
      "*SEARCH* [2023-01-09 08:10:07] [040-200][000/196] Time 4.60 (4.60) Data 4.23 (4.23) Base [Loss 0.766 (0.766)  Prec@1 72.66 (72.66) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:10:25] [040-200][050/196] Time 0.35 (0.43) Data 0.00 (0.08) Base [Loss 0.786 (0.741)  Prec@1 74.22 (73.66) Prec@5 98.44 (98.30)]\n",
      "*SEARCH* [2023-01-09 08:10:42] [040-200][100/196] Time 0.33 (0.39) Data 0.00 (0.04) Base [Loss 0.664 (0.737)  Prec@1 76.56 (73.93) Prec@5 99.22 (98.26)]\n",
      "*SEARCH* [2023-01-09 08:10:59] [040-200][150/196] Time 0.33 (0.37) Data 0.00 (0.03) Base [Loss 0.784 (0.736)  Prec@1 71.88 (74.09) Prec@5 99.61 (98.31)]\n",
      "*SEARCH* [2023-01-09 08:11:14] [040-200][195/196] Time 0.13 (0.36) Data 0.00 (0.02) Base [Loss 0.632 (0.737)  Prec@1 77.50 (74.13) Prec@5 100.00 (98.26)]\n",
      "[040-200] searching : loss=0.74, accuracy@1=74.13%, accuracy@5=98.26%, time-cost=2875.3 s\n",
      "[040-200] evaluate  : loss=0.79, accuracy@1=72.61%, accuracy@5=98.08%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 040-200-th epoch : find the highest test accuracy : 72.61%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 041-200-th epoch] Time Left: [03:44:44], LR=0.08998423292435453\n",
      "*SEARCH* [2023-01-09 08:11:33] [041-200][000/196] Time 5.11 (5.11) Data 4.72 (4.72) Base [Loss 0.765 (0.765)  Prec@1 71.09 (71.09) Prec@5 97.27 (97.27)]\n",
      "*SEARCH* [2023-01-09 08:11:49] [041-200][050/196] Time 0.33 (0.43) Data 0.00 (0.09) Base [Loss 0.704 (0.715)  Prec@1 73.44 (75.27) Prec@5 98.44 (98.32)]\n",
      "*SEARCH* [2023-01-09 08:12:06] [041-200][100/196] Time 0.33 (0.38) Data 0.00 (0.05) Base [Loss 0.674 (0.725)  Prec@1 76.56 (74.76) Prec@5 98.44 (98.26)]\n",
      "*SEARCH* [2023-01-09 08:12:22] [041-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.695 (0.728)  Prec@1 73.83 (74.69) Prec@5 99.22 (98.28)]\n",
      "*SEARCH* [2023-01-09 08:12:36] [041-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.991 (0.733)  Prec@1 70.00 (74.46) Prec@5 97.50 (98.28)]\n",
      "[041-200] searching : loss=0.73, accuracy@1=74.46%, accuracy@5=98.28%, time-cost=2944.5 s\n",
      "[041-200] evaluate  : loss=0.82, accuracy@1=71.30%, accuracy@5=98.06%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 042-200-th epoch] Time Left: [03:38:55], LR=0.08950775061878452\n",
      "*SEARCH* [2023-01-09 08:12:55] [042-200][000/196] Time 4.74 (4.74) Data 4.36 (4.36) Base [Loss 0.772 (0.772)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 08:13:12] [042-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.732 (0.717)  Prec@1 74.61 (74.96) Prec@5 98.83 (98.49)]\n",
      "*SEARCH* [2023-01-09 08:13:28] [042-200][100/196] Time 0.34 (0.37) Data 0.00 (0.04) Base [Loss 0.719 (0.722)  Prec@1 73.05 (74.64) Prec@5 98.83 (98.37)]\n",
      "*SEARCH* [2023-01-09 08:13:45] [042-200][150/196] Time 0.40 (0.36) Data 0.00 (0.03) Base [Loss 0.694 (0.727)  Prec@1 76.95 (74.52) Prec@5 98.44 (98.29)]\n",
      "*SEARCH* [2023-01-09 08:14:00] [042-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.765 (0.729)  Prec@1 75.00 (74.43) Prec@5 97.50 (98.33)]\n",
      "[042-200] searching : loss=0.73, accuracy@1=74.43%, accuracy@5=98.33%, time-cost=3014.2 s\n",
      "[042-200] evaluate  : loss=0.78, accuracy@1=72.65%, accuracy@5=98.00%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 042-200-th epoch : find the highest test accuracy : 72.65%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 043-200-th epoch] Time Left: [03:37:29], LR=0.08902152036691649\n",
      "*SEARCH* [2023-01-09 08:14:18] [043-200][000/196] Time 4.52 (4.52) Data 4.13 (4.13) Base [Loss 0.794 (0.794)  Prec@1 73.44 (73.44) Prec@5 97.27 (97.27)]\n",
      "*SEARCH* [2023-01-09 08:14:36] [043-200][050/196] Time 0.35 (0.43) Data 0.00 (0.08) Base [Loss 0.831 (0.753)  Prec@1 72.27 (73.51) Prec@5 98.44 (97.90)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 08:14:53] [043-200][100/196] Time 0.35 (0.39) Data 0.00 (0.04) Base [Loss 0.671 (0.742)  Prec@1 75.39 (74.16) Prec@5 98.44 (98.09)]\n",
      "*SEARCH* [2023-01-09 08:15:10] [043-200][150/196] Time 0.35 (0.37) Data 0.00 (0.03) Base [Loss 0.619 (0.737)  Prec@1 77.34 (74.35) Prec@5 99.61 (98.14)]\n",
      "*SEARCH* [2023-01-09 08:15:26] [043-200][195/196] Time 0.16 (0.37) Data 0.00 (0.02) Base [Loss 0.891 (0.736)  Prec@1 66.25 (74.44) Prec@5 97.50 (98.13)]\n",
      "[043-200] searching : loss=0.74, accuracy@1=74.44%, accuracy@5=98.13%, time-cost=3087.1 s\n",
      "[043-200] evaluate  : loss=0.85, accuracy@1=71.08%, accuracy@5=97.55%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 044-200-th epoch] Time Left: [03:43:21], LR=0.08852566213878947\n",
      "*SEARCH* [2023-01-09 08:15:44] [044-200][000/196] Time 4.45 (4.45) Data 4.07 (4.07) Base [Loss 0.766 (0.766)  Prec@1 71.88 (71.88) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:16:00] [044-200][050/196] Time 0.32 (0.40) Data 0.00 (0.08) Base [Loss 0.680 (0.718)  Prec@1 76.56 (74.79) Prec@5 98.44 (98.36)]\n",
      "*SEARCH* [2023-01-09 08:16:17] [044-200][100/196] Time 0.35 (0.37) Data 0.00 (0.04) Base [Loss 0.712 (0.720)  Prec@1 75.39 (74.95) Prec@5 98.83 (98.36)]\n",
      "*SEARCH* [2023-01-09 08:16:34] [044-200][150/196] Time 0.35 (0.36) Data 0.00 (0.03) Base [Loss 0.804 (0.726)  Prec@1 70.31 (74.63) Prec@5 98.83 (98.35)]\n",
      "*SEARCH* [2023-01-09 08:16:50] [044-200][195/196] Time 0.20 (0.36) Data 0.00 (0.02) Base [Loss 1.013 (0.727)  Prec@1 66.25 (74.65) Prec@5 97.50 (98.30)]\n",
      "[044-200] searching : loss=0.73, accuracy@1=74.65%, accuracy@5=98.30%, time-cost=3158.1 s\n",
      "[044-200] evaluate  : loss=0.82, accuracy@1=71.49%, accuracy@5=98.03%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 045-200-th epoch] Time Left: [03:38:16], LR=0.08802029828000156\n",
      "*SEARCH* [2023-01-09 08:17:09] [045-200][000/196] Time 4.57 (4.57) Data 4.13 (4.13) Base [Loss 0.797 (0.797)  Prec@1 71.09 (71.09) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:17:27] [045-200][050/196] Time 0.36 (0.45) Data 0.00 (0.08) Base [Loss 0.670 (0.717)  Prec@1 77.73 (75.44) Prec@5 98.83 (98.33)]\n",
      "*SEARCH* [2023-01-09 08:17:45] [045-200][100/196] Time 0.35 (0.40) Data 0.00 (0.04) Base [Loss 0.742 (0.717)  Prec@1 72.66 (75.07) Prec@5 98.83 (98.31)]\n",
      "*SEARCH* [2023-01-09 08:18:02] [045-200][150/196] Time 0.35 (0.38) Data 0.00 (0.03) Base [Loss 0.722 (0.724)  Prec@1 73.44 (74.67) Prec@5 97.27 (98.29)]\n",
      "*SEARCH* [2023-01-09 08:18:18] [045-200][195/196] Time 0.15 (0.38) Data 0.00 (0.02) Base [Loss 0.875 (0.722)  Prec@1 70.00 (74.73) Prec@5 96.25 (98.29)]\n",
      "[045-200] searching : loss=0.72, accuracy@1=74.73%, accuracy@5=98.29%, time-cost=3232.8 s\n",
      "[045-200] evaluate  : loss=0.81, accuracy@1=71.40%, accuracy@5=97.85%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 046-200-th epoch] Time Left: [03:46:37], LR=0.08750555348152299\n",
      "*SEARCH* [2023-01-09 08:18:37] [046-200][000/196] Time 4.78 (4.78) Data 4.40 (4.40) Base [Loss 0.738 (0.738)  Prec@1 75.00 (75.00) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:18:53] [046-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.744 (0.724)  Prec@1 73.83 (74.67) Prec@5 97.27 (98.51)]\n",
      "*SEARCH* [2023-01-09 08:19:10] [046-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.901 (0.716)  Prec@1 72.27 (74.95) Prec@5 98.44 (98.52)]\n",
      "*SEARCH* [2023-01-09 08:19:26] [046-200][150/196] Time 0.34 (0.35) Data 0.00 (0.03) Base [Loss 0.737 (0.714)  Prec@1 73.44 (75.13) Prec@5 97.66 (98.48)]\n",
      "*SEARCH* [2023-01-09 08:19:41] [046-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.735 (0.720)  Prec@1 72.50 (74.94) Prec@5 97.50 (98.39)]\n",
      "[046-200] searching : loss=0.72, accuracy@1=74.94%, accuracy@5=98.39%, time-cost=3301.7 s\n",
      "[046-200] evaluate  : loss=0.75, accuracy@1=74.02%, accuracy@5=98.22%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 046-200-th epoch : find the highest test accuracy : 74.02%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 047-200-th epoch] Time Left: [03:29:49], LR=0.08698155474893049\n",
      "*SEARCH* [2023-01-09 08:20:00] [047-200][000/196] Time 4.73 (4.73) Data 4.31 (4.31) Base [Loss 0.551 (0.551)  Prec@1 80.86 (80.86) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 08:20:16] [047-200][050/196] Time 0.33 (0.42) Data 0.00 (0.08) Base [Loss 0.625 (0.715)  Prec@1 76.56 (75.02) Prec@5 100.00 (98.41)]\n",
      "*SEARCH* [2023-01-09 08:20:32] [047-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.718 (0.713)  Prec@1 74.61 (75.12) Prec@5 96.88 (98.38)]\n",
      "*SEARCH* [2023-01-09 08:20:49] [047-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.709 (0.714)  Prec@1 75.78 (75.04) Prec@5 98.83 (98.42)]\n",
      "*SEARCH* [2023-01-09 08:21:03] [047-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.542 (0.719)  Prec@1 83.75 (74.90) Prec@5 100.00 (98.38)]\n",
      "[047-200] searching : loss=0.72, accuracy@1=74.90%, accuracy@5=98.38%, time-cost=3370.3 s\n",
      "[047-200] evaluate  : loss=0.76, accuracy@1=73.54%, accuracy@5=98.12%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 048-200-th epoch] Time Left: [03:27:27], LR=0.08644843137107058\n",
      "*SEARCH* [2023-01-09 08:21:21] [048-200][000/196] Time 4.72 (4.72) Data 4.32 (4.32) Base [Loss 0.666 (0.666)  Prec@1 75.78 (75.78) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 08:21:38] [048-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.792 (0.714)  Prec@1 74.22 (74.89) Prec@5 97.27 (98.37)]\n",
      "*SEARCH* [2023-01-09 08:21:54] [048-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.676 (0.712)  Prec@1 75.39 (75.07) Prec@5 98.44 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:22:10] [048-200][150/196] Time 0.33 (0.35) Data 0.00 (0.03) Base [Loss 0.755 (0.713)  Prec@1 73.83 (75.08) Prec@5 98.44 (98.34)]\n",
      "*SEARCH* [2023-01-09 08:22:24] [048-200][195/196] Time 0.12 (0.34) Data 0.00 (0.02) Base [Loss 0.764 (0.715)  Prec@1 76.25 (75.11) Prec@5 97.50 (98.33)]\n",
      "[048-200] searching : loss=0.71, accuracy@1=75.11%, accuracy@5=98.33%, time-cost=3438.3 s\n",
      "[048-200] evaluate  : loss=0.79, accuracy@1=72.66%, accuracy@5=98.31%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 049-200-th epoch] Time Left: [03:24:05], LR=0.08590631488815945\n",
      "*SEARCH* [2023-01-09 08:22:42] [049-200][000/196] Time 4.50 (4.50) Data 4.10 (4.10) Base [Loss 0.816 (0.816)  Prec@1 70.70 (70.70) Prec@5 97.66 (97.66)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 08:22:58] [049-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 0.664 (0.718)  Prec@1 77.73 (75.67) Prec@5 99.22 (98.41)]\n",
      "*SEARCH* [2023-01-09 08:23:15] [049-200][100/196] Time 0.32 (0.36) Data 0.00 (0.04) Base [Loss 0.698 (0.704)  Prec@1 76.95 (75.75) Prec@5 98.83 (98.50)]\n",
      "*SEARCH* [2023-01-09 08:23:31] [049-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.593 (0.709)  Prec@1 78.91 (75.57) Prec@5 98.83 (98.42)]\n",
      "*SEARCH* [2023-01-09 08:23:45] [049-200][195/196] Time 0.14 (0.35) Data 0.00 (0.02) Base [Loss 0.758 (0.712)  Prec@1 75.00 (75.48) Prec@5 97.50 (98.39)]\n",
      "[049-200] searching : loss=0.71, accuracy@1=75.48%, accuracy@5=98.39%, time-cost=3506.6 s\n",
      "[049-200] evaluate  : loss=0.82, accuracy@1=72.04%, accuracy@5=97.96%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 050-200-th epoch] Time Left: [03:23:23], LR=0.08535533905932738\n",
      "*SEARCH* [2023-01-09 08:24:04] [050-200][000/196] Time 4.59 (4.59) Data 4.20 (4.20) Base [Loss 0.627 (0.627)  Prec@1 79.30 (79.30) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:24:20] [050-200][050/196] Time 0.34 (0.42) Data 0.00 (0.08) Base [Loss 0.685 (0.708)  Prec@1 73.83 (75.64) Prec@5 98.83 (98.38)]\n",
      "*SEARCH* [2023-01-09 08:24:37] [050-200][100/196] Time 0.33 (0.38) Data 0.00 (0.04) Base [Loss 0.800 (0.707)  Prec@1 72.27 (75.45) Prec@5 97.27 (98.35)]\n",
      "*SEARCH* [2023-01-09 08:24:53] [050-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.648 (0.712)  Prec@1 76.17 (75.19) Prec@5 98.05 (98.28)]\n",
      "*SEARCH* [2023-01-09 08:25:08] [050-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.538 (0.716)  Prec@1 78.75 (75.00) Prec@5 98.75 (98.28)]\n",
      "[050-200] searching : loss=0.72, accuracy@1=75.00%, accuracy@5=98.28%, time-cost=3575.7 s\n",
      "[050-200] evaluate  : loss=0.84, accuracy@1=71.50%, accuracy@5=97.70%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 051-200-th epoch] Time Left: [03:24:46], LR=0.08479563982961572\n",
      "*SEARCH* [2023-01-09 08:25:26] [051-200][000/196] Time 4.82 (4.82) Data 4.45 (4.45) Base [Loss 0.755 (0.755)  Prec@1 72.66 (72.66) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 08:25:43] [051-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.693 (0.715)  Prec@1 75.78 (75.23) Prec@5 98.05 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:25:59] [051-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.711 (0.711)  Prec@1 76.95 (75.29) Prec@5 98.44 (98.46)]\n",
      "*SEARCH* [2023-01-09 08:26:15] [051-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.752 (0.708)  Prec@1 75.39 (75.44) Prec@5 98.05 (98.47)]\n",
      "*SEARCH* [2023-01-09 08:26:29] [051-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.934 (0.710)  Prec@1 72.50 (75.49) Prec@5 96.25 (98.41)]\n",
      "[051-200] searching : loss=0.71, accuracy@1=75.49%, accuracy@5=98.41%, time-cost=3644.1 s\n",
      "[051-200] evaluate  : loss=0.79, accuracy@1=72.69%, accuracy@5=97.87%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 052-200-th epoch] Time Left: [03:20:58], LR=0.08422735529643444\n",
      "*SEARCH* [2023-01-09 08:26:48] [052-200][000/196] Time 4.47 (4.47) Data 4.08 (4.08) Base [Loss 0.752 (0.752)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 08:27:04] [052-200][050/196] Time 0.32 (0.40) Data 0.00 (0.08) Base [Loss 0.768 (0.726)  Prec@1 74.22 (75.04) Prec@5 97.27 (98.32)]\n",
      "*SEARCH* [2023-01-09 08:27:20] [052-200][100/196] Time 0.32 (0.36) Data 0.00 (0.04) Base [Loss 0.735 (0.711)  Prec@1 73.44 (75.42) Prec@5 99.22 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:27:36] [052-200][150/196] Time 0.33 (0.35) Data 0.00 (0.03) Base [Loss 0.665 (0.714)  Prec@1 75.00 (75.33) Prec@5 99.22 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:27:50] [052-200][195/196] Time 0.13 (0.34) Data 0.00 (0.02) Base [Loss 0.711 (0.709)  Prec@1 70.00 (75.42) Prec@5 97.50 (98.46)]\n",
      "[052-200] searching : loss=0.71, accuracy@1=75.42%, accuracy@5=98.46%, time-cost=3712.1 s\n",
      "[052-200] evaluate  : loss=0.80, accuracy@1=72.31%, accuracy@5=97.88%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 053-200-th epoch] Time Left: [03:20:35], LR=0.08365062567548867\n",
      "*SEARCH* [2023-01-09 08:28:09] [053-200][000/196] Time 4.55 (4.55) Data 4.16 (4.16) Base [Loss 0.725 (0.725)  Prec@1 73.83 (73.83) Prec@5 97.27 (97.27)]\n",
      "*SEARCH* [2023-01-09 08:28:26] [053-200][050/196] Time 0.33 (0.41) Data 0.00 (0.08) Base [Loss 0.613 (0.695)  Prec@1 78.91 (75.87) Prec@5 100.00 (98.49)]\n",
      "*SEARCH* [2023-01-09 08:28:43] [053-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.849 (0.700)  Prec@1 70.70 (75.77) Prec@5 98.44 (98.54)]\n",
      "*SEARCH* [2023-01-09 08:28:59] [053-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.798 (0.706)  Prec@1 71.09 (75.53) Prec@5 98.05 (98.49)]\n",
      "*SEARCH* [2023-01-09 08:29:14] [053-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.843 (0.707)  Prec@1 66.25 (75.45) Prec@5 98.75 (98.46)]\n",
      "[053-200] searching : loss=0.71, accuracy@1=75.45%, accuracy@5=98.46%, time-cost=3782.2 s\n",
      "[053-200] evaluate  : loss=0.78, accuracy@1=72.97%, accuracy@5=98.20%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 054-200-th epoch] Time Left: [03:23:26], LR=0.0830655932661826\n",
      "*SEARCH* [2023-01-09 08:29:33] [054-200][000/196] Time 4.69 (4.69) Data 4.31 (4.31) Base [Loss 0.731 (0.731)  Prec@1 73.83 (73.83) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 08:29:50] [054-200][050/196] Time 0.33 (0.42) Data 0.00 (0.08) Base [Loss 0.689 (0.702)  Prec@1 73.05 (75.69) Prec@5 98.83 (98.55)]\n",
      "*SEARCH* [2023-01-09 08:30:06] [054-200][100/196] Time 0.32 (0.37) Data 0.00 (0.04) Base [Loss 0.679 (0.699)  Prec@1 76.95 (75.80) Prec@5 97.66 (98.39)]\n",
      "*SEARCH* [2023-01-09 08:30:23] [054-200][150/196] Time 0.34 (0.36) Data 0.00 (0.03) Base [Loss 0.857 (0.707)  Prec@1 72.27 (75.63) Prec@5 96.09 (98.32)]\n",
      "*SEARCH* [2023-01-09 08:30:38] [054-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.571 (0.703)  Prec@1 78.75 (75.72) Prec@5 100.00 (98.35)]\n",
      "[054-200] searching : loss=0.70, accuracy@1=75.72%, accuracy@5=98.35%, time-cost=3851.8 s\n",
      "[054-200] evaluate  : loss=0.80, accuracy@1=72.59%, accuracy@5=97.82%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 055-200-th epoch] Time Left: [03:21:21], LR=0.08247240241650919\n",
      "*SEARCH* [2023-01-09 08:30:56] [055-200][000/196] Time 4.62 (4.62) Data 4.22 (4.22) Base [Loss 0.668 (0.668)  Prec@1 73.05 (73.05) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:31:14] [055-200][050/196] Time 0.35 (0.44) Data 0.00 (0.08) Base [Loss 0.716 (0.710)  Prec@1 75.78 (75.43) Prec@5 98.44 (98.41)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 08:31:32] [055-200][100/196] Time 0.35 (0.39) Data 0.00 (0.04) Base [Loss 0.695 (0.695)  Prec@1 74.61 (75.87) Prec@5 97.27 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:31:49] [055-200][150/196] Time 0.36 (0.38) Data 0.00 (0.03) Base [Loss 0.684 (0.696)  Prec@1 77.34 (75.94) Prec@5 98.44 (98.46)]\n",
      "*SEARCH* [2023-01-09 08:32:05] [055-200][195/196] Time 0.16 (0.37) Data 0.00 (0.02) Base [Loss 0.677 (0.698)  Prec@1 75.00 (75.79) Prec@5 97.50 (98.46)]\n",
      "[055-200] searching : loss=0.70, accuracy@1=75.79%, accuracy@5=98.46%, time-cost=3925.5 s\n",
      "[055-200] evaluate  : loss=0.77, accuracy@1=72.83%, accuracy@5=98.14%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 056-200-th epoch] Time Left: [03:30:00], LR=0.08187119948743449\n",
      "*SEARCH* [2023-01-09 08:32:24] [056-200][000/196] Time 4.51 (4.51) Data 4.11 (4.11) Base [Loss 0.684 (0.684)  Prec@1 76.56 (76.56) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:32:41] [056-200][050/196] Time 0.33 (0.42) Data 0.00 (0.08) Base [Loss 0.641 (0.712)  Prec@1 76.17 (74.86) Prec@5 98.44 (98.54)]\n",
      "*SEARCH* [2023-01-09 08:32:57] [056-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.643 (0.701)  Prec@1 76.56 (75.40) Prec@5 98.83 (98.49)]\n",
      "*SEARCH* [2023-01-09 08:33:14] [056-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.650 (0.703)  Prec@1 74.22 (75.43) Prec@5 98.44 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:33:29] [056-200][195/196] Time 0.14 (0.35) Data 0.00 (0.02) Base [Loss 0.692 (0.701)  Prec@1 77.50 (75.52) Prec@5 97.50 (98.43)]\n",
      "[056-200] searching : loss=0.70, accuracy@1=75.52%, accuracy@5=98.43%, time-cost=3995.4 s\n",
      "[056-200] evaluate  : loss=0.80, accuracy@1=72.24%, accuracy@5=97.89%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 057-200-th epoch] Time Left: [03:17:42], LR=0.08126213281678528\n",
      "*SEARCH* [2023-01-09 08:33:47] [057-200][000/196] Time 4.53 (4.53) Data 4.11 (4.11) Base [Loss 0.793 (0.793)  Prec@1 73.05 (73.05) Prec@5 96.88 (96.88)]\n",
      "*SEARCH* [2023-01-09 08:34:03] [057-200][050/196] Time 0.32 (0.41) Data 0.00 (0.08) Base [Loss 0.636 (0.708)  Prec@1 74.61 (75.24) Prec@5 98.83 (98.54)]\n",
      "*SEARCH* [2023-01-09 08:34:19] [057-200][100/196] Time 0.32 (0.36) Data 0.00 (0.04) Base [Loss 0.728 (0.706)  Prec@1 76.56 (75.46) Prec@5 98.44 (98.46)]\n",
      "*SEARCH* [2023-01-09 08:34:35] [057-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.727 (0.707)  Prec@1 75.78 (75.48) Prec@5 98.83 (98.42)]\n",
      "*SEARCH* [2023-01-09 08:34:49] [057-200][195/196] Time 0.12 (0.34) Data 0.00 (0.02) Base [Loss 0.809 (0.702)  Prec@1 76.25 (75.65) Prec@5 97.50 (98.42)]\n",
      "[057-200] searching : loss=0.70, accuracy@1=75.65%, accuracy@5=98.42%, time-cost=4063.1 s\n",
      "[057-200] evaluate  : loss=0.76, accuracy@1=73.55%, accuracy@5=98.10%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 058-200-th epoch] Time Left: [03:14:19], LR=0.08064535268264883\n",
      "*SEARCH* [2023-01-09 08:35:09] [058-200][000/196] Time 4.67 (4.67) Data 4.30 (4.30) Base [Loss 0.756 (0.756)  Prec@1 76.17 (76.17) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:35:26] [058-200][050/196] Time 0.33 (0.42) Data 0.00 (0.08) Base [Loss 0.713 (0.699)  Prec@1 73.83 (75.96) Prec@5 98.44 (98.48)]\n",
      "*SEARCH* [2023-01-09 08:35:43] [058-200][100/196] Time 0.34 (0.38) Data 0.00 (0.04) Base [Loss 0.729 (0.696)  Prec@1 76.17 (75.87) Prec@5 98.44 (98.47)]\n",
      "*SEARCH* [2023-01-09 08:36:00] [058-200][150/196] Time 0.35 (0.37) Data 0.00 (0.03) Base [Loss 0.644 (0.692)  Prec@1 75.00 (75.98) Prec@5 99.22 (98.41)]\n",
      "*SEARCH* [2023-01-09 08:36:16] [058-200][195/196] Time 0.15 (0.36) Data 0.00 (0.02) Base [Loss 0.727 (0.696)  Prec@1 75.00 (75.88) Prec@5 98.75 (98.40)]\n",
      "[058-200] searching : loss=0.70, accuracy@1=75.88%, accuracy@5=98.40%, time-cost=4135.2 s\n",
      "[058-200] evaluate  : loss=0.78, accuracy@1=72.86%, accuracy@5=98.12%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 059-200-th epoch] Time Left: [03:20:13], LR=0.08002101126629421\n",
      "*SEARCH* [2023-01-09 08:36:34] [059-200][000/196] Time 4.79 (4.79) Data 4.38 (4.38) Base [Loss 0.654 (0.654)  Prec@1 77.73 (77.73) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2023-01-09 08:36:51] [059-200][050/196] Time 0.33 (0.41) Data 0.00 (0.09) Base [Loss 0.736 (0.690)  Prec@1 75.39 (76.16) Prec@5 98.05 (98.50)]\n",
      "*SEARCH* [2023-01-09 08:37:07] [059-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.679 (0.693)  Prec@1 76.17 (75.93) Prec@5 97.66 (98.47)]\n",
      "*SEARCH* [2023-01-09 08:37:24] [059-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.706 (0.695)  Prec@1 76.95 (75.96) Prec@5 99.61 (98.43)]\n",
      "*SEARCH* [2023-01-09 08:37:39] [059-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.842 (0.691)  Prec@1 68.75 (75.98) Prec@5 95.00 (98.44)]\n",
      "[059-200] searching : loss=0.69, accuracy@1=75.98%, accuracy@5=98.44%, time-cost=4205.1 s\n",
      "[059-200] evaluate  : loss=0.79, accuracy@1=72.84%, accuracy@5=98.08%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 060-200-th epoch] Time Left: [03:15:20], LR=0.07938926261462367\n",
      "*SEARCH* [2023-01-09 08:37:58] [060-200][000/196] Time 4.59 (4.59) Data 4.15 (4.15) Base [Loss 0.641 (0.641)  Prec@1 77.73 (77.73) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:38:16] [060-200][050/196] Time 0.35 (0.45) Data 0.00 (0.08) Base [Loss 0.734 (0.684)  Prec@1 75.39 (76.34) Prec@5 97.27 (98.41)]\n",
      "*SEARCH* [2023-01-09 08:38:33] [060-200][100/196] Time 0.34 (0.39) Data 0.00 (0.04) Base [Loss 0.639 (0.687)  Prec@1 77.73 (76.08) Prec@5 99.22 (98.46)]\n",
      "*SEARCH* [2023-01-09 08:38:50] [060-200][150/196] Time 0.32 (0.37) Data 0.00 (0.03) Base [Loss 0.730 (0.691)  Prec@1 75.78 (75.96) Prec@5 98.05 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:39:05] [060-200][195/196] Time 0.14 (0.36) Data 0.00 (0.02) Base [Loss 0.673 (0.691)  Prec@1 73.75 (75.96) Prec@5 98.75 (98.42)]\n",
      "[060-200] searching : loss=0.69, accuracy@1=75.96%, accuracy@5=98.42%, time-cost=4277.0 s\n",
      "[060-200] evaluate  : loss=0.84, accuracy@1=70.81%, accuracy@5=97.95%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 061-200-th epoch] Time Left: [03:20:16], LR=0.07875026260216395\n",
      "*SEARCH* [2023-01-09 08:39:25] [061-200][000/196] Time 4.83 (4.83) Data 4.43 (4.43) Base [Loss 0.686 (0.686)  Prec@1 75.39 (75.39) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:39:43] [061-200][050/196] Time 0.37 (0.45) Data 0.00 (0.09) Base [Loss 0.663 (0.694)  Prec@1 75.78 (76.25) Prec@5 99.22 (98.51)]\n",
      "*SEARCH* [2023-01-09 08:40:01] [061-200][100/196] Time 0.37 (0.41) Data 0.00 (0.04) Base [Loss 0.622 (0.684)  Prec@1 76.95 (76.29) Prec@5 98.44 (98.59)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 08:40:20] [061-200][150/196] Time 0.38 (0.40) Data 0.00 (0.03) Base [Loss 0.765 (0.685)  Prec@1 73.44 (76.24) Prec@5 98.83 (98.49)]\n",
      "*SEARCH* [2023-01-09 08:40:36] [061-200][195/196] Time 0.16 (0.39) Data 0.00 (0.02) Base [Loss 0.730 (0.682)  Prec@1 70.00 (76.43) Prec@5 98.75 (98.52)]\n",
      "[061-200] searching : loss=0.68, accuracy@1=76.43%, accuracy@5=98.52%, time-cost=4354.1 s\n",
      "[061-200] evaluate  : loss=0.81, accuracy@1=71.71%, accuracy@5=98.29%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 062-200-th epoch] Time Left: [03:28:31], LR=0.07810416889260655\n",
      "*SEARCH* [2023-01-09 08:40:56] [062-200][000/196] Time 5.27 (5.27) Data 4.83 (4.83) Base [Loss 0.670 (0.670)  Prec@1 76.56 (76.56) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 08:41:14] [062-200][050/196] Time 0.38 (0.46) Data 0.00 (0.10) Base [Loss 0.674 (0.680)  Prec@1 77.73 (76.76) Prec@5 98.44 (98.54)]\n",
      "*SEARCH* [2023-01-09 08:41:33] [062-200][100/196] Time 0.36 (0.42) Data 0.00 (0.05) Base [Loss 0.701 (0.684)  Prec@1 75.39 (76.37) Prec@5 98.83 (98.52)]\n",
      "*SEARCH* [2023-01-09 08:41:51] [062-200][150/196] Time 0.32 (0.40) Data 0.00 (0.03) Base [Loss 0.695 (0.689)  Prec@1 73.05 (76.06) Prec@5 98.44 (98.49)]\n",
      "*SEARCH* [2023-01-09 08:42:05] [062-200][195/196] Time 0.13 (0.38) Data 0.00 (0.02) Base [Loss 0.854 (0.689)  Prec@1 71.25 (76.08) Prec@5 97.50 (98.46)]\n",
      "[062-200] searching : loss=0.69, accuracy@1=76.08%, accuracy@5=98.46%, time-cost=4429.6 s\n",
      "[062-200] evaluate  : loss=0.76, accuracy@1=73.59%, accuracy@5=98.14%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 063-200-th epoch] Time Left: [03:22:51], LR=0.0774511408999066\n",
      "*SEARCH* [2023-01-09 08:42:24] [063-200][000/196] Time 4.90 (4.90) Data 4.51 (4.51) Base [Loss 0.642 (0.642)  Prec@1 78.52 (78.52) Prec@5 99.61 (99.61)]\n",
      "*SEARCH* [2023-01-09 08:42:40] [063-200][050/196] Time 0.32 (0.41) Data 0.00 (0.09) Base [Loss 0.804 (0.681)  Prec@1 74.22 (76.52) Prec@5 97.66 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:42:56] [063-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.727 (0.682)  Prec@1 75.00 (76.43) Prec@5 98.05 (98.51)]\n",
      "*SEARCH* [2023-01-09 08:43:12] [063-200][150/196] Time 0.32 (0.35) Data 0.00 (0.03) Base [Loss 0.568 (0.678)  Prec@1 80.47 (76.57) Prec@5 99.22 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:43:27] [063-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 1.004 (0.679)  Prec@1 66.25 (76.55) Prec@5 96.25 (98.47)]\n",
      "[063-200] searching : loss=0.68, accuracy@1=76.55%, accuracy@5=98.47%, time-cost=4498.3 s\n",
      "[063-200] evaluate  : loss=0.77, accuracy@1=73.27%, accuracy@5=98.09%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 064-200-th epoch] Time Left: [03:07:32], LR=0.07679133974894983\n",
      "*SEARCH* [2023-01-09 08:43:47] [064-200][000/196] Time 4.57 (4.57) Data 4.17 (4.17) Base [Loss 0.832 (0.832)  Prec@1 71.88 (71.88) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:44:04] [064-200][050/196] Time 0.35 (0.43) Data 0.00 (0.08) Base [Loss 0.728 (0.673)  Prec@1 75.39 (76.70) Prec@5 97.66 (98.61)]\n",
      "*SEARCH* [2023-01-09 08:44:22] [064-200][100/196] Time 0.35 (0.40) Data 0.00 (0.04) Base [Loss 0.772 (0.679)  Prec@1 73.44 (76.31) Prec@5 97.66 (98.57)]\n",
      "*SEARCH* [2023-01-09 08:44:40] [064-200][150/196] Time 0.36 (0.38) Data 0.00 (0.03) Base [Loss 0.594 (0.682)  Prec@1 77.73 (76.31) Prec@5 99.22 (98.52)]\n",
      "*SEARCH* [2023-01-09 08:44:55] [064-200][195/196] Time 0.15 (0.37) Data 0.00 (0.02) Base [Loss 0.779 (0.681)  Prec@1 73.75 (76.35) Prec@5 95.00 (98.49)]\n",
      "[064-200] searching : loss=0.68, accuracy@1=76.35%, accuracy@5=98.49%, time-cost=4572.3 s\n",
      "[064-200] evaluate  : loss=0.76, accuracy@1=73.45%, accuracy@5=98.30%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 065-200-th epoch] Time Left: [03:18:12], LR=0.07612492823579745\n",
      "*SEARCH* [2023-01-09 08:45:15] [065-200][000/196] Time 5.18 (5.18) Data 4.75 (4.75) Base [Loss 0.594 (0.594)  Prec@1 76.17 (76.17) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 08:45:33] [065-200][050/196] Time 0.36 (0.45) Data 0.00 (0.09) Base [Loss 0.700 (0.671)  Prec@1 78.12 (76.75) Prec@5 98.83 (98.64)]\n",
      "*SEARCH* [2023-01-09 08:45:51] [065-200][100/196] Time 0.37 (0.41) Data 0.00 (0.05) Base [Loss 0.594 (0.675)  Prec@1 78.91 (76.63) Prec@5 100.00 (98.57)]\n",
      "*SEARCH* [2023-01-09 08:46:09] [065-200][150/196] Time 0.35 (0.39) Data 0.00 (0.03) Base [Loss 0.694 (0.679)  Prec@1 74.61 (76.42) Prec@5 99.22 (98.55)]\n",
      "*SEARCH* [2023-01-09 08:46:25] [065-200][195/196] Time 0.16 (0.38) Data 0.00 (0.02) Base [Loss 0.657 (0.684)  Prec@1 75.00 (76.31) Prec@5 100.00 (98.46)]\n",
      "[065-200] searching : loss=0.68, accuracy@1=76.31%, accuracy@5=98.46%, time-cost=4648.3 s\n",
      "[065-200] evaluate  : loss=0.75, accuracy@1=74.50%, accuracy@5=98.22%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 065-200-th epoch : find the highest test accuracy : 74.50%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 066-200-th epoch] Time Left: [03:18:57], LR=0.07545207078751857\n",
      "*SEARCH* [2023-01-09 08:46:44] [066-200][000/196] Time 4.72 (4.72) Data 4.30 (4.30) Base [Loss 0.618 (0.618)  Prec@1 77.73 (77.73) Prec@5 100.00 (100.00)]\n",
      "*SEARCH* [2023-01-09 08:47:01] [066-200][050/196] Time 0.35 (0.44) Data 0.00 (0.08) Base [Loss 0.719 (0.675)  Prec@1 77.34 (76.84) Prec@5 96.88 (98.55)]\n",
      "*SEARCH* [2023-01-09 08:47:19] [066-200][100/196] Time 0.35 (0.39) Data 0.00 (0.04) Base [Loss 0.624 (0.684)  Prec@1 80.86 (76.37) Prec@5 99.61 (98.46)]\n",
      "*SEARCH* [2023-01-09 08:47:36] [066-200][150/196] Time 0.35 (0.38) Data 0.00 (0.03) Base [Loss 0.616 (0.684)  Prec@1 76.56 (76.41) Prec@5 99.22 (98.47)]\n",
      "*SEARCH* [2023-01-09 08:47:52] [066-200][195/196] Time 0.21 (0.37) Data 0.00 (0.02) Base [Loss 0.787 (0.682)  Prec@1 70.00 (76.40) Prec@5 100.00 (98.45)]\n",
      "[066-200] searching : loss=0.68, accuracy@1=76.40%, accuracy@5=98.45%, time-cost=4722.2 s\n",
      "[066-200] evaluate  : loss=0.77, accuracy@1=73.51%, accuracy@5=98.11%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 067-200-th epoch] Time Left: [03:13:21], LR=0.07477293342162038\n",
      "*SEARCH* [2023-01-09 08:48:11] [067-200][000/196] Time 4.83 (4.83) Data 4.42 (4.42) Base [Loss 0.705 (0.705)  Prec@1 76.17 (76.17) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:48:28] [067-200][050/196] Time 0.33 (0.42) Data 0.00 (0.09) Base [Loss 0.603 (0.689)  Prec@1 80.86 (76.17) Prec@5 99.61 (98.35)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2023-01-09 08:48:45] [067-200][100/196] Time 0.33 (0.38) Data 0.00 (0.04) Base [Loss 0.606 (0.681)  Prec@1 80.47 (76.39) Prec@5 98.44 (98.45)]\n",
      "*SEARCH* [2023-01-09 08:49:01] [067-200][150/196] Time 0.33 (0.36) Data 0.00 (0.03) Base [Loss 0.699 (0.676)  Prec@1 76.17 (76.55) Prec@5 98.44 (98.46)]\n",
      "*SEARCH* [2023-01-09 08:49:16] [067-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.785 (0.676)  Prec@1 68.75 (76.55) Prec@5 98.75 (98.44)]\n",
      "[067-200] searching : loss=0.68, accuracy@1=76.55%, accuracy@5=98.44%, time-cost=4792.2 s\n",
      "[067-200] evaluate  : loss=0.74, accuracy@1=74.95%, accuracy@5=98.29%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "<<<--->>> The 067-200-th epoch : find the highest test accuracy : 74.95%.\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth exist, delete is at first before saving\n",
      "copy the file from results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth into results/tmp/train_w32_a32/checkpoint/seed-68245-best.pth\n",
      "\n",
      "[Search the 068-200-th epoch] Time Left: [03:03:07], LR=0.07408768370508577\n",
      "*SEARCH* [2023-01-09 08:49:34] [068-200][000/196] Time 4.49 (4.49) Data 4.07 (4.07) Base [Loss 0.601 (0.601)  Prec@1 79.69 (79.69) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 08:49:52] [068-200][050/196] Time 0.33 (0.43) Data 0.00 (0.08) Base [Loss 0.668 (0.672)  Prec@1 78.52 (76.65) Prec@5 98.05 (98.58)]\n",
      "*SEARCH* [2023-01-09 08:50:08] [068-200][100/196] Time 0.33 (0.38) Data 0.00 (0.04) Base [Loss 0.702 (0.674)  Prec@1 76.17 (76.50) Prec@5 98.44 (98.53)]\n",
      "*SEARCH* [2023-01-09 08:50:25] [068-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.725 (0.676)  Prec@1 74.22 (76.53) Prec@5 98.44 (98.54)]\n",
      "*SEARCH* [2023-01-09 08:50:39] [068-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.731 (0.676)  Prec@1 73.75 (76.53) Prec@5 97.50 (98.47)]\n",
      "[068-200] searching : loss=0.68, accuracy@1=76.53%, accuracy@5=98.47%, time-cost=4862.2 s\n",
      "[068-200] evaluate  : loss=0.72, accuracy@1=74.64%, accuracy@5=98.49%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 069-200-th epoch] Time Left: [03:01:51], LR=0.07339649071302867\n",
      "*SEARCH* [2023-01-09 08:50:57] [069-200][000/196] Time 4.45 (4.45) Data 4.07 (4.07) Base [Loss 0.773 (0.773)  Prec@1 72.66 (72.66) Prec@5 98.05 (98.05)]\n",
      "*SEARCH* [2023-01-09 08:51:14] [069-200][050/196] Time 0.32 (0.42) Data 0.00 (0.08) Base [Loss 0.676 (0.670)  Prec@1 76.56 (76.85) Prec@5 98.83 (98.48)]\n",
      "*SEARCH* [2023-01-09 08:51:31] [069-200][100/196] Time 0.33 (0.37) Data 0.00 (0.04) Base [Loss 0.749 (0.675)  Prec@1 73.05 (76.30) Prec@5 97.66 (98.48)]\n",
      "*SEARCH* [2023-01-09 08:51:47] [069-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.608 (0.669)  Prec@1 80.47 (76.62) Prec@5 99.22 (98.53)]\n",
      "*SEARCH* [2023-01-09 08:52:01] [069-200][195/196] Time 0.13 (0.35) Data 0.00 (0.02) Base [Loss 0.634 (0.671)  Prec@1 77.50 (76.62) Prec@5 98.75 (98.50)]\n",
      "[069-200] searching : loss=0.67, accuracy@1=76.62%, accuracy@5=98.50%, time-cost=4930.9 s\n",
      "[069-200] evaluate  : loss=0.77, accuracy@1=73.63%, accuracy@5=98.25%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 070-200-th epoch] Time Left: [02:58:50], LR=0.07269952498697733\n",
      "*SEARCH* [2023-01-09 08:52:20] [070-200][000/196] Time 4.57 (4.57) Data 4.18 (4.18) Base [Loss 0.733 (0.733)  Prec@1 75.00 (75.00) Prec@5 99.22 (99.22)]\n",
      "*SEARCH* [2023-01-09 08:52:37] [070-200][050/196] Time 0.34 (0.42) Data 0.00 (0.08) Base [Loss 0.679 (0.669)  Prec@1 76.17 (76.72) Prec@5 98.83 (98.61)]\n",
      "*SEARCH* [2023-01-09 08:52:54] [070-200][100/196] Time 0.32 (0.38) Data 0.00 (0.04) Base [Loss 0.604 (0.663)  Prec@1 78.91 (76.83) Prec@5 98.83 (98.56)]\n",
      "*SEARCH* [2023-01-09 08:53:10] [070-200][150/196] Time 0.32 (0.36) Data 0.00 (0.03) Base [Loss 0.638 (0.670)  Prec@1 76.17 (76.59) Prec@5 99.61 (98.55)]\n",
      "*SEARCH* [2023-01-09 08:53:24] [070-200][195/196] Time 0.12 (0.35) Data 0.00 (0.02) Base [Loss 0.547 (0.671)  Prec@1 81.25 (76.58) Prec@5 100.00 (98.54)]\n",
      "[070-200] searching : loss=0.67, accuracy@1=76.58%, accuracy@5=98.54%, time-cost=5000.0 s\n",
      "[070-200] evaluate  : loss=0.80, accuracy@1=72.36%, accuracy@5=98.13%\n",
      "Find results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\n",
      "Find results/tmp/train_w32_a32/seed-68245-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into results/tmp/train_w32_a32/seed-68245-last-info.pth\n",
      "\n",
      "[Search the 071-200-th epoch] Time Left: [02:56:23], LR=0.07199695849279575\n",
      "*SEARCH* [2023-01-09 08:53:42] [071-200][000/196] Time 4.45 (4.45) Data 4.08 (4.08) Base [Loss 0.720 (0.720)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2023-01-09 08:53:58] [071-200][050/196] Time 0.32 (0.40) Data 0.00 (0.08) Base [Loss 0.673 (0.657)  Prec@1 76.17 (76.88) Prec@5 98.44 (98.65)]\n"
     ]
    }
   ],
   "source": [
    "w, a = 32, 32\n",
    "\n",
    "xxargs = deepcopy(args)\n",
    "xxargs.save_dir = os.path.join(xxargs.save_dir, \"train_w{:}_a{:}\".format(w,a))\n",
    "xxargs.workers = 16\n",
    "\n",
    "logger = prepare_logger(xxargs)\n",
    "\n",
    "cifar_train_config_path = xxargs.train_config_path\n",
    "\n",
    "## prepare dataloader\n",
    "train_data, test_data, xshape, class_num = get_datasets(xxargs.dataset, xxargs.data_path, -1)\n",
    "config = load_config(cifar_train_config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=xxargs.workers,\n",
    "        pin_memory=True,)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_data,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=xxargs.workers,\n",
    "            pin_memory=True,)\n",
    "\n",
    "logger.log(\"||||||| {:10s} ||||||| Train-Loader-Num={:}, Test-Loader-Num={:}, batch size={:}\".format(\n",
    "            xxargs.dataset, len(train_loader), len(test_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xxargs.dataset, config))\n",
    "\n",
    "## prepare model, optim, loss\n",
    "search_space = get_search_spaces(\"cell\", xargs.search_space_name)\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": xargs.channel,\n",
    "        \"N\": xargs.num_cells,\n",
    "        \"max_nodes\": xargs.max_nodes,\n",
    "        \"num_classes\": class_num,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": bool(xargs.track_running_stats),\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "network = search_model.cuda()\n",
    "network.arch_cache = best_arch\n",
    "\n",
    "for m in network.modules():\n",
    "    if isinstance(m, QConv):\n",
    "        m.set_q_range(w, a)\n",
    "\n",
    "for layer in network.children(): # reset params\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()\n",
    "w_optimizer, w_scheduler, criterion = get_optim_scheduler(network.parameters(), config)\n",
    "\n",
    "last_info, model_base_path, model_best_path = (\n",
    "    logger.path(\"info\"),\n",
    "    logger.path(\"model\"),\n",
    "    logger.path(\"best\"),\n",
    ")\n",
    "\n",
    "start_epoch, valid_accuracies = 0, {\"best\": -1}\n",
    "\n",
    "start_time, search_time, epoch_time, total_epoch = (\n",
    "    time.time(),\n",
    "    AverageMeter(),\n",
    "    AverageMeter(),\n",
    "    config.epochs + config.warmup,\n",
    ")\n",
    "for epoch in range(0, total_epoch):\n",
    "    w_scheduler.update(epoch, 0.0)\n",
    "    need_time = \"Time Left: {:}\".format(\n",
    "        convert_secs2time(epoch_time.val * (total_epoch - epoch), True)\n",
    "    )\n",
    "    epoch_str = \"{:03d}-{:03d}\".format(epoch, total_epoch)\n",
    "    logger.log(\n",
    "        \"\\n[Search the {:}-th epoch] {:}, LR={:}\".format(\n",
    "            epoch_str, need_time, min(w_scheduler.get_lr())\n",
    "        )\n",
    "    )\n",
    "\n",
    "    search_w_loss, search_w_top1, search_w_top5 = train_func_one_arch(\n",
    "        train_loader,\n",
    "        network,\n",
    "        criterion,\n",
    "        w_scheduler,\n",
    "        w_optimizer,\n",
    "        epoch_str,\n",
    "        xxargs.print_freq,\n",
    "        logger,\n",
    "    )\n",
    "    search_time.update(time.time() - start_time)\n",
    "    logger.log(\n",
    "        \"[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\".format(\n",
    "            epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum\n",
    "        )\n",
    "    )\n",
    "    valid_a_loss, valid_a_top1, valid_a_top5 = valid_func_one_arch(\n",
    "        test_loader, network, criterion\n",
    "    )\n",
    "    logger.log(\n",
    "        \"[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\".format(\n",
    "            epoch_str, valid_a_loss, valid_a_top1, valid_a_top5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # check the best accuracy\n",
    "    valid_accuracies[epoch] = valid_a_top1\n",
    "    if valid_a_top1 > valid_accuracies[\"best\"]:\n",
    "        valid_accuracies[\"best\"] = valid_a_top1\n",
    "        find_best = True\n",
    "    else:\n",
    "        find_best = False\n",
    "\n",
    "    # save checkpoint\n",
    "    save_path = save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"args\": deepcopy(xxargs),\n",
    "            \"search_model\": search_model.state_dict(),\n",
    "            \"w_optimizer\": w_optimizer.state_dict(),\n",
    "            \"w_scheduler\": w_scheduler.state_dict(),\n",
    "            \"valid_accuracies\": valid_accuracies,\n",
    "            \"arch\":search_model.arch_cache,\n",
    "        },\n",
    "        model_base_path,\n",
    "        logger,\n",
    "    )\n",
    "    last_info = save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"args\": deepcopy(xxargs),\n",
    "            \"last_checkpoint\": save_path,\n",
    "        },\n",
    "        logger.path(\"info\"),\n",
    "        logger,\n",
    "    )\n",
    "    if find_best:\n",
    "        logger.log(\n",
    "            \"<<<--->>> The {:}-th epoch : find the highest test accuracy : {:.2f}%.\".format(\n",
    "                epoch_str, valid_a_top1\n",
    "            )\n",
    "        )\n",
    "        copy_checkpoint(model_base_path, model_best_path, logger)\n",
    "    # measure elapsed time\n",
    "    epoch_time.update(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405bb17",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "259c78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_normal_fanin_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.affine:\n",
    "            nn.init.ones_(m.weight.data)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def kaiming_normal_fanout_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.affine:\n",
    "            nn.init.ones_(m.weight.data)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_model(model, method='kaiming_norm_fanin'):\n",
    "    if method == 'kaiming_norm_fanin':\n",
    "        model.apply(kaiming_normal_fanin_init)\n",
    "    elif method == 'kaiming_norm_fanout':\n",
    "        model.apply(kaiming_normal_fanout_init)\n",
    "    return model\n",
    "\n",
    "def pca_eig_diag(xloader, network, num_batch=1):\n",
    "    device = torch.cuda.current_device()\n",
    "    network.train()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feat_list = []\n",
    "        for i, (inputs, targets) in enumerate(xloader):\n",
    "            if num_batch > 0 and i >= num_batch: break\n",
    "\n",
    "            inputs = inputs.cuda(device=device, non_blocking=True)\n",
    "            network.zero_grad()\n",
    "            inputs_ = inputs.clone().cuda(device=device, non_blocking=True)\n",
    "#             inputs_ = torch.randn_like(inputs)\n",
    "            _ = network(inputs_)\n",
    "            feat = network.last_feature_map\n",
    "            feat = feat.mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "            b,c,h,w = feat.size()\n",
    "            feat_list.append(feat.permute(0,2,3,1).contiguous().view(b*h*w,c))\n",
    "\n",
    "        feat = torch.cat(feat_list, dim=0)\n",
    "        m = feat.mean(dim=0, keepdim=True)\n",
    "        feat = feat - m\n",
    "        sigma = torch.mm(feat.transpose(1,0),feat) / (feat.size(0))\n",
    "        u, s, v = torch.svd(sigma)\n",
    "        prob_s = s / s.sum()\n",
    "        score = (-prob_s)*torch.log(prob_s+1e-8)\n",
    "        score = score.sum()\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return score.item()\n",
    "\n",
    "def search_find_best(xloader, network, lrc_model, archs, w_a_bits, reinit=True):\n",
    "    network.train()\n",
    "    pca_scores, ntk_scores, lr_scores = dict(), dict(), dict()\n",
    "    for w,a in w_a_bits:\n",
    "        key = \"w{:}a{:}\".format(w,a)\n",
    "        pca_scores[key] = []\n",
    "        ntk_scores[key] = []\n",
    "        lr_scores[key] = []\n",
    "    \n",
    "    for i, arch in enumerate(tqdm.tqdm(archs)):\n",
    "        # random sampling\n",
    "#         arch = network.module.random_genotype(True)\n",
    "        network.arch_cache = arch\n",
    "    \n",
    "        pca_score_tmp, ntk_score_tmp, lr_score_tmp = dict(), dict(), dict()\n",
    "        for w,a in w_a_bits:\n",
    "            key = \"w{:}a{:}\".format(w,a)\n",
    "            pca_score_tmp[key] = []\n",
    "            ntk_score_tmp[key] = []\n",
    "            lr_score_tmp[key] = []\n",
    "        \n",
    "        for _ in range(3):\n",
    "            if reinit:\n",
    "                init_model(network)\n",
    "            for w,a in w_a_bits:\n",
    "                key = \"w{:}a{:}\".format(w,a)\n",
    "                for m in network.modules():\n",
    "                    if isinstance(m, QConv):\n",
    "                        m.set_q_range(w, a)\n",
    "                # pca score\n",
    "                score = pca_eig_diag(xloader, network)\n",
    "                pca_score_tmp[key].append(score)\n",
    "                # ntk score\n",
    "                score = get_ntk_n(xloader, [network], recalbn=0, train_mode=True, num_batch=1)[0]\n",
    "                ntk_score_tmp[key].append(-score)\n",
    "                # lr score\n",
    "                lrc_model.reinit(models=[network], seed=xargs.rand_seed)\n",
    "                score = lrc_model.forward_batch_sample()\n",
    "                lr_score_tmp[key].append(score)\n",
    "                lrc_model.clear()\n",
    "        \n",
    "        \n",
    "        for w,a in w_a_bits:\n",
    "            key = \"w{:}a{:}\".format(w,a)\n",
    "            pca_scores[key].append(np.mean(pca_score_tmp[key]))\n",
    "            ntk_scores[key].append(np.mean(ntk_score_tmp[key]))\n",
    "            lr_scores[key].append(np.mean(lr_score_tmp[key]))\n",
    "        \n",
    "    return pca_scores, ntk_scores, lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad28c7",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bbfe256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=results/tmp, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "arch_nas_dataset : ../../NAS-Bench-201-v1_1-096897.pth\n",
      "channel          : 3\n",
      "config_path      : ../../configs/nas-benchmark/algos/RANDOM.config\n",
      "data_path        : ../../cifar.python\n",
      "dataset          : cifar10\n",
      "max_nodes        : 4\n",
      "num_cells        : 5\n",
      "print_freq       : 50\n",
      "rand_seed        : 76322\n",
      "save_dir         : ./results/tmp\n",
      "search_space_name : nas-bench-201\n",
      "select_num       : 100\n",
      "track_running_stats : 0\n",
      "train_config_path : ../../configs/nas-benchmark/CIFAR.config\n",
      "workers          : 0\n",
      "Python  Version  : 3.8.8 (default, Feb 24 2021, 21:46:12)  [GCC 7.3.0]\n",
      "Pillow  Version  : 8.1.2\n",
      "PyTorch Version  : 1.8.1\n",
      "cuDNN   Version  : 8005\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "../../configs/nas-benchmark/algos/RANDOM.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=250, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, Valid-Loader-Num=49, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=250, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "logger = prepare_logger(args)\n",
    "\n",
    "## data\n",
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(xargs.config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "search_loader, train_loader, valid_loader = get_nas_search_loaders(train_data,\n",
    "                                                        valid_data,\n",
    "                                                        xargs.dataset,\n",
    "                                                        \"../../configs/nas-benchmark/\",\n",
    "                                                        (config.batch_size, config.test_batch_size),\n",
    "                                                        xargs.workers)\n",
    "logger.log(\"||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\".format(\n",
    "            xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "\n",
    "# ## model\n",
    "search_space = get_search_spaces(\"cell\", xargs.search_space_name)\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": xargs.channel,\n",
    "        \"N\": xargs.num_cells,\n",
    "        \"max_nodes\": xargs.max_nodes,\n",
    "        \"num_classes\": class_num,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": bool(xargs.track_running_stats),\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "\n",
    "if 'api' not in vars():\n",
    "    if xargs.arch_nas_dataset is None:\n",
    "        api = None\n",
    "    else:\n",
    "        api = API(xargs.arch_nas_dataset)\n",
    "    logger.log(\"{:} create API = {:} done\".format(time_string(), api))\n",
    "\n",
    "    last_info, model_base_path, model_best_path = (\n",
    "        logger.path(\"info\"),\n",
    "        logger.path(\"model\"),\n",
    "        logger.path(\"best\"),\n",
    "    )\n",
    "\n",
    "network = search_model.cuda()\n",
    "\n",
    "## LRC\n",
    "lrc_model = Linear_Region_Collector(input_size=(100, 3, 3, 3), sample_batch=3, dataset=xargs.dataset, data_path=xargs.data_path, seed=xargs.rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ca428b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000 0.335 0.564 0.814 0.938 0.861 0.857 0.674 0.359 0.494 0.296 0.694\n",
      "  0.347 0.922 0.394 0.969 0.852 0.721 0.324 0.242 0.261 0.849 0.243 0.453\n",
      "  0.612 0.233 0.646 0.491 0.272 0.855 0.886 0.847 0.473 0.366 0.661 0.625\n",
      "  0.656 0.402 0.920 0.823 0.380 0.484 0.449 0.663 0.906 0.747 0.242 0.297\n",
      "  0.194 0.337 0.357 0.231 0.411 0.794 0.722 0.960 0.672 0.335 0.325 0.521\n",
      "  0.665 0.487 0.762 0.401]\n",
      " [0.335 1.000 0.655 0.187 0.262 0.397 0.232 0.313 0.752 0.305 0.756 0.616\n",
      "  0.546 0.167 0.931 0.452 0.143 0.204 0.782 0.692 0.822 0.465 0.890 0.529\n",
      "  0.505 0.680 0.362 0.834 0.700 0.276 0.167 0.465 0.863 0.586 0.720 0.405\n",
      "  0.431 0.824 0.448 0.210 0.653 0.839 0.789 0.856 0.528 0.724 0.468 0.963\n",
      "  0.622 0.838 0.818 0.827 0.445 0.171 0.622 0.455 0.214 0.725 0.833 0.624\n",
      "  0.374 0.248 0.232 0.763]\n",
      " [0.564 0.655 1.000 0.714 0.661 0.584 0.449 0.498 0.887 0.351 0.647 0.957\n",
      "  0.685 0.620 0.686 0.664 0.659 0.790 0.831 0.587 0.713 0.802 0.669 0.921\n",
      "  0.948 0.584 0.404 0.762 0.678 0.503 0.670 0.790 0.649 0.603 0.965 0.426\n",
      "  0.715 0.757 0.591 0.343 0.690 0.903 0.665 0.813 0.673 0.875 0.474 0.729\n",
      "  0.517 0.761 0.808 0.667 0.499 0.694 0.938 0.663 0.427 0.625 0.709 0.944\n",
      "  0.540 0.297 0.658 0.669]\n",
      " [0.814 0.187 0.714 1.000 0.906 0.706 0.780 0.719 0.349 0.481 0.238 0.796\n",
      "  0.387 0.909 0.241 0.867 0.944 0.901 0.327 0.207 0.271 0.860 0.201 0.593\n",
      "  0.792 0.190 0.552 0.408 0.280 0.793 0.943 0.879 0.324 0.428 0.739 0.541\n",
      "  0.818 0.271 0.750 0.693 0.453 0.535 0.352 0.482 0.654 0.671 0.289 0.198\n",
      "  0.177 0.315 0.285 0.163 0.430 0.946 0.774 0.758 0.718 0.245 0.265 0.628\n",
      "  0.750 0.477 0.921 0.313]\n",
      " [0.938 0.262 0.661 0.906 1.000 0.783 0.799 0.674 0.401 0.417 0.235 0.791\n",
      "  0.289 0.990 0.292 0.933 0.951 0.894 0.341 0.163 0.243 0.877 0.187 0.612\n",
      "  0.774 0.152 0.523 0.422 0.219 0.807 0.982 0.938 0.403 0.313 0.696 0.494\n",
      "  0.641 0.326 0.815 0.717 0.372 0.533 0.367 0.608 0.865 0.694 0.168 0.245\n",
      "  0.129 0.336 0.304 0.187 0.338 0.898 0.822 0.911 0.607 0.332 0.251 0.658\n",
      "  0.595 0.391 0.818 0.312]\n",
      " [0.861 0.397 0.584 0.706 0.783 1.000 0.618 0.484 0.474 0.337 0.352 0.694\n",
      "  0.313 0.769 0.505 0.825 0.659 0.644 0.411 0.286 0.266 0.803 0.320 0.456\n",
      "  0.552 0.296 0.491 0.604 0.326 0.692 0.745 0.726 0.455 0.379 0.720 0.471\n",
      "  0.764 0.431 0.777 0.632 0.296 0.477 0.376 0.681 0.840 0.791 0.194 0.410\n",
      "  0.203 0.358 0.399 0.343 0.311 0.628 0.696 0.892 0.501 0.263 0.411 0.493\n",
      "  0.658 0.320 0.583 0.419]\n",
      " [0.857 0.232 0.449 0.780 0.799 0.618 1.000 0.900 0.179 0.802 0.311 0.503\n",
      "  0.467 0.806 0.245 0.881 0.848 0.585 0.206 0.312 0.343 0.831 0.240 0.340\n",
      "  0.498 0.297 0.879 0.412 0.322 0.980 0.753 0.757 0.405 0.564 0.531 0.864\n",
      "  0.650 0.347 0.933 0.975 0.567 0.461 0.539 0.515 0.706 0.541 0.520 0.158\n",
      "  0.337 0.309 0.298 0.166 0.672 0.849 0.537 0.765 0.930 0.351 0.295 0.395\n",
      "  0.813 0.822 0.891 0.391]\n",
      " [0.674 0.313 0.498 0.719 0.674 0.484 0.900 1.000 0.237 0.921 0.334 0.478\n",
      "  0.486 0.665 0.276 0.775 0.762 0.519 0.240 0.354 0.477 0.782 0.407 0.389\n",
      "  0.526 0.334 0.897 0.424 0.395 0.909 0.617 0.687 0.442 0.702 0.559 0.877\n",
      "  0.684 0.380 0.814 0.878 0.743 0.585 0.623 0.529 0.599 0.462 0.684 0.231\n",
      "  0.403 0.367 0.348 0.215 0.827 0.787 0.513 0.608 0.933 0.398 0.332 0.427\n",
      "  0.864 0.902 0.915 0.391]\n",
      " [0.359 0.752 0.887 0.349 0.401 0.474 0.179 0.237 1.000 0.186 0.714 0.798\n",
      "  0.664 0.349 0.789 0.422 0.341 0.527 0.902 0.637 0.744 0.605 0.746 0.871\n",
      "  0.770 0.650 0.243 0.798 0.715 0.256 0.372 0.555 0.687 0.520 0.845 0.271\n",
      "  0.455 0.884 0.417 0.109 0.608 0.855 0.672 0.851 0.627 0.808 0.431 0.844\n",
      "  0.553 0.801 0.919 0.782 0.393 0.370 0.801 0.537 0.142 0.669 0.782 0.869\n",
      "  0.267 0.116 0.309 0.708]\n",
      " [0.494 0.305 0.351 0.481 0.417 0.337 0.802 0.921 0.186 1.000 0.418 0.272\n",
      "  0.620 0.411 0.325 0.587 0.539 0.246 0.225 0.494 0.516 0.629 0.490 0.207\n",
      "  0.298 0.470 0.965 0.443 0.511 0.798 0.345 0.432 0.467 0.786 0.434 0.944\n",
      "  0.567 0.451 0.729 0.810 0.815 0.490 0.711 0.448 0.451 0.369 0.862 0.245\n",
      "  0.554 0.372 0.404 0.260 0.917 0.578 0.294 0.445 0.915 0.358 0.412 0.236\n",
      "  0.818 0.961 0.766 0.492]\n",
      " [0.296 0.756 0.647 0.238 0.235 0.352 0.311 0.334 0.714 0.418 1.000 0.538\n",
      "  0.854 0.202 0.815 0.371 0.224 0.212 0.907 0.978 0.897 0.501 0.844 0.585\n",
      "  0.478 0.980 0.459 0.934 0.960 0.331 0.187 0.401 0.809 0.824 0.667 0.466\n",
      "  0.477 0.819 0.491 0.275 0.763 0.766 0.876 0.665 0.448 0.663 0.710 0.850\n",
      "  0.951 0.953 0.853 0.964 0.522 0.256 0.533 0.383 0.346 0.816 0.977 0.614\n",
      "  0.446 0.340 0.327 0.949]\n",
      " [0.694 0.616 0.957 0.796 0.791 0.694 0.503 0.478 0.798 0.272 0.538 1.000\n",
      "  0.545 0.747 0.654 0.766 0.746 0.878 0.734 0.460 0.572 0.836 0.560 0.860\n",
      "  0.952 0.448 0.366 0.705 0.542 0.547 0.801 0.883 0.631 0.464 0.954 0.381\n",
      "  0.713 0.655 0.635 0.389 0.563 0.825 0.564 0.796 0.752 0.898 0.303 0.665\n",
      "  0.375 0.672 0.681 0.558 0.366 0.753 0.982 0.776 0.408 0.524 0.608 0.910\n",
      "  0.523 0.219 0.673 0.590]\n",
      " [0.347 0.546 0.685 0.387 0.289 0.313 0.467 0.486 0.664 0.620 0.854 0.545\n",
      "  1.000 0.272 0.687 0.426 0.382 0.318 0.764 0.904 0.778 0.580 0.739 0.557\n",
      "  0.526 0.888 0.662 0.800 0.915 0.458 0.276 0.401 0.699 0.852 0.684 0.670\n",
      "  0.549 0.824 0.569 0.406 0.861 0.699 0.875 0.589 0.419 0.679 0.867 0.652\n",
      "  0.881 0.776 0.852 0.737 0.706 0.436 0.506 0.401 0.571 0.602 0.860 0.562\n",
      "  0.569 0.542 0.528 0.901]\n",
      " [0.922 0.167 0.620 0.909 0.990 0.769 0.806 0.665 0.349 0.411 0.202 0.747\n",
      "  0.272 1.000 0.209 0.899 0.964 0.894 0.304 0.132 0.205 0.869 0.120 0.588\n",
      "  0.736 0.128 0.513 0.372 0.195 0.818 0.986 0.909 0.318 0.285 0.652 0.485\n",
      "  0.620 0.270 0.809 0.731 0.332 0.465 0.307 0.541 0.834 0.637 0.156 0.166\n",
      "  0.109 0.293 0.247 0.141 0.333 0.915 0.784 0.893 0.618 0.300 0.200 0.625\n",
      "  0.583 0.405 0.820 0.260]\n",
      " [0.394 0.931 0.686 0.241 0.292 0.505 0.245 0.276 0.789 0.325 0.815 0.654\n",
      "  0.687 0.209 1.000 0.477 0.178 0.242 0.816 0.781 0.769 0.496 0.913 0.503\n",
      "  0.500 0.755 0.421 0.915 0.798 0.289 0.214 0.445 0.923 0.627 0.773 0.452\n",
      "  0.499 0.900 0.497 0.227 0.688 0.776 0.833 0.827 0.571 0.827 0.540 0.953\n",
      "  0.680 0.835 0.877 0.834 0.444 0.194 0.621 0.521 0.242 0.600 0.909 0.578\n",
      "  0.417 0.231 0.256 0.884]\n",
      " [0.969 0.452 0.664 0.867 0.933 0.825 0.881 0.775 0.422 0.587 0.371 0.766\n",
      "  0.426 0.899 0.477 1.000 0.869 0.747 0.392 0.324 0.382 0.888 0.369 0.525\n",
      "  0.706 0.305 0.708 0.568 0.355 0.880 0.880 0.902 0.573 0.500 0.751 0.693\n",
      "  0.762 0.469 0.924 0.830 0.526 0.627 0.561 0.721 0.874 0.795 0.356 0.397\n",
      "  0.279 0.429 0.439 0.309 0.512 0.836 0.778 0.921 0.746 0.406 0.414 0.598\n",
      "  0.771 0.565 0.850 0.479]\n",
      " [0.852 0.143 0.659 0.944 0.951 0.659 0.848 0.762 0.341 0.539 0.224 0.746\n",
      "  0.382 0.964 0.178 0.869 1.000 0.910 0.304 0.190 0.268 0.893 0.154 0.613\n",
      "  0.775 0.178 0.605 0.357 0.254 0.848 0.964 0.903 0.307 0.392 0.668 0.578\n",
      "  0.656 0.283 0.793 0.749 0.461 0.514 0.371 0.505 0.746 0.601 0.304 0.145\n",
      "  0.191 0.313 0.275 0.132 0.464 0.981 0.772 0.814 0.727 0.309 0.217 0.644\n",
      "  0.653 0.525 0.914 0.288]\n",
      " [0.721 0.204 0.790 0.901 0.894 0.644 0.585 0.519 0.527 0.246 0.212 0.878\n",
      "  0.318 0.894 0.242 0.747 0.910 1.000 0.422 0.141 0.252 0.836 0.166 0.776\n",
      "  0.903 0.135 0.317 0.378 0.229 0.619 0.941 0.903 0.292 0.256 0.753 0.304\n",
      "  0.622 0.319 0.591 0.458 0.347 0.571 0.263 0.533 0.692 0.659 0.118 0.250\n",
      "  0.100 0.350 0.339 0.194 0.246 0.903 0.882 0.750 0.452 0.284 0.239 0.788\n",
      "  0.464 0.217 0.755 0.258]\n",
      " [0.324 0.782 0.831 0.327 0.341 0.411 0.206 0.240 0.902 0.225 0.907 0.734\n",
      "  0.764 0.304 0.816 0.392 0.304 0.422 1.000 0.844 0.889 0.559 0.827 0.800\n",
      "  0.680 0.860 0.273 0.890 0.891 0.253 0.319 0.500 0.732 0.655 0.809 0.298\n",
      "  0.471 0.847 0.439 0.139 0.678 0.848 0.759 0.774 0.536 0.760 0.537 0.904\n",
      "  0.787 0.959 0.904 0.948 0.436 0.327 0.740 0.473 0.195 0.834 0.916 0.831\n",
      "  0.323 0.165 0.320 0.840]\n",
      " [0.242 0.692 0.587 0.207 0.163 0.286 0.312 0.354 0.637 0.494 0.978 0.460\n",
      "  0.904 0.132 0.781 0.324 0.190 0.141 0.844 1.000 0.870 0.454 0.837 0.488\n",
      "  0.402 0.994 0.522 0.888 0.973 0.313 0.120 0.312 0.777 0.864 0.615 0.520\n",
      "  0.472 0.788 0.461 0.274 0.806 0.710 0.890 0.592 0.365 0.611 0.798 0.794\n",
      "  0.983 0.901 0.824 0.913 0.587 0.225 0.441 0.314 0.398 0.746 0.955 0.519\n",
      "  0.479 0.400 0.340 0.953]\n",
      " [0.261 0.822 0.713 0.271 0.243 0.266 0.343 0.477 0.744 0.516 0.897 0.572\n",
      "  0.778 0.205 0.769 0.382 0.268 0.252 0.889 0.870 1.000 0.541 0.907 0.648\n",
      "  0.544 0.882 0.499 0.836 0.910 0.381 0.189 0.429 0.728 0.805 0.721 0.534\n",
      "  0.473 0.814 0.500 0.308 0.845 0.868 0.865 0.753 0.443 0.615 0.755 0.869\n",
      "  0.870 0.950 0.853 0.909 0.707 0.322 0.603 0.375 0.413 0.898 0.889 0.709\n",
      "  0.480 0.484 0.418 0.812]\n",
      " [0.849 0.465 0.802 0.860 0.877 0.803 0.831 0.782 0.605 0.629 0.501 0.836\n",
      "  0.580 0.869 0.496 0.888 0.893 0.836 0.559 0.454 0.541 1.000 0.453 0.725\n",
      "  0.811 0.457 0.714 0.659 0.509 0.881 0.856 0.917 0.537 0.618 0.853 0.706\n",
      "  0.790 0.582 0.880 0.770 0.636 0.739 0.607 0.773 0.851 0.794 0.499 0.469\n",
      "  0.434 0.564 0.569 0.442 0.621 0.914 0.865 0.884 0.757 0.515 0.520 0.760\n",
      "  0.765 0.612 0.861 0.539]\n",
      " [0.243 0.890 0.669 0.201 0.187 0.320 0.240 0.407 0.746 0.490 0.844 0.560\n",
      "  0.739 0.120 0.913 0.369 0.154 0.166 0.827 0.837 0.907 0.453 1.000 0.507\n",
      "  0.465 0.818 0.490 0.866 0.888 0.290 0.111 0.350 0.859 0.752 0.730 0.521\n",
      "  0.472 0.872 0.447 0.228 0.848 0.812 0.888 0.759 0.448 0.674 0.735 0.923\n",
      "  0.790 0.886 0.865 0.854 0.653 0.189 0.550 0.376 0.326 0.694 0.905 0.576\n",
      "  0.463 0.401 0.326 0.856]\n",
      " [0.453 0.529 0.921 0.593 0.612 0.456 0.340 0.389 0.871 0.207 0.585 0.860\n",
      "  0.557 0.588 0.503 0.525 0.613 0.776 0.800 0.488 0.648 0.725 0.507 1.000\n",
      "  0.933 0.509 0.225 0.642 0.563 0.398 0.622 0.751 0.501 0.490 0.816 0.230\n",
      "  0.517 0.648 0.453 0.219 0.547 0.848 0.532 0.728 0.631 0.703 0.332 0.617\n",
      "  0.451 0.710 0.721 0.635 0.346 0.637 0.887 0.563 0.263 0.687 0.592 0.977\n",
      "  0.328 0.157 0.532 0.529]\n",
      " [0.612 0.505 0.948 0.792 0.774 0.552 0.498 0.526 0.770 0.298 0.478 0.952\n",
      "  0.526 0.736 0.500 0.706 0.775 0.903 0.680 0.402 0.544 0.811 0.465 0.933\n",
      "  1.000 0.393 0.340 0.604 0.477 0.532 0.791 0.885 0.542 0.478 0.877 0.341\n",
      "  0.656 0.584 0.560 0.358 0.572 0.835 0.529 0.717 0.681 0.779 0.314 0.552\n",
      "  0.349 0.618 0.636 0.492 0.366 0.790 0.946 0.669 0.413 0.541 0.521 0.942\n",
      "  0.481 0.235 0.709 0.506]\n",
      " [0.233 0.680 0.584 0.190 0.152 0.296 0.297 0.334 0.650 0.470 0.980 0.448\n",
      "  0.888 0.128 0.755 0.305 0.178 0.135 0.860 0.994 0.882 0.457 0.818 0.509\n",
      "  0.393 1.000 0.497 0.881 0.970 0.306 0.111 0.298 0.730 0.855 0.608 0.496\n",
      "  0.464 0.777 0.458 0.267 0.775 0.707 0.863 0.599 0.369 0.598 0.782 0.790\n",
      "  0.982 0.904 0.822 0.929 0.585 0.216 0.441 0.314 0.382 0.782 0.947 0.535\n",
      "  0.463 0.393 0.320 0.927]\n",
      " [0.646 0.362 0.404 0.552 0.523 0.491 0.879 0.897 0.243 0.965 0.459 0.366\n",
      "  0.662 0.513 0.421 0.708 0.605 0.317 0.273 0.522 0.499 0.714 0.490 0.225\n",
      "  0.340 0.497 1.000 0.524 0.529 0.870 0.449 0.520 0.538 0.761 0.515 0.988\n",
      "  0.625 0.526 0.848 0.887 0.779 0.502 0.736 0.539 0.577 0.517 0.813 0.302\n",
      "  0.550 0.399 0.466 0.294 0.877 0.635 0.378 0.598 0.941 0.357 0.470 0.271\n",
      "  0.849 0.939 0.783 0.566]\n",
      " [0.491 0.834 0.762 0.408 0.422 0.604 0.412 0.424 0.798 0.443 0.934 0.705\n",
      "  0.800 0.372 0.915 0.568 0.357 0.378 0.890 0.888 0.836 0.659 0.866 0.642\n",
      "  0.604 0.881 0.524 1.000 0.894 0.467 0.365 0.576 0.895 0.801 0.823 0.535\n",
      "  0.656 0.879 0.625 0.390 0.756 0.833 0.877 0.808 0.633 0.842 0.645 0.895\n",
      "  0.820 0.911 0.882 0.912 0.520 0.386 0.684 0.584 0.415 0.716 0.968 0.676\n",
      "  0.578 0.361 0.434 0.942]\n",
      " [0.272 0.700 0.678 0.280 0.219 0.326 0.322 0.395 0.715 0.511 0.960 0.542\n",
      "  0.915 0.195 0.798 0.355 0.254 0.229 0.891 0.973 0.910 0.509 0.888 0.563\n",
      "  0.477 0.970 0.529 0.894 1.000 0.346 0.186 0.350 0.765 0.847 0.704 0.542\n",
      "  0.510 0.836 0.499 0.289 0.848 0.748 0.887 0.643 0.418 0.661 0.819 0.816\n",
      "  0.949 0.922 0.866 0.907 0.657 0.292 0.526 0.374 0.416 0.746 0.954 0.596\n",
      "  0.499 0.432 0.400 0.934]\n",
      " [0.855 0.276 0.503 0.793 0.807 0.692 0.980 0.909 0.256 0.798 0.331 0.547\n",
      "  0.458 0.818 0.289 0.880 0.848 0.619 0.253 0.313 0.381 0.881 0.290 0.398\n",
      "  0.532 0.306 0.870 0.467 0.346 1.000 0.761 0.783 0.418 0.581 0.595 0.864\n",
      "  0.706 0.393 0.944 0.976 0.578 0.504 0.537 0.570 0.744 0.576 0.524 0.206\n",
      "  0.331 0.340 0.337 0.204 0.691 0.864 0.585 0.796 0.921 0.358 0.327 0.441\n",
      "  0.841 0.829 0.887 0.392]\n",
      " [0.886 0.167 0.670 0.943 0.982 0.745 0.753 0.617 0.372 0.345 0.187 0.801\n",
      "  0.276 0.986 0.214 0.880 0.964 0.941 0.319 0.120 0.189 0.856 0.111 0.622\n",
      "  0.791 0.111 0.449 0.365 0.186 0.761 1.000 0.921 0.309 0.263 0.686 0.426\n",
      "  0.651 0.256 0.750 0.657 0.317 0.482 0.278 0.518 0.780 0.661 0.118 0.176\n",
      "  0.085 0.290 0.250 0.135 0.280 0.924 0.815 0.856 0.579 0.264 0.200 0.659\n",
      "  0.569 0.334 0.820 0.256]\n",
      " [0.847 0.465 0.790 0.879 0.938 0.726 0.757 0.687 0.555 0.432 0.401 0.883\n",
      "  0.401 0.909 0.445 0.902 0.903 0.903 0.500 0.312 0.429 0.917 0.350 0.751\n",
      "  0.885 0.298 0.520 0.576 0.350 0.783 0.921 1.000 0.554 0.451 0.801 0.511\n",
      "  0.697 0.472 0.777 0.656 0.501 0.726 0.505 0.713 0.825 0.758 0.257 0.435\n",
      "  0.276 0.517 0.464 0.370 0.375 0.897 0.905 0.847 0.599 0.480 0.424 0.795\n",
      "  0.621 0.399 0.806 0.450]\n",
      " [0.473 0.863 0.649 0.324 0.403 0.455 0.405 0.442 0.687 0.467 0.809 0.631\n",
      "  0.699 0.318 0.923 0.573 0.307 0.292 0.732 0.777 0.728 0.537 0.859 0.501\n",
      "  0.542 0.730 0.538 0.895 0.765 0.418 0.309 0.554 1.000 0.700 0.709 0.541\n",
      "  0.489 0.855 0.570 0.363 0.766 0.782 0.905 0.765 0.612 0.770 0.592 0.850\n",
      "  0.704 0.814 0.814 0.769 0.462 0.306 0.603 0.533 0.366 0.596 0.875 0.557\n",
      "  0.479 0.333 0.389 0.907]\n",
      " [0.366 0.586 0.603 0.428 0.313 0.379 0.564 0.702 0.520 0.786 0.824 0.464\n",
      "  0.852 0.285 0.627 0.500 0.392 0.256 0.655 0.864 0.805 0.618 0.752 0.490\n",
      "  0.478 0.855 0.761 0.801 0.847 0.581 0.263 0.451 0.700 1.000 0.639 0.741\n",
      "  0.706 0.677 0.606 0.540 0.906 0.757 0.890 0.587 0.411 0.578 0.913 0.622\n",
      "  0.882 0.747 0.712 0.726 0.792 0.452 0.448 0.365 0.708 0.655 0.809 0.494\n",
      "  0.783 0.700 0.634 0.822]\n",
      " [0.661 0.720 0.965 0.739 0.696 0.720 0.531 0.559 0.845 0.434 0.667 0.954\n",
      "  0.684 0.652 0.773 0.751 0.668 0.753 0.809 0.615 0.721 0.853 0.730 0.816\n",
      "  0.877 0.608 0.515 0.823 0.704 0.595 0.686 0.801 0.709 0.639 1.000 0.539\n",
      "  0.798 0.778 0.700 0.458 0.713 0.885 0.707 0.869 0.744 0.936 0.515 0.773\n",
      "  0.536 0.764 0.799 0.676 0.566 0.698 0.933 0.762 0.514 0.596 0.745 0.871\n",
      "  0.654 0.387 0.688 0.711]\n",
      " [0.625 0.405 0.426 0.541 0.494 0.471 0.864 0.877 0.271 0.944 0.466 0.381\n",
      "  0.670 0.485 0.452 0.693 0.578 0.304 0.298 0.520 0.534 0.706 0.521 0.230\n",
      "  0.341 0.496 0.988 0.535 0.542 0.864 0.426 0.511 0.541 0.741 0.539 1.000\n",
      "  0.623 0.566 0.850 0.882 0.779 0.515 0.736 0.560 0.555 0.536 0.808 0.337\n",
      "  0.540 0.420 0.500 0.310 0.891 0.626 0.389 0.588 0.934 0.367 0.489 0.286\n",
      "  0.840 0.949 0.763 0.568]\n",
      " [0.656 0.431 0.715 0.818 0.641 0.764 0.650 0.684 0.455 0.567 0.477 0.713\n",
      "  0.549 0.620 0.499 0.762 0.656 0.622 0.471 0.472 0.473 0.790 0.472 0.517\n",
      "  0.656 0.464 0.625 0.656 0.510 0.706 0.651 0.697 0.489 0.706 0.798 0.623\n",
      "  1.000 0.445 0.704 0.630 0.593 0.652 0.541 0.581 0.544 0.753 0.514 0.447\n",
      "  0.421 0.465 0.480 0.426 0.563 0.707 0.655 0.623 0.728 0.331 0.535 0.540\n",
      "  0.919 0.548 0.797 0.531]\n",
      " [0.402 0.824 0.757 0.271 0.326 0.431 0.347 0.380 0.884 0.451 0.819 0.655\n",
      "  0.824 0.270 0.900 0.469 0.283 0.319 0.847 0.788 0.814 0.582 0.872 0.648\n",
      "  0.584 0.777 0.526 0.879 0.836 0.393 0.256 0.472 0.855 0.677 0.778 0.566\n",
      "  0.445 1.000 0.571 0.319 0.778 0.812 0.878 0.850 0.623 0.808 0.670 0.868\n",
      "  0.714 0.833 0.978 0.804 0.595 0.320 0.647 0.540 0.348 0.656 0.892 0.674\n",
      "  0.405 0.381 0.347 0.876]\n",
      " [0.920 0.448 0.591 0.750 0.815 0.777 0.933 0.814 0.417 0.729 0.491 0.635\n",
      "  0.569 0.809 0.497 0.924 0.793 0.591 0.439 0.461 0.500 0.880 0.447 0.453\n",
      "  0.560 0.458 0.848 0.625 0.499 0.944 0.750 0.777 0.570 0.606 0.700 0.850\n",
      "  0.704 0.571 1.000 0.930 0.617 0.586 0.656 0.721 0.854 0.746 0.546 0.408\n",
      "  0.442 0.497 0.519 0.390 0.689 0.783 0.668 0.894 0.840 0.486 0.504 0.521\n",
      "  0.799 0.747 0.816 0.563]\n",
      " [0.823 0.210 0.343 0.693 0.717 0.632 0.975 0.878 0.109 0.810 0.275 0.389\n",
      "  0.406 0.731 0.227 0.830 0.749 0.458 0.139 0.274 0.308 0.770 0.228 0.219\n",
      "  0.358 0.267 0.887 0.390 0.289 0.976 0.657 0.656 0.363 0.540 0.458 0.882\n",
      "  0.630 0.319 0.930 1.000 0.514 0.374 0.498 0.478 0.672 0.483 0.512 0.121\n",
      "  0.300 0.249 0.250 0.133 0.681 0.756 0.427 0.731 0.923 0.295 0.264 0.271\n",
      "  0.821 0.857 0.818 0.345]\n",
      " [0.380 0.653 0.690 0.453 0.372 0.296 0.567 0.743 0.608 0.815 0.763 0.563\n",
      "  0.861 0.332 0.688 0.526 0.461 0.347 0.678 0.806 0.845 0.636 0.848 0.547\n",
      "  0.572 0.775 0.779 0.756 0.848 0.578 0.317 0.501 0.766 0.906 0.713 0.779\n",
      "  0.593 0.778 0.617 0.514 1.000 0.810 0.934 0.665 0.478 0.614 0.931 0.673\n",
      "  0.814 0.774 0.777 0.670 0.869 0.508 0.556 0.427 0.684 0.638 0.784 0.583\n",
      "  0.691 0.717 0.672 0.811]\n",
      " [0.484 0.839 0.903 0.535 0.533 0.477 0.461 0.585 0.855 0.490 0.766 0.825\n",
      "  0.699 0.465 0.776 0.627 0.514 0.571 0.848 0.710 0.868 0.739 0.812 0.848\n",
      "  0.835 0.707 0.502 0.833 0.748 0.504 0.482 0.726 0.782 0.757 0.885 0.515\n",
      "  0.652 0.812 0.586 0.374 0.810 1.000 0.829 0.886 0.644 0.796 0.609 0.851\n",
      "  0.673 0.866 0.858 0.798 0.610 0.554 0.838 0.571 0.460 0.807 0.806 0.887\n",
      "  0.571 0.417 0.596 0.754]\n",
      " [0.449 0.789 0.665 0.352 0.367 0.376 0.539 0.623 0.672 0.711 0.876 0.564\n",
      "  0.875 0.307 0.833 0.561 0.371 0.263 0.759 0.890 0.865 0.607 0.888 0.532\n",
      "  0.529 0.863 0.736 0.877 0.887 0.537 0.278 0.505 0.905 0.890 0.707 0.736\n",
      "  0.541 0.878 0.656 0.498 0.934 0.829 1.000 0.763 0.573 0.712 0.856 0.800\n",
      "  0.870 0.854 0.868 0.800 0.749 0.395 0.560 0.496 0.584 0.725 0.900 0.578\n",
      "  0.618 0.604 0.538 0.932]\n",
      " [0.663 0.856 0.813 0.482 0.608 0.681 0.515 0.529 0.851 0.448 0.665 0.796\n",
      "  0.589 0.541 0.827 0.721 0.505 0.533 0.774 0.592 0.753 0.773 0.759 0.728\n",
      "  0.717 0.599 0.539 0.808 0.643 0.570 0.518 0.713 0.765 0.587 0.869 0.560\n",
      "  0.581 0.850 0.721 0.478 0.665 0.886 0.763 1.000 0.845 0.876 0.485 0.841\n",
      "  0.525 0.764 0.842 0.715 0.578 0.508 0.837 0.783 0.429 0.725 0.736 0.797\n",
      "  0.521 0.406 0.506 0.693]\n",
      " [0.906 0.528 0.673 0.654 0.865 0.840 0.706 0.599 0.627 0.451 0.448 0.752\n",
      "  0.419 0.834 0.571 0.874 0.746 0.692 0.536 0.365 0.443 0.851 0.448 0.631\n",
      "  0.681 0.369 0.577 0.633 0.418 0.744 0.780 0.825 0.612 0.411 0.744 0.555\n",
      "  0.544 0.623 0.854 0.672 0.478 0.644 0.573 0.845 1.000 0.802 0.307 0.517\n",
      "  0.311 0.524 0.573 0.437 0.444 0.685 0.813 0.965 0.506 0.512 0.483 0.678\n",
      "  0.519 0.403 0.625 0.515]\n",
      " [0.747 0.724 0.875 0.671 0.694 0.791 0.541 0.462 0.808 0.369 0.663 0.898\n",
      "  0.679 0.637 0.827 0.795 0.601 0.659 0.760 0.611 0.615 0.794 0.674 0.703\n",
      "  0.779 0.598 0.517 0.842 0.661 0.576 0.661 0.758 0.770 0.578 0.936 0.536\n",
      "  0.753 0.808 0.746 0.483 0.614 0.796 0.712 0.876 0.802 1.000 0.438 0.765\n",
      "  0.499 0.703 0.811 0.658 0.457 0.602 0.861 0.818 0.469 0.527 0.757 0.758\n",
      "  0.613 0.314 0.594 0.763]\n",
      " [0.242 0.468 0.474 0.289 0.168 0.194 0.520 0.684 0.431 0.862 0.710 0.303\n",
      "  0.867 0.156 0.540 0.356 0.304 0.118 0.537 0.798 0.755 0.499 0.735 0.332\n",
      "  0.314 0.782 0.813 0.645 0.819 0.524 0.118 0.257 0.592 0.913 0.515 0.808\n",
      "  0.514 0.670 0.546 0.512 0.931 0.609 0.856 0.485 0.307 0.438 1.000 0.507\n",
      "  0.834 0.635 0.671 0.580 0.907 0.367 0.295 0.268 0.709 0.530 0.703 0.344\n",
      "  0.679 0.789 0.570 0.740]\n",
      " [0.297 0.963 0.729 0.198 0.245 0.410 0.158 0.231 0.844 0.245 0.850 0.665\n",
      "  0.652 0.166 0.953 0.397 0.145 0.250 0.904 0.794 0.869 0.469 0.923 0.617\n",
      "  0.552 0.790 0.302 0.895 0.816 0.206 0.176 0.435 0.850 0.622 0.773 0.337\n",
      "  0.447 0.868 0.408 0.121 0.673 0.851 0.800 0.841 0.517 0.765 0.507 1.000\n",
      "  0.717 0.914 0.888 0.919 0.430 0.168 0.661 0.446 0.157 0.763 0.913 0.694\n",
      "  0.337 0.169 0.216 0.837]\n",
      " [0.194 0.622 0.517 0.177 0.129 0.203 0.337 0.403 0.553 0.554 0.951 0.375\n",
      "  0.881 0.109 0.680 0.279 0.191 0.100 0.787 0.983 0.870 0.434 0.790 0.451\n",
      "  0.349 0.982 0.550 0.820 0.949 0.331 0.085 0.276 0.704 0.882 0.536 0.540\n",
      "  0.421 0.714 0.442 0.300 0.814 0.673 0.870 0.525 0.311 0.499 0.834 0.717\n",
      "  1.000 0.872 0.753 0.874 0.631 0.230 0.376 0.253 0.439 0.767 0.898 0.478\n",
      "  0.477 0.467 0.357 0.898]\n",
      " [0.337 0.838 0.761 0.315 0.336 0.358 0.309 0.367 0.801 0.372 0.953 0.672\n",
      "  0.776 0.293 0.835 0.429 0.313 0.350 0.959 0.901 0.950 0.564 0.886 0.710\n",
      "  0.618 0.904 0.399 0.911 0.922 0.340 0.290 0.517 0.814 0.747 0.764 0.420\n",
      "  0.465 0.833 0.497 0.249 0.774 0.866 0.854 0.764 0.524 0.703 0.635 0.914\n",
      "  0.872 1.000 0.868 0.964 0.527 0.339 0.689 0.456 0.307 0.887 0.943 0.768\n",
      "  0.403 0.305 0.376 0.886]\n",
      " [0.357 0.818 0.808 0.285 0.304 0.399 0.298 0.348 0.919 0.404 0.853 0.681\n",
      "  0.852 0.247 0.877 0.439 0.275 0.339 0.904 0.824 0.853 0.569 0.865 0.721\n",
      "  0.636 0.822 0.466 0.882 0.866 0.337 0.250 0.464 0.814 0.712 0.799 0.500\n",
      "  0.480 0.978 0.519 0.250 0.777 0.858 0.868 0.842 0.573 0.811 0.671 0.888\n",
      "  0.753 0.868 1.000 0.857 0.581 0.315 0.668 0.488 0.320 0.725 0.913 0.738\n",
      "  0.403 0.334 0.353 0.879]\n",
      " [0.231 0.827 0.667 0.163 0.187 0.343 0.166 0.215 0.782 0.260 0.964 0.558\n",
      "  0.737 0.141 0.834 0.309 0.132 0.194 0.948 0.913 0.909 0.442 0.854 0.635\n",
      "  0.492 0.929 0.294 0.912 0.907 0.204 0.135 0.370 0.769 0.726 0.676 0.310\n",
      "  0.426 0.804 0.390 0.133 0.670 0.798 0.800 0.715 0.437 0.658 0.580 0.919\n",
      "  0.874 0.964 0.857 1.000 0.427 0.159 0.568 0.352 0.183 0.865 0.953 0.672\n",
      "  0.335 0.193 0.210 0.876]\n",
      " [0.411 0.445 0.499 0.430 0.338 0.311 0.672 0.827 0.393 0.917 0.522 0.366\n",
      "  0.706 0.333 0.444 0.512 0.464 0.246 0.436 0.587 0.707 0.621 0.653 0.346\n",
      "  0.366 0.585 0.877 0.520 0.657 0.691 0.280 0.375 0.462 0.792 0.566 0.891\n",
      "  0.563 0.595 0.689 0.681 0.869 0.610 0.749 0.578 0.444 0.457 0.907 0.430\n",
      "  0.631 0.527 0.581 0.427 1.000 0.520 0.397 0.438 0.819 0.520 0.531 0.395\n",
      "  0.754 0.914 0.702 0.545]\n",
      " [0.794 0.171 0.694 0.946 0.898 0.628 0.849 0.787 0.370 0.578 0.256 0.753\n",
      "  0.436 0.915 0.194 0.836 0.981 0.903 0.327 0.225 0.322 0.914 0.189 0.637\n",
      "  0.790 0.216 0.635 0.386 0.292 0.864 0.924 0.897 0.306 0.452 0.698 0.626\n",
      "  0.707 0.320 0.783 0.756 0.508 0.554 0.395 0.508 0.685 0.602 0.367 0.168\n",
      "  0.230 0.339 0.315 0.159 0.520 1.000 0.768 0.763 0.774 0.317 0.255 0.661\n",
      "  0.703 0.586 0.930 0.308]\n",
      " [0.722 0.622 0.938 0.774 0.822 0.696 0.537 0.513 0.801 0.294 0.533 0.982\n",
      "  0.506 0.784 0.621 0.778 0.772 0.882 0.740 0.441 0.603 0.865 0.550 0.887\n",
      "  0.946 0.441 0.378 0.684 0.526 0.585 0.815 0.905 0.603 0.448 0.933 0.389\n",
      "  0.655 0.647 0.668 0.427 0.556 0.838 0.560 0.837 0.813 0.861 0.295 0.661\n",
      "  0.376 0.689 0.668 0.568 0.397 0.768 1.000 0.817 0.411 0.606 0.582 0.942\n",
      "  0.492 0.252 0.672 0.553]\n",
      " [0.960 0.455 0.663 0.758 0.911 0.892 0.765 0.608 0.537 0.445 0.383 0.776\n",
      "  0.401 0.893 0.521 0.921 0.814 0.750 0.473 0.314 0.375 0.884 0.376 0.563\n",
      "  0.669 0.314 0.598 0.584 0.374 0.796 0.856 0.847 0.533 0.365 0.762 0.588\n",
      "  0.623 0.540 0.894 0.731 0.427 0.571 0.496 0.783 0.965 0.818 0.268 0.446\n",
      "  0.253 0.456 0.488 0.352 0.438 0.763 0.817 1.000 0.579 0.416 0.425 0.635\n",
      "  0.591 0.430 0.692 0.466]\n",
      " [0.672 0.214 0.427 0.718 0.607 0.501 0.930 0.933 0.142 0.915 0.346 0.408\n",
      "  0.571 0.618 0.242 0.746 0.727 0.452 0.195 0.398 0.413 0.757 0.326 0.263\n",
      "  0.413 0.382 0.941 0.415 0.416 0.921 0.579 0.599 0.366 0.708 0.514 0.934\n",
      "  0.728 0.348 0.840 0.923 0.684 0.460 0.584 0.429 0.506 0.469 0.709 0.157\n",
      "  0.439 0.307 0.320 0.183 0.819 0.774 0.411 0.579 1.000 0.304 0.340 0.304\n",
      "  0.915 0.935 0.898 0.420]\n",
      " [0.335 0.725 0.625 0.245 0.332 0.263 0.351 0.398 0.669 0.358 0.816 0.524\n",
      "  0.602 0.300 0.600 0.406 0.309 0.284 0.834 0.746 0.898 0.515 0.694 0.687\n",
      "  0.541 0.782 0.357 0.716 0.746 0.358 0.264 0.480 0.596 0.655 0.596 0.367\n",
      "  0.331 0.656 0.486 0.295 0.638 0.807 0.725 0.725 0.512 0.527 0.530 0.763\n",
      "  0.767 0.887 0.725 0.865 0.520 0.317 0.606 0.416 0.304 1.000 0.751 0.744\n",
      "  0.329 0.344 0.354 0.672]\n",
      " [0.325 0.833 0.709 0.265 0.251 0.411 0.295 0.332 0.782 0.412 0.977 0.608\n",
      "  0.860 0.200 0.909 0.414 0.217 0.239 0.916 0.955 0.889 0.520 0.905 0.592\n",
      "  0.521 0.947 0.470 0.968 0.954 0.327 0.200 0.424 0.875 0.809 0.745 0.489\n",
      "  0.535 0.892 0.504 0.264 0.784 0.806 0.900 0.736 0.483 0.757 0.703 0.913\n",
      "  0.898 0.943 0.913 0.953 0.531 0.255 0.582 0.425 0.340 0.751 1.000 0.629\n",
      "  0.476 0.327 0.332 0.972]\n",
      " [0.521 0.624 0.944 0.628 0.658 0.493 0.395 0.427 0.869 0.236 0.614 0.910\n",
      "  0.562 0.625 0.578 0.598 0.644 0.788 0.831 0.519 0.709 0.760 0.576 0.977\n",
      "  0.942 0.535 0.271 0.676 0.596 0.441 0.659 0.795 0.557 0.494 0.871 0.286\n",
      "  0.540 0.674 0.521 0.271 0.583 0.887 0.578 0.797 0.678 0.758 0.344 0.694\n",
      "  0.478 0.768 0.738 0.672 0.395 0.661 0.942 0.635 0.304 0.744 0.629 1.000\n",
      "  0.368 0.197 0.568 0.565]\n",
      " [0.665 0.374 0.540 0.750 0.595 0.658 0.813 0.864 0.267 0.818 0.446 0.523\n",
      "  0.569 0.583 0.417 0.771 0.653 0.464 0.323 0.479 0.480 0.765 0.463 0.328\n",
      "  0.481 0.463 0.849 0.578 0.499 0.841 0.569 0.621 0.479 0.783 0.654 0.840\n",
      "  0.919 0.405 0.799 0.821 0.691 0.571 0.618 0.521 0.519 0.613 0.679 0.337\n",
      "  0.477 0.403 0.403 0.335 0.754 0.703 0.492 0.591 0.915 0.329 0.476 0.368\n",
      "  1.000 0.811 0.861 0.513]\n",
      " [0.487 0.248 0.297 0.477 0.391 0.320 0.822 0.902 0.116 0.961 0.340 0.219\n",
      "  0.542 0.405 0.231 0.565 0.525 0.217 0.165 0.400 0.484 0.612 0.401 0.157\n",
      "  0.235 0.393 0.939 0.361 0.432 0.829 0.334 0.399 0.333 0.700 0.387 0.949\n",
      "  0.548 0.381 0.747 0.857 0.717 0.417 0.604 0.406 0.403 0.314 0.789 0.169\n",
      "  0.467 0.305 0.334 0.193 0.914 0.586 0.252 0.430 0.935 0.344 0.327 0.197\n",
      "  0.811 1.000 0.748 0.378]\n",
      " [0.762 0.232 0.658 0.921 0.818 0.583 0.891 0.915 0.309 0.766 0.327 0.673\n",
      "  0.528 0.820 0.256 0.850 0.914 0.755 0.320 0.340 0.418 0.861 0.326 0.532\n",
      "  0.709 0.320 0.783 0.434 0.400 0.887 0.820 0.806 0.389 0.634 0.688 0.763\n",
      "  0.797 0.347 0.816 0.818 0.672 0.596 0.538 0.506 0.625 0.594 0.570 0.216\n",
      "  0.357 0.376 0.353 0.210 0.702 0.930 0.672 0.692 0.898 0.354 0.332 0.568\n",
      "  0.861 0.748 1.000 0.399]\n",
      " [0.401 0.763 0.669 0.313 0.312 0.419 0.391 0.391 0.708 0.492 0.949 0.590\n",
      "  0.901 0.260 0.884 0.479 0.288 0.258 0.840 0.953 0.812 0.539 0.856 0.529\n",
      "  0.506 0.927 0.566 0.942 0.934 0.392 0.256 0.450 0.907 0.822 0.711 0.568\n",
      "  0.531 0.876 0.563 0.345 0.811 0.754 0.932 0.693 0.515 0.763 0.740 0.837\n",
      "  0.898 0.886 0.879 0.876 0.545 0.308 0.553 0.466 0.420 0.672 0.972 0.565\n",
      "  0.513 0.378 0.399 1.000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-3e89f8f3a087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mw_a_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpca_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntk_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_find_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marchs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_a_bits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntk_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-07fedff64e01>\u001b[0m in \u001b[0;36msearch_find_best\u001b[0;34m(xloader, network, lrc_model, archs, w_a_bits, reinit)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_q_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# pca score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_eig_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mpca_score_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;31m# ntk score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-07fedff64e01>\u001b[0m in \u001b[0;36mpca_eig_diag\u001b[0;34m(xloader, network, num_batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcross_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0masd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asd' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples = 300\n",
    "\n",
    "fp_results = torch.load(\"./c3n5_1000samples.pth\")\n",
    "archs = fp_results['archs']\n",
    "fp_ntk_scores = fp_results['ntk_scores']\n",
    "fp_lr_scores = fp_results['lr_scores']\n",
    "api_valid_accs = fp_results['api_valid_accs']\n",
    "api_flops = fp_results['api_flops']\n",
    "api_params = fp_results['api_params']\n",
    "\n",
    "w_a_bits = [(32,32),(4,4),(2,2),(1,1)]\n",
    "trained_weights = torch.load(\"./results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\")\n",
    "network.load_state_dict(trained_weights['search_model'])\n",
    "pca_scores, ntk_scores, lr_scores = search_find_best(train_loader, network, lrc_model, [archs[best_idx]], w_a_bits, reinit=False)\n",
    "print(pca_scores, ntk_scores, lr_scores)\n",
    "\n",
    "w_a_bits = [(32,32),(4,4),(2,2),(1,1)]\n",
    "init_model(network)\n",
    "pca_scores, ntk_scores, lr_scores = search_find_best(train_loader, network, lrc_model, [archs[best_idx]], w_a_bits)\n",
    "print(pca_scores, ntk_scores, lr_scores)\n",
    "\n",
    "# w_a_bits = [(2,2)]\n",
    "# trained_weights = torch.load(\"./results/tmp/train_w2_a2/checkpoint/seed-29411-basic.pth\")\n",
    "# network.load_state_dict(trained_weights['search_model'])\n",
    "# pca_scores, ntk_scores, lr_scores = search_find_best(train_loader, network, lrc_model, [archs[best_idx]], w_a_bits)\n",
    "# print(pca_scores, ntk_scores, lr_scores)\n",
    "\n",
    "# w_a_bits = [(2,2)]\n",
    "# init_model(network)\n",
    "# pca_scores, ntk_scores, lr_scores = search_find_best(train_loader, network, lrc_model, [archs[best_idx]], w_a_bits)\n",
    "# print(pca_scores, ntk_scores, lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee0648af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0953, 0.0917, 0.0893, 0.0874, 0.0869, 0.0840, 0.0838, 0.0812, 0.0780,\n",
      "        0.0752, 0.0749, 0.0722])\n",
      "tensor(2.4815)\n"
     ]
    }
   ],
   "source": [
    "feat = torch.randn((2000,12))\n",
    "m = feat.mean(dim=0, keepdim=True)\n",
    "feat = feat - m\n",
    "sigma = torch.mm(feat.transpose(1,0),feat) / (feat.size(0))\n",
    "u, s, v = torch.svd(sigma)\n",
    "prob_s = s / s.sum()\n",
    "print(prob_s)\n",
    "score = (-prob_s)*torch.log(prob_s+1e-8)\n",
    "score = score.sum()\n",
    "    \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c669c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:39<00:00, 39.98s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w32a32': [2.2307282288869223], 'w4a4': [2.2216827074686685], 'w2a2': [2.232145388921102]} {'w32a32': [13168784.0], 'w4a4': [13720861.333333334], 'w2a2': [12135564.333333334]} {'w32a32': [300.0], 'w4a4': [299.3333333333333], 'w2a2': [299.6666666666667]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:33<00:00, 33.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w32a32': [2.046016534169515], 'w4a4': [2.029487689336141], 'w2a2': [1.9883435169855754]} {'w32a32': [-303.4014383951823], 'w4a4': [-154.0976791381836], 'w2a2': [-326.6259409586589]} {'w32a32': [299.6666666666667], 'w4a4': [300.0], 'w2a2': [299.6666666666667]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_a_bits = [(32,32),(4,4),(2,2)]\n",
    "trained_weights = torch.load(\"./results/tmp/train_w32_a32/checkpoint/seed-68245-basic.pth\")\n",
    "network.load_state_dict(trained_weights['search_model'])\n",
    "pca_scores, ntk_scores, lr_scores = search_find_best(train_loader, network, lrc_model, [archs[best_idx]], w_a_bits)\n",
    "print(pca_scores, ntk_scores, lr_scores)\n",
    "\n",
    "w_a_bits = [(32,32),(4,4),(2,2)]\n",
    "init_model(network)\n",
    "pca_scores, ntk_scores, lr_scores = search_find_best(train_loader, network, lrc_model, [archs[best_idx]], w_a_bits)\n",
    "print(pca_scores, ntk_scores, lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aebcc098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.scatter(stats.rankdata(q_pca_scores_32),stats.rankdata(q_pca_scores_1))\n",
    "# plt.xlim([-2000,10])\n",
    "# plt.ylim([-2000,10])\n",
    "# plt.scatter(q_ntk_scores_32,q_ntk_scores_32)\n",
    "# plt.show()\n",
    "\n",
    "target = pca_scores\n",
    "\n",
    "plt.scatter(target[\"w32a32\"],target[\"w8a8\"])\n",
    "plt.scatter(target[\"w32a32\"],target[\"w32a32\"])\n",
    "# plt.xlim([-5e3, 0])\n",
    "# plt.ylim([-5e3, 0])\n",
    "# plt.xlim([280, 310])\n",
    "# plt.ylim([280, 310])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(target[\"w32a32\"],target[\"w4a4\"])\n",
    "plt.scatter(target[\"w32a32\"],target[\"w32a32\"])\n",
    "# plt.xlim([-5e3, 0])\n",
    "# plt.ylim([-5e3, 0])\n",
    "# plt.xlim([280, 310])\n",
    "# plt.ylim([280, 310])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(target[\"w32a32\"],target[\"w2a2\"])\n",
    "plt.scatter(target[\"w32a32\"],target[\"w32a32\"])\n",
    "# plt.xlim([-5e3, 0])\n",
    "# plt.ylim([-5e3, 0])\n",
    "# plt.xlim([280, 310])\n",
    "# plt.ylim([280, 310])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ca924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # def get_valid_acc_from_api(api, arch):\n",
    "# #     # print(api.query_by_arch(arch, \"200\"))\n",
    "# #     index = api.query_index_by_arch(arch)\n",
    "# #     results = api.query_by_index(index, 'cifar10-valid', '200') # a dict of all trials for 1st net on cifar100, where the key is the seed\n",
    "# #     acc = 0\n",
    "# #     for seed, result in results.items():\n",
    "# #         acc = acc + result.get_eval('valid')['accuracy']\n",
    "# #     acc = acc / len(results)\n",
    "# #     return acc\n",
    "\n",
    "# def get_results_from_api(api, arch):\n",
    "#     # print(api.query_by_arch(arch, \"200\"))\n",
    "#     index = api.query_index_by_arch(arch)\n",
    "#     results = api.query_by_index(index, 'cifar10-valid', '200') # a dict of all trials for 1st net on cifar100, where the key is the seed\n",
    "# #     results = api.query_by_index(index, 'cifar100', '200') # a dict of all trials for 1st net on cifar100, where the key is the seed\n",
    "    \n",
    "#     # valid acc\n",
    "#     acc = 0\n",
    "#     for seed, result in results.items():\n",
    "#         acc = acc + result.get_eval('valid')['accuracy']\n",
    "# #         acc = acc + result.get_eval('x-test')['accuracy']\n",
    "#     acc = acc / len(results)\n",
    "    \n",
    "#     result = list(results.values())[0]\n",
    "    \n",
    "#     return acc, result.flop, result.params\n",
    "\n",
    "# api_valid_accs, api_flops, api_params = [], [], []\n",
    "# for a in archs:\n",
    "#     valid_acc, flops, params = get_results_from_api(api, a)\n",
    "#     api_valid_accs.append(valid_acc)\n",
    "#     api_flops.append(flops)\n",
    "#     api_params.append(params)\n",
    "\n",
    "# # api_valid_accs = [get_valid_acc_from_api(api, a) for a in archs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd152cc4",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9047304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp_results = torch.load(\"./c3n1_1000samples.pth\")\n",
    "# archs = fp_results['archs']\n",
    "# fp_ntk_scores = fp_results['ntk_scores']\n",
    "# fp_lr_scores = fp_results['lr_scores']\n",
    "# api_valid_accs = fp_results['api_valid_accs']\n",
    "# api_flops = fp_results['api_flops']\n",
    "# api_params = fp_results['api_params']\n",
    "\n",
    "# torch.save({\"archs\":archs,\n",
    "#             \"ntk_scores\":ntk_scores,\n",
    "#             \"pca_scores\":pca_scores,\n",
    "#             \"lr_scores\":lr_scores,\n",
    "#             \"api_valid_accs\":api_valid_accs,\n",
    "#             \"api_flops\":api_flops,\n",
    "#             \"api_params\":api_params,\n",
    "#            },\"./c3n5_1000samples_32_8_4_2.pth\")\n",
    "\n",
    "# torch.save({\"archs\":archs,\n",
    "#             \"fp_ntk_scores\":fp_ntk_scores,\n",
    "#             \"fp_lr_scores\":fp_lr_scores,\n",
    "#             \"q_ntk_scores\":q_ntk_scores,\n",
    "#             \"q_lr_scores\":q_lr_scores,\n",
    "#             \"api_valid_accs\":api_valid_accs,\n",
    "#             \"api_flops\":api_flops,\n",
    "#             \"api_params\":api_params,\n",
    "#            },\"./c3n5_1000samples_1bit.pth\")\n",
    "\n",
    "# trained_results = torch.load(\"./c3n5_1000samples_4bit.pth\")\n",
    "# archs = trained_results['archs']\n",
    "# fp_ntk_scores = trained_results['fp_ntk_scores']\n",
    "# fp_lr_scores = trained_results['fp_lr_scores']\n",
    "# q_ntk_scores = trained_results['q_ntk_scores']\n",
    "# q_lr_scores = trained_results['q_lr_scores']\n",
    "# api_valid_accs = trained_results['api_valid_accs']\n",
    "# api_flops = trained_results['api_flops']\n",
    "# api_params = trained_results['api_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63b4c375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM-NAS finds the best one : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|avg_pool_3x3~2|) with ntk_score=-327.8279113769531, lr_score=300.0\n",
      "117.88353 0.830426\n",
      "\n",
      "\n",
      "\n",
      "Call query_info_str_by_arch with arch=Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|avg_pool_3x3~2|) and hp=200\n",
      "Call query_index_by_arch with arch=Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|avg_pool_3x3~2|)\n",
      "|nor_conv_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_1x1~1|avg_pool_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=14152\n",
      "cifar10-valid  FLOP=117.88 M, Params=0.830 MB, latency=19.51 ms.\n",
      "cifar10-valid  train : [loss = 0.002, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.02%]\n",
      "cifar10        FLOP=117.88 M, Params=0.830 MB, latency=19.51 ms.\n",
      "cifar10        train : [loss = 0.003, top1 = 99.97%], test  : [loss = 0.287, top1 = 93.82%]\n",
      "cifar100       FLOP=117.89 M, Params=0.836 MB, latency=17.14 ms.\n",
      "cifar100       train : [loss = 0.051, top1 = 99.35%], valid : [loss = 1.368, top1 = 70.61%], test : [loss = 1.347, top1 = 70.85%]\n",
      "ImageNet16-120 FLOP= 29.48 M, Params=0.838 MB, latency=15.42 ms.\n",
      "ImageNet16-120 train : [loss = 1.509, top1 = 59.16%], valid : [loss = 2.216, top1 = 44.01%], test : [loss = 2.242, top1 = 44.64%]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6877306427764505 1.3642851573445723e-70\n"
     ]
    }
   ],
   "source": [
    "q_pca_scores = np.array(pca_scores[\"w32a32\"]) - np.array(pca_scores[\"w2a2\"])\n",
    "q_ntk_scores = ntk_scores[\"w32a32\"]\n",
    "q_lr_scores = lr_scores[\"w32a32\"]\n",
    "\n",
    "rank_pca, rank_ntk, rank_lr, rank_flops, rank_params = stats.rankdata(q_pca_scores), stats.rankdata(q_ntk_scores), stats.rankdata(q_lr_scores), stats.rankdata(api_flops), stats.rankdata(api_params)\n",
    "\n",
    "l = len(q_ntk_scores)\n",
    "# rank_agg = np.log(rank_pca/l)\n",
    "rank_agg = np.log(rank_ntk/l) + np.log(rank_lr/l) + np.log(rank_flops/l)\n",
    "\n",
    "idx_10p = stats.rankdata(rank_agg) > 0.9*l\n",
    "tmp = q_pca_scores == np.min(q_pca_scores[idx_10p])\n",
    "\n",
    "# best_idx = np.argmax(rank_agg)\n",
    "best_idx = np.argmax(tmp)\n",
    "best_arch, best_ntk_score, best_lr_score, flops, params = archs[best_idx], q_ntk_scores[best_idx], q_lr_scores[best_idx], api_flops[best_idx], api_params[best_idx]\n",
    "\n",
    "print(\"RANDOM-NAS finds the best one : {:} with ntk_score={:}, lr_score={:}\".format(best_arch, best_ntk_score, best_lr_score))\n",
    "print(flops, params)\n",
    "print(\"\\n\\n\")\n",
    "if api is not None:\n",
    "    print(\"{:}\".format(api.query_by_arch(best_arch, \"200\")))\n",
    "\n",
    "x = stats.rankdata(rank_agg)\n",
    "y = stats.rankdata(api_valid_accs)\n",
    "# y = api_valid_accs\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=4)\n",
    "plt.title(\"rank_agg\")\n",
    "plt.show()\n",
    "tau, p_value = stats.kendalltau(x, y)\n",
    "print(tau, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b332093",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stats.rankdata(ntk_scores)\n",
    "y = stats.rankdata(api_valid_accs)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=4)\n",
    "plt.title(\"metric_confidences\")\n",
    "plt.show()\n",
    "tau, p_value = stats.kendalltau(x, y)\n",
    "print(tau, p_value)\n",
    "\n",
    "x = stats.rankdata(lr_scores)\n",
    "y = stats.rankdata(api_valid_accs)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=4)\n",
    "plt.title(\"metric_confidences\")\n",
    "plt.show()\n",
    "tau, p_value = stats.kendalltau(x, y)\n",
    "print(tau, p_value)\n",
    "\n",
    "x = stats.rankdata(api_flops)\n",
    "y = stats.rankdata(api_valid_accs)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=4)\n",
    "plt.title(\"metric_confidences\")\n",
    "plt.show()\n",
    "tau, p_value = stats.kendalltau(x, y)\n",
    "print(tau, p_value)\n",
    "\n",
    "x = stats.rankdata(api_params)\n",
    "y = stats.rankdata(api_valid_accs)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x[best_idx], y[best_idx], c=\"r\", linewidths=4)\n",
    "plt.title(\"metric_confidences\")\n",
    "plt.show()\n",
    "tau, p_value = stats.kendalltau(x, y)\n",
    "print(tau, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c62b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = api.query_index_by_arch(archs[0])\n",
    "results = api.query_by_index(index, 'cifar10-valid', '200')\n",
    "tmp = list(results.values())[0]\n",
    "print(tmp)\n",
    "print(tmp.params)\n",
    "print(tmp.flop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
